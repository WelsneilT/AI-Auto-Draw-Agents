"""
======================================================================================
ANIME STORY STUDIO V5 - PURE COMPUTER VISION (NO HOTKEYS)
100% Mouse Click - KhÃ´ng dÃ¹ng phÃ­m táº¯t Windows
======================================================================================
"""

import os
import time
import base64
import json
import subprocess
from io import BytesIO
from datetime import datetime
from dotenv import load_dotenv
from PIL import Image, ImageDraw
import pyautogui
import cv2
import numpy as np
from typing import TypedDict, List, Dict, Tuple, Optional
from langgraph.graph import StateGraph, END
import google.generativeai as genai
import traceback
import pyperclip

# Load environment
load_dotenv()
genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))

# Táº¯t fail-safe
pyautogui.FAILSAFE = False
pyautogui.PAUSE = 0.05

# ============ SHARED STATE ============

class StoryArtState(TypedDict):
    """State chung cho cáº£ 2 agents"""
    # User Input
    character_name: str
    story_theme: str
    story_length: int
    mode: str
    
    # Story Writer State
    character_info: Dict
    story_outline: Dict
    story_content: str
    story_file_path: str
    
    # Art Creator State
    reference_image_b64: str
    paint_screenshot_b64: str
    tool_positions: Dict
    color_positions: Dict
    canvas_area: Dict
    drawing_steps: List[Dict]
    current_step: int
    total_steps: int
    
    # Window Management State
    paint_window_ready: bool
    paint_maximized: bool
    
    # Shared
    execution_log: List[str]
    is_complete: bool
    error: str


# ============ UTILITY FUNCTIONS ============

def screenshot_to_base64(region=None) -> str:
    """Chá»¥p mÃ n hÃ¬nh vÃ  convert sang base64"""
    if region:
        screenshot = pyautogui.screenshot(region=region)
    else:
        screenshot = pyautogui.screenshot()
    buffered = BytesIO()
    screenshot.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode()

def image_to_base64(image_path: str) -> str:
    """Convert áº£nh file sang base64"""
    with open(image_path, 'rb') as f:
        return base64.b64encode(f.read()).decode()

def call_gemini(prompt: str) -> str:
    """Gá»i Gemini text-only"""
    model = genai.GenerativeModel('gemini-2.0-flash-exp')
    response = model.generate_content(prompt)
    return response.text

def call_gemini_vision(prompt: str, images: List[Image.Image]) -> str:
    """Gá»i Gemini vá»›i vision"""
    model = genai.GenerativeModel('gemini-2.0-flash-exp')
    content = images + [prompt]
    response = model.generate_content(content)
    return response.text

def simplify_image_for_drawing(image_path: str, output_path: str = "simplified.png"):
    """ÄÆ¡n giáº£n hÃ³a áº£nh thÃ nh dáº¡ng cartoon/sketch dá»… váº½"""
    img = cv2.imread(image_path)
    
    # Resize vá» kÃ­ch thÆ°á»›c vá»«a pháº£i
    height, width = img.shape[:2]
    max_size = 300
    if max(height, width) > max_size:
        scale = max_size / max(height, width)
        img = cv2.resize(img, None, fx=scale, fy=scale)
    
    # Chuyá»ƒn sang cartoon style
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray, 5)
    
    # Detect edges
    edges = cv2.adaptiveThreshold(
        gray, 255, 
        cv2.ADAPTIVE_THRESH_MEAN_C, 
        cv2.THRESH_BINARY, 
        9, 9
    )
    
    # Smooth colors
    color = cv2.bilateralFilter(img, 9, 250, 250)
    
    # Combine
    cartoon = cv2.bitwise_and(color, color, mask=edges)
    
    cv2.imwrite(output_path, cartoon)
    print(f"   âœ… Simplified image saved: {output_path}")
    return output_path


# ============ COMPUTER VISION MODULE ============

def find_button_by_template(screenshot_b64: str, button_name: str) -> Optional[Tuple[int, int]]:
    """
    TÃ¬m button báº±ng template matching
    """
    # Decode screenshot
    img_data = base64.b64decode(screenshot_b64)
    img = cv2.imdecode(np.frombuffer(img_data, np.uint8), cv2.IMREAD_COLOR)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # Template path (cáº§n chuáº©n bá»‹ trÆ°á»›c)
    template_path = f"templates/{button_name}.png"
    
    if not os.path.exists(template_path):
        return None
    
    template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)
    
    # Template matching
    result = cv2.matchTemplate(gray, template, cv2.TM_CCOEFF_NORMED)
    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)
    
    if max_val > 0.7:  # Threshold
        # Tráº£ vá» tÃ¢m cá»§a button
        h, w = template.shape
        center_x = max_loc[0] + w // 2
        center_y = max_loc[1] + h // 2
        return (center_x, center_y)
    
    return None


def detect_window_state_with_llm(screenshot_b64: str) -> Dict:
    """
    DÃ¹ng LLM Ä‘á»ƒ phÃ¢n tÃ­ch tráº¡ng thÃ¡i window hiá»‡n táº¡i
    """
    img = Image.open(BytesIO(base64.b64decode(screenshot_b64)))
    img.thumbnail((1200, 1200), Image.Resampling.LANCZOS)
    
    prompt = """
PhÃ¢n tÃ­ch mÃ n hÃ¬nh hiá»‡n táº¡i vÃ  tráº£ vá» JSON:

{{
  "window_type": "paint" | "dialog" | "desktop" | "other",
  "is_maximized": true/false,
  "has_dialog": true/false,
  "dialog_type": "share" | "save" | "close_confirm" | null,
  "action_needed": "maximize" | "close_dialog" | "click_canvas" | "ready",
  "maximize_button_position": {{"x": 1234, "y": 56}} or null,
  "close_button_position": {{"x": 1234, "y": 56}} or null,
  "canvas_visible": true/false,
  "description": "MÃ´ táº£ ngáº¯n gá»n"
}}

QUY Táº®C:
1. Náº¿u tháº¥y dialog "Share" â†’ action_needed = "close_dialog"
2. Náº¿u Paint chÆ°a maximize (tháº¥y nÃºt maximize á»Ÿ gÃ³c trÃªn pháº£i) â†’ action_needed = "maximize"
3. Náº¿u Paint Ä‘Ã£ maximize vÃ  khÃ´ng cÃ³ dialog â†’ action_needed = "ready"
4. XÃ¡c Ä‘á»‹nh tá»a Ä‘á»™ CHÃNH XÃC cá»§a nÃºt cáº§n click
"""
    
    response = call_gemini_vision(prompt, [img])
    
    # Extract JSON
    json_str = response
    if '```json' in response:
        json_str = response.split('```json')[1].split('```')[0]
    elif '```' in response:
        json_str = response.split('```')[1].split('```')[0]
    
    return json.loads(json_str.strip())


def find_maximize_button_cv(screenshot_b64: str) -> Optional[Tuple[int, int]]:
    """
    TÃ¬m nÃºt Maximize báº±ng Computer Vision (heuristic)
    NÃºt maximize thÆ°á»ng á»Ÿ gÃ³c trÃªn pháº£i, trÆ°á»›c nÃºt X
    """
    img_data = base64.b64decode(screenshot_b64)
    img = cv2.imdecode(np.frombuffer(img_data, np.uint8), cv2.IMREAD_COLOR)
    
    height, width = img.shape[:2]
    
    # VÃ¹ng title bar (phÃ­a trÃªn cÃ¹ng)
    title_bar = img[0:50, width-200:width]
    
    # Convert to grayscale
    gray = cv2.cvtColor(title_bar, cv2.COLOR_BGR2GRAY)
    
    # TÃ¬m cÃ¡c cáº¡nh (buttons thÆ°á»ng cÃ³ viá»n)
    edges = cv2.Canny(gray, 50, 150)
    
    # TÃ¬m contours
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # Lá»c contours cÃ³ kÃ­ch thÆ°á»›c giá»‘ng button (20-40 pixels)
    buttons = []
    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        if 15 < w < 50 and 15 < h < 50:
            # Tá»a Ä‘á»™ tuyá»‡t Ä‘á»‘i
            abs_x = (width - 200) + x + w // 2
            abs_y = y + h // 2
            buttons.append((abs_x, abs_y))
    
    # NÃºt maximize thÆ°á»ng lÃ  nÃºt thá»© 2 tá»« pháº£i sang (trÆ°á»›c nÃºt X)
    if len(buttons) >= 2:
        buttons.sort(key=lambda p: p[0], reverse=True)
        return buttons[1]  # NÃºt thá»© 2
    
    # Fallback: Æ°á»›c lÆ°á»£ng vá»‹ trÃ­
    return (width - 90, 15)


def find_close_dialog_button_cv(screenshot_b64: str) -> Optional[Tuple[int, int]]:
    """
    TÃ¬m nÃºt X Ä‘á»ƒ Ä‘Ã³ng dialog
    """
    img_data = base64.b64decode(screenshot_b64)
    img = cv2.imdecode(np.frombuffer(img_data, np.uint8), cv2.IMREAD_COLOR)
    
    height, width = img.shape[:2]
    
    # Dialog thÆ°á»ng á»Ÿ giá»¯a mÃ n hÃ¬nh
    dialog_region = img[height//4:3*height//4, width//4:3*width//4]
    
    # TÃ¬m nÃºt X (thÆ°á»ng á»Ÿ gÃ³c trÃªn pháº£i cá»§a dialog)
    gray = cv2.cvtColor(dialog_region, cv2.COLOR_BGR2GRAY)
    
    # Template matching cho nÃºt X
    # Hoáº·c tÃ¬m vÃ¹ng tá»‘i (nÃºt X thÆ°á»ng cÃ³ mÃ u Ä‘á»/tá»‘i)
    
    # Fallback: Æ¯á»›c lÆ°á»£ng vá»‹ trÃ­ nÃºt X cá»§a dialog
    # ThÆ°á»ng á»Ÿ gÃ³c trÃªn pháº£i cá»§a dialog
    dialog_x = width // 2 + 300  # Giáº£ sá»­ dialog rá»™ng 600px
    dialog_y = height // 4 + 10
    
    return (dialog_x, dialog_y)


# ============ WINDOW MANAGEMENT AGENT ============

def window_setup_agent(state: StoryArtState) -> StoryArtState:
    """
    Agent setup Paint window - PURE VISION (NO HOTKEYS)
    """
    
    if state['mode'] == 'story_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("ğŸªŸ WINDOW SETUP AGENT (Pure Vision)")
    print("="*70)
    
    MAX_ATTEMPTS = 10
    
    try:
        for attempt in range(MAX_ATTEMPTS):
            print(f"\n   ğŸ”„ Attempt {attempt + 1}/{MAX_ATTEMPTS}")
            
            # 1. Chá»¥p mÃ n hÃ¬nh hiá»‡n táº¡i
            print("      ğŸ“¸ Capturing current screen...")
            screenshot_b64 = screenshot_to_base64()
            
            # 2. LLM phÃ¢n tÃ­ch tráº¡ng thÃ¡i
            print("      ğŸ§  LLM analyzing window state...")
            window_state = detect_window_state_with_llm(screenshot_b64)
            
            print(f"      ğŸ“Š State: {window_state.get('description', 'N/A')}")
            print(f"      ğŸ¯ Action needed: {window_state.get('action_needed')}")
            
            action = window_state.get('action_needed')
            
            # 3. Thá»±c hiá»‡n action tÆ°Æ¡ng á»©ng
            if action == "ready":
                print("      âœ… Paint is ready!")
                state['paint_window_ready'] = True
                state['paint_maximized'] = True
                state['paint_screenshot_b64'] = screenshot_b64
                break
                
            elif action == "close_dialog":
                print("      ğŸšª Closing dialog...")
                
                # Láº¥y vá»‹ trÃ­ nÃºt close tá»« LLM
                close_pos = window_state.get('close_button_position')
                
                if not close_pos:
                    # Fallback: DÃ¹ng CV
                    print("         ğŸ” CV finding close button...")
                    close_pos_tuple = find_close_dialog_button_cv(screenshot_b64)
                    if close_pos_tuple:
                        close_pos = {'x': close_pos_tuple[0], 'y': close_pos_tuple[1]}
                
                if close_pos:
                    print(f"         ğŸ–±ï¸  Clicking close at ({close_pos['x']}, {close_pos['y']})")
                    pyautogui.click(close_pos['x'], close_pos['y'])
                    time.sleep(1)
                else:
                    # Fallback cuá»‘i: ESC key (ngoáº¡i lá»‡ duy nháº¥t)
                    print("         âš ï¸  Using ESC as fallback...")
                    pyautogui.press('esc')
                    time.sleep(0.5)
                
            elif action == "maximize":
                print("      ğŸ“ Maximizing window...")
                
                # Láº¥y vá»‹ trÃ­ nÃºt maximize tá»« LLM
                max_pos = window_state.get('maximize_button_position')
                
                if not max_pos:
                    # Fallback: DÃ¹ng CV
                    print("         ğŸ” CV finding maximize button...")
                    max_pos_tuple = find_maximize_button_cv(screenshot_b64)
                    if max_pos_tuple:
                        max_pos = {'x': max_pos_tuple[0], 'y': max_pos_tuple[1]}
                
                if max_pos:
                    print(f"         ğŸ–±ï¸  Clicking maximize at ({max_pos['x']}, {max_pos['y']})")
                    pyautogui.click(max_pos['x'], max_pos['y'])
                    time.sleep(1)
                else:
                    # Fallback: Double-click title bar
                    print("         ğŸ”„ Double-clicking title bar...")
                    screen_width, screen_height = pyautogui.size()
                    pyautogui.doubleClick(screen_width // 2, 10)
                    time.sleep(1)
                
            elif action == "click_canvas":
                print("      ğŸ–±ï¸  Clicking canvas to focus...")
                screen_width, screen_height = pyautogui.size()
                pyautogui.click(screen_width // 2, screen_height // 2)
                time.sleep(0.5)
                
            else:
                print(f"      âš ï¸  Unknown action: {action}")
                time.sleep(1)
        
        if not state.get('paint_window_ready'):
            raise Exception("Failed to setup Paint window after max attempts")
        
        state['execution_log'].append("âœ“ Window Setup: Paint ready")
        
    except Exception as e:
        print(f"âŒ Window setup error: {e}")
        state['error'] = f"Window setup failed: {e}"
        traceback.print_exc()
    
    return state


# ============ AGENT 1: STORY WRITER (UNCHANGED) ============

def story_research_agent(state: StoryArtState) -> StoryArtState:
    """Agent tÃ¬m kiáº¿m thÃ´ng tin vá» nhÃ¢n váº­t"""
    
    if state['mode'] == 'art_only':
        print("\nâ© Skipping story research (art_only mode)")
        return state
    
    print("\n" + "="*70)
    print("ğŸ“š STORY RESEARCH AGENT")
    print("="*70)
    
    try:
        prompt = f"""
TÃ¬m kiáº¿m thÃ´ng tin vá» nhÃ¢n váº­t hoáº¡t hÃ¬nh "{state['character_name']}".

Tráº£ vá» JSON vá»›i format:
{{
    "name": "TÃªn nhÃ¢n váº­t",
    "origin": "Xuáº¥t xá»© (anime/cartoon nÃ o)",
    "personality": ["TÃ­nh cÃ¡ch 1", "TÃ­nh cÃ¡ch 2", ...],
    "appearance": "MÃ´ táº£ ngoáº¡i hÃ¬nh",
    "special_abilities": ["Kháº£ nÄƒng Ä‘áº·c biá»‡t 1", ...],
    "famous_quotes": ["CÃ¢u nÃ³i ná»•i tiáº¿ng 1", ...]
}}
"""
        
        response = call_gemini(prompt)
        
        # Extract JSON
        json_str = response
        if '```json' in response:
            json_str = response.split('```json')[1].split('```')[0]
        elif '```' in response:
            json_str = response.split('```')[1].split('```')[0]
        
        character_info = json.loads(json_str.strip())
        state['character_info'] = character_info
        
        print(f"\nâœ… Found info about: {character_info['name']}")
        print(f"   Origin: {character_info['origin']}")
        
        state['execution_log'].append(f"âœ“ Research: Found info about {character_info['name']}")
        
    except Exception as e:
        print(f"âŒ Research error: {e}")
        state['error'] = f"Research failed: {e}"
    
    return state


def story_outline_agent(state: StoryArtState) -> StoryArtState:
    """Agent táº¡o dÃ n Ã½ truyá»‡n"""
    
    if state['mode'] == 'art_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("ğŸ“ STORY OUTLINE AGENT")
    print("="*70)
    
    try:
        char_info = state['character_info']
        
        prompt = f"""
Táº¡o dÃ n Ã½ cho má»™t cÃ¢u chuyá»‡n ngáº¯n vá» {char_info['name']}.

THÃ”NG TIN NHÃ‚N Váº¬T:
- Xuáº¥t xá»©: {char_info['origin']}
- TÃ­nh cÃ¡ch: {', '.join(char_info['personality'])}

CHá»¦ Äá»€: {state['story_theme']}
Äá»˜ DÃ€I: {state['story_length']} tá»«

JSON FORMAT:
{{
    "title": "TiÃªu Ä‘á» háº¥p dáº«n",
    "setting": "Bá»‘i cáº£nh",
    "act1": "Má»Ÿ Ä‘áº§u",
    "act2": "PhÃ¡t triá»ƒn",
    "act3": "Káº¿t thÃºc",
    "moral": "BÃ i há»c"
}}
"""
        
        response = call_gemini(prompt)
        
        json_str = response
        if '```json' in response:
            json_str = response.split('```json')[1].split('```')[0]
        elif '```' in response:
            json_str = response.split('```')[1].split('```')[0]
        
        outline = json.loads(json_str.strip())
        state['story_outline'] = outline
        
        print(f"\nâœ… Outline: {outline['title']}")
        state['execution_log'].append("âœ“ Outline created")
        
    except Exception as e:
        print(f"âŒ Outline error: {e}")
        state['error'] = f"Outline failed: {e}"
    
    return state


def story_writer_agent(state: StoryArtState) -> StoryArtState:
    """Agent viáº¿t ná»™i dung truyá»‡n"""
    
    if state['mode'] == 'art_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("âœï¸ STORY WRITER AGENT")
    print("="*70)
    
    try:
        char_info = state['character_info']
        outline = state['story_outline']
        
        prompt = f"""
Viáº¿t má»™t cÃ¢u chuyá»‡n hoÃ n chá»‰nh vá» {char_info['name']}.

TIÃŠU Äá»€: {outline['title']}
DÃ€N Ã:
- Má»Ÿ Ä‘áº§u: {outline['act1']}
- PhÃ¡t triá»ƒn: {outline['act2']}
- Káº¿t thÃºc: {outline['act3']}

YÃŠU Cáº¦U:
- Äá»™ dÃ i: {state['story_length']} tá»«
- NgÃ´n ngá»¯: Tiáº¿ng Viá»‡t, sinh Ä‘á»™ng
- CÃ³ thoáº¡i trá»±c tiáº¿p

Chá»‰ viáº¿t ná»™i dung truyá»‡n.
"""
        
        print("   ğŸ¤– AI Ä‘ang viáº¿t truyá»‡n...")
        response = call_gemini(prompt)
        
        story_content = f"""
{'='*70}
{outline['title'].upper()}
{'='*70}

{response.strip()}

{'='*70}
BÃ i há»c: {outline['moral']}
{'='*70}
"""
        
        state['story_content'] = story_content
        
        word_count = len(response.split())
        print(f"\nâœ… Story written: {word_count} words")
        state['execution_log'].append(f"âœ“ Story: {word_count} words")
        
    except Exception as e:
        print(f"âŒ Writer error: {e}")
        state['error'] = f"Writer failed: {e}"
    
    return state


def story_formatter_agent(state: StoryArtState) -> StoryArtState:
    """Agent má»Ÿ Notepad vÃ  ghi truyá»‡n - DÃ™NG MOUSE CLICK"""
    
    if state['mode'] == 'art_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("ğŸ’¾ STORY FORMATTER AGENT")
    print("="*70)
    
    try:
        # 1. Má»Ÿ Notepad
        print("   ğŸ“ Opening Notepad...")
        subprocess.Popen(['notepad'])
        time.sleep(2)
        
        # 2. Maximize báº±ng double-click title bar (KHÃ”NG DÃ™NG HOTKEY)
        print("   ğŸ“ Maximizing Notepad...")
        screen_width, screen_height = pyautogui.size()
        pyautogui.doubleClick(screen_width // 2, 10)
        time.sleep(1)
        
        # 3. Paste ná»™i dung
        print("   âŒ¨ï¸  Pasting story content...")
        pyperclip.copy(state['story_content'])
        pyautogui.hotkey('ctrl', 'v')  # Ctrl+V lÃ  OK (khÃ´ng pháº£i Windows hotkey)
        time.sleep(1)
        
        # 4. Save file báº±ng menu click (KHÃ”NG DÃ™NG Ctrl+S)
        print("   ğŸ’¾ Saving file...")
        
        # Click vÃ o File menu
        pyautogui.click(15, 30)  # Vá»‹ trÃ­ File menu
        time.sleep(0.5)
        
        # Click vÃ o Save
        pyautogui.click(15, 80)  # Vá»‹ trÃ­ Save
        time.sleep(1)
        
        # Nháº­p tÃªn file
        char_name = state['character_name'].replace(' ', '_')
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"story_{char_name}_{timestamp}.txt"
        
        pyperclip.copy(filename)
        pyautogui.hotkey('ctrl', 'a')
        time.sleep(0.2)
        pyautogui.hotkey('ctrl', 'v')
        time.sleep(0.5)
        
        pyautogui.press('enter')
        time.sleep(0.5)
        
        state['story_file_path'] = filename
        
        print(f"\nâœ… Story saved: {filename}")
        state['execution_log'].append(f"âœ“ Saved: {filename}")
        
        # ÄÃ³ng Notepad báº±ng click nÃºt X
        print("   ğŸšª Closing Notepad...")
        pyautogui.click(screen_width - 15, 10)
        time.sleep(1)
        
    except Exception as e:
        print(f"âŒ Formatter error: {e}")
        state['error'] = f"Formatter failed: {e}"
    
    return state


# ============ AGENT 2: ART CREATOR ============

def art_preparation_agent(state: StoryArtState) -> StoryArtState:
    """Agent chuáº©n bá»‹ áº£nh tham kháº£o vÃ  má»Ÿ Paint - NO HOTKEYS"""
    
    if state['mode'] == 'story_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("ğŸ¨ ART PREPARATION AGENT")
    print("="*70)
    
    IMAGE_FOLDER = "images"
    char_name = state['character_name'].replace(' ', '_').lower()
    REFERENCE_IMAGE_PATH = os.path.join(IMAGE_FOLDER, f"{char_name}.jpg")
    
    try:
        # 1. Kiá»ƒm tra áº£nh tham kháº£o
        if not os.path.exists(REFERENCE_IMAGE_PATH):
            REFERENCE_IMAGE_PATH = os.path.join(IMAGE_FOLDER, f"{char_name}.png")
            
            if not os.path.exists(REFERENCE_IMAGE_PATH):
                print(f"\nâš ï¸  KhÃ´ng tÃ¬m tháº¥y áº£nh: {REFERENCE_IMAGE_PATH}")
                
                import webbrowser
                search_url = f"https://www.google.com/search?q={state['character_name']}+simple+drawing&tbm=isch"
                webbrowser.open(search_url)
                
                input("\n   â¸ï¸  Táº£i áº£nh vÃ  lÆ°u vÃ o images/, nháº¥n Enter...")
                
                if not os.path.exists(REFERENCE_IMAGE_PATH):
                    raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y: {REFERENCE_IMAGE_PATH}")
        
        print(f"   âœ… Found: {REFERENCE_IMAGE_PATH}")
        
        # 2. ÄÆ¡n giáº£n hÃ³a áº£nh
        print("   ğŸ–¼ï¸  Simplifying image...")
        simplified_path = simplify_image_for_drawing(REFERENCE_IMAGE_PATH)
        
        # 3. Load áº£nh vÃ o state
        state['reference_image_b64'] = image_to_base64(simplified_path)
        
        # 4. ÄÃ³ng Paint cÅ© báº±ng taskkill
        print("\n   ğŸ§¹ Closing old Paint...")
        try:
            subprocess.run(['taskkill', '/F', '/IM', 'mspaint.exe'], 
                          capture_output=True, 
                          timeout=3)
            time.sleep(1)
        except:
            pass
        
        # 5. Má»Ÿ Paint má»›i
        print("   ğŸ¨ Opening Paint...")
        subprocess.Popen(['mspaint'])
        time.sleep(3)
        
        state['execution_log'].append("âœ“ Preparation: Image ready, Paint opened")
        
    except Exception as e:
        print(f"âŒ Preparation error: {e}")
        state['error'] = f"Preparation failed: {e}"
        traceback.print_exc()
    
    return state


def detect_canvas_area(img_cv: np.ndarray) -> Dict:
    """TÃ¬m vÃ¹ng canvas (vÃ¹ng tráº¯ng lá»›n nháº¥t) trong Paint"""
    print("   ğŸ” Detecting canvas area...")
    
    gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
    _, binary = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY)
    
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if not contours:
        raise Exception("Cannot find canvas area!")
    
    canvas_contour = max(contours, key=cv2.contourArea)
    x, y, w, h = cv2.boundingRect(canvas_contour)
    
    margin = 20
    canvas = {
        'x': x + margin,
        'y': y + margin,
        'width': w - 2*margin,
        'height': h - 2*margin
    }
    
    print(f"   âœ… Canvas: ({canvas['x']}, {canvas['y']}) - {canvas['width']}x{canvas['height']}")
    
    return canvas


def art_cv_analyzer_agent(state: StoryArtState) -> StoryArtState:
    """Agent phÃ¢n tÃ­ch giao diá»‡n Paint báº±ng Computer Vision"""
    
    if state['mode'] == 'story_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("ğŸ”¬ COMPUTER VISION ANALYSIS")
    print("="*70)
    
    try:
        # Decode screenshot
        img_data = base64.b64decode(state['paint_screenshot_b64'])
        img_pil = Image.open(BytesIO(img_data))
        img_cv = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
        
        screen_height, screen_width = img_cv.shape[:2]
        print(f"   ğŸ“ Screen: {screen_width}x{screen_height}")
        
        # 1. Detect Canvas
        canvas_area = detect_canvas_area(img_cv)
        state['canvas_area'] = canvas_area
        
        # 2. Detect Colors & Tools báº±ng LLM Vision
        print("\n   ğŸ§  LLM detecting tools and colors...")
        
        prompt = """
PhÃ¢n tÃ­ch giao diá»‡n Paint vÃ  tráº£ vá» JSON:

{{
  "tool_positions": {{
    "pencil": {{"x": 334, "y": 65}},
    "brush": {{"x": 350, "y": 81}},
    "fill": {{"x": 306, "y": 81}},
    "eraser": {{"x": 290, "y": 65}},
    "color_picker": {{"x": 274, "y": 81}},
    "text": {{"x": 386, "y": 65}}, 
    "line": {{"x": 370, "y": 65}},
    "curve": {{"x": 386, "y": 81}},
    "rectangle": {{"x": 418, "y": 65}},
    "polygon": {{"x": 434, "y": 65}},
    "ellipse": {{"x": 402, "y": 81}},
    "rounded_rectangle": {{"x": 450, "y": 65}}
  }},
  "color_positions": {{
    "black": {{"x": 573, "y": 63}},
    "white": {{"x": 619, "y": 99}},
    "gray": {{"x": 589, "y": 63}},
    "red": {{"x": 638, "y": 63}},
    "orange": {{"x": 654, "y": 63}},
    "yellow": {{"x": 692, "y": 63}},
    "green": {{"x": 710, "y": 63}},
    "blue": {{"x": 728, "y": 63}},
    "purple": {{"x": 746, "y": 63}},
    "brown": {{"x": 670, "y": 63}}
  }},
  "other_buttons": {{
    "size": {{"x": 48, "y": 133}},
    "outline": {{"x": 244, "y": 81}}
  }}
}}

YÃŠU Cáº¦U:
- XÃ¡c Ä‘á»‹nh tá»a Ä‘á»™ CHÃNH XÃC cá»§a Tá»ªNG tool trong toolbar
- XÃ¡c Ä‘á»‹nh tá»a Ä‘á»™ CHÃNH XÃC cá»§a Tá»ªNG mÃ u trong color palette
- Tá»a Ä‘á»™ pháº£i lÃ  pixel tuyá»‡t Ä‘á»‘i trÃªn mÃ n hÃ¬nh
"""
        
        img_pil_small = img_pil.copy()
        img_pil_small.thumbnail((1200, 1200), Image.Resampling.LANCZOS)
        
        response = call_gemini_vision(prompt, [img_pil_small])
        
        # Extract JSON
        json_str = response
        if '```json' in response:
            json_str = response.split('```json')[1].split('```')[0]
        elif '```' in response:
            json_str = response.split('```')[1].split('```')[0]
        
        detection = json.loads(json_str.strip())
        
        state['tool_positions'] = detection.get('tool_positions', {})
        state['color_positions'] = detection.get('color_positions', {})
        
        print(f"\n   âœ… Detected {len(state['tool_positions'])} tools")
        print(f"   âœ… Detected {len(state['color_positions'])} colors")
        
        state['execution_log'].append("âœ“ CV Analysis: Interface mapped")
        
    except Exception as e:
        print(f"âŒ CV Analysis error: {e}")
        state['error'] = f"CV Analysis failed: {e}"
        traceback.print_exc()
    
    return state


def art_planner_agent(state: StoryArtState) -> StoryArtState:
    """Agent táº¡o káº¿ hoáº¡ch váº½ ÄÆ N GIáº¢N"""
    
    if state['mode'] == 'story_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("ğŸ§  ART PLANNER AGENT")
    print("="*70)
    
    try:
        # Load reference image
        ref_img = Image.open(BytesIO(base64.b64decode(state['reference_image_b64'])))
        ref_img.thumbnail((800, 800), Image.Resampling.LANCZOS)
        
        canvas = state['canvas_area']
        
        prompt = f"""
Táº¡o káº¿ hoáº¡ch váº½ SIÃŠU ÄÆ N GIáº¢N cho nhÃ¢n váº­t "{state['character_name']}" trong Paint.

áº¢NH THAM KHáº¢O: áº¢nh Ä‘Ã£ Ä‘Æ°á»£c Ä‘Æ¡n giáº£n hÃ³a

THÃ”NG TIN CANVAS:
- Vá»‹ trÃ­: ({canvas['x']}, {canvas['y']})
- KÃ­ch thÆ°á»›c: {canvas['width']}x{canvas['height']}

TOOLS CÃ“ Sáº´N:
{json.dumps(list(state['tool_positions'].keys()), indent=2)}

COLORS CÃ“ Sáº´N:
{json.dumps(list(state['color_positions'].keys()), indent=2)}

Táº O Káº¾ HOáº CH Váº¼:
- CHá»ˆ 6-8 BÆ¯á»šC ÄÆ N GIáº¢N
- DÃ¹ng ellipse vÃ  rectangle Ä‘á»ƒ táº¡o hÃ¬nh cÆ¡ báº£n
- TÃ´ mÃ u 2-3 mÃ u chÃ­nh
- KHÃ”NG Váº¼ CHI TIáº¾T NHá»

JSON FORMAT:
{{
  "character_analysis": {{
    "main_shapes": ["head (ellipse)", "body (rectangle)", ...],
    "main_colors": ["yellow", "red", "black"],
    "complexity": "simple"
  }},
  "steps": [
    {{
      "step": 1,
      "description": "Váº½ Ä‘áº§u (ellipse lá»›n)",
      "tool": "ellipse",
      "color": "black",
      "action": "drag",
      "start_x": 600,
      "start_y": 300,
      "end_x": 800,
      "end_y": 450,
      "note": "Outline cá»§a Ä‘áº§u"
    }},
    {{
      "step": 2,
      "description": "TÃ´ mÃ u Ä‘áº§u",
      "tool": "fill",
      "color": "yellow",
      "action": "click",
      "click_x": 700,
      "click_y": 375,
      "note": "Fill mÃ u da/lÃ´ng"
    }},
    {{
      "step": 3,
      "description": "Váº½ thÃ¢n",
      "tool": "rectangle",
      "color": "black",
      "action": "drag",
      "start_x": 650,
      "start_y": 430,
      "end_x": 750,
      "end_y": 600,
      "note": "Outline cá»§a thÃ¢n"
    }}
  ]
}}

LÆ¯U Ã:
- Tá»a Ä‘á»™ pháº£i náº±m TRONG canvas: x âˆˆ [{canvas['x']}, {canvas['x'] + canvas['width']}], y âˆˆ [{canvas['y']}, {canvas['y'] + canvas['height']}]
- action = "drag" cho ellipse/rectangle/line (cáº§n start_x, start_y, end_x, end_y)
- action = "click" cho fill (chá»‰ cáº§n click_x, click_y)
- CHá»ˆ 6-8 BÆ¯á»šC
"""
        
        print("   ğŸ¤– AI creating simple drawing plan...")
        response = call_gemini_vision(prompt, [ref_img])
        
        # Extract JSON
        json_str = response
        if '```json' in response:
            json_str = response.split('```json')[1].split('```')[0]
        elif '```' in response:
            json_str = response.split('```')[1].split('```')[0]
        
        plan = json.loads(json_str.strip())
        
        state['drawing_steps'] = plan.get('steps', [])
        state['current_step'] = 0
        state['total_steps'] = len(state['drawing_steps'])
        
        print(f"\nâœ… Plan created:")
        print(f"   Character: {plan.get('character_analysis', {}).get('main_shapes', [])}")
        print(f"   Colors: {plan.get('character_analysis', {}).get('main_colors', [])}")
        print(f"   Total steps: {state['total_steps']}")
        
        # In ra cÃ¡c bÆ°á»›c
        for step in state['drawing_steps']:
            print(f"   Step {step['step']}: {step['description']}")
        
        state['execution_log'].append(f"âœ“ Plan: {state['total_steps']} steps")
        
    except Exception as e:
        print(f"âŒ Planner error: {e}")
        state['error'] = f"Planner failed: {e}"
        traceback.print_exc()
    
    return state


def safe_click_tool(tool_name: str, tool_positions: Dict, retry: int = 2) -> bool:
    """Click vÃ o tool vá»›i retry"""
    if tool_name not in tool_positions:
        print(f"      âš ï¸  Tool '{tool_name}' not found in positions")
        return False
    
    pos = tool_positions[tool_name]
    
    for attempt in range(retry):
        try:
            print(f"      ğŸ”§ Clicking {tool_name} at ({pos['x']}, {pos['y']})...")
            pyautogui.click(pos['x'], pos['y'])
            time.sleep(0.3)
            return True
        except Exception as e:
            print(f"         âš ï¸  Attempt {attempt+1} failed: {e}")
            time.sleep(0.2)
    
    return False


def safe_click_color(color_name: str, color_positions: Dict, retry: int = 2) -> bool:
    """Click vÃ o mÃ u vá»›i retry"""
    if color_name not in color_positions:
        print(f"      âš ï¸  Color '{color_name}' not found in positions")
        return False
    
    pos = color_positions[color_name]
    
    for attempt in range(retry):
        try:
            print(f"      ğŸ¨ Clicking {color_name} at ({pos['x']}, {pos['y']})...")
            pyautogui.click(pos['x'], pos['y'])
            time.sleep(0.3)
            return True
        except Exception as e:
            print(f"         âš ï¸  Attempt {attempt+1} failed: {e}")
            time.sleep(0.2)
    
    return False


def safe_drag(start_x: int, start_y: int, end_x: int, end_y: int, duration: float = 0.5):
    """Thá»±c hiá»‡n drag an toÃ n"""
    try:
        print(f"      âœï¸  Dragging from ({start_x},{start_y}) to ({end_x},{end_y})...")
        
        # Di chuyá»ƒn Ä‘áº¿n vá»‹ trÃ­ báº¯t Ä‘áº§u
        pyautogui.moveTo(start_x, start_y, duration=0.2)
        time.sleep(0.1)
        
        # Giá»¯ chuá»™t trÃ¡i vÃ  kÃ©o
        pyautogui.mouseDown(button='left')
        time.sleep(0.1)
        
        pyautogui.moveTo(end_x, end_y, duration=duration)
        time.sleep(0.1)
        
        pyautogui.mouseUp(button='left')
        time.sleep(0.2)
        
        return True
        
    except Exception as e:
        print(f"         âŒ Drag failed: {e}")
        # Äáº£m báº£o tháº£ chuá»™t náº¿u cÃ³ lá»—i
        try:
            pyautogui.mouseUp(button='left')
        except:
            pass
        return False


def art_executor_agent(state: StoryArtState) -> StoryArtState:
    """Agent thá»±c thi váº½ TOÃ€N Bá»˜ cÃ¡c bÆ°á»›c - PURE MOUSE"""
    
    if state['mode'] == 'story_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("âš™ï¸ ART EXECUTOR AGENT - FULL AUTO DRAWING")
    print("="*70)
    
    tool_positions = state['tool_positions']
    color_positions = state['color_positions']
    steps = state['drawing_steps']
    
    try:
        # Click vÃ o canvas trÆ°á»›c Ä‘á»ƒ focus
        canvas = state['canvas_area']
        canvas_center_x = canvas['x'] + canvas['width'] // 2
        canvas_center_y = canvas['y'] + canvas['height'] // 2
        
        print(f"\n   ğŸ–±ï¸  Focusing canvas at ({canvas_center_x}, {canvas_center_y})...")
        pyautogui.click(canvas_center_x, canvas_center_y)
        time.sleep(0.5)
        
        # Váº¼ TOÃ€N Bá»˜ KHÃ”NG Dá»ªNG
        for i, step_data in enumerate(steps):
            step_num = i + 1
            print(f"\n   [{step_num}/{len(steps)}] {step_data['description']}")
            
            tool = step_data.get('tool', 'ellipse')
            color = step_data.get('color', 'black')
            action = step_data.get('action', 'drag')
            
            # 1. Chá»n tool
            if not safe_click_tool(tool, tool_positions):
                print(f"      âš ï¸  Skipping step {step_num} - tool selection failed")
                continue
            
            # 2. Chá»n mÃ u
            if not safe_click_color(color, color_positions):
                print(f"      âš ï¸  Warning: color selection failed, continuing anyway...")
            
            # 3. Thá»±c hiá»‡n váº½
            if action == 'drag':
                sx = step_data.get('start_x', 600)
                sy = step_data.get('start_y', 300)
                ex = step_data.get('end_x', 800)
                ey = step_data.get('end_y', 450)
                
                if not safe_drag(sx, sy, ex, ey):
                    print(f"      âš ï¸  Step {step_num} drag failed")
                
            elif action == 'click':
                cx = step_data.get('click_x', 700)
                cy = step_data.get('click_y', 400)
                
                print(f"      ğŸ–±ï¸  Clicking at ({cx},{cy})...")
                pyautogui.click(cx, cy)
                time.sleep(0.3)
            
            time.sleep(0.5)
            
            print(f"      âœ… Step {step_num} done!")
            state['current_step'] = step_num
        
        # ÄÃ¡nh dáº¥u hoÃ n thÃ nh
        state['is_complete'] = True
        
        print(f"\n   ğŸ‰ ALL {len(steps)} STEPS COMPLETED!")
        state['execution_log'].append(f"âœ“ Drawing: {len(steps)} steps completed")
        
        # LÆ°u áº£nh cuá»‘i cÃ¹ng
        print("\n   ğŸ’¾ Saving final drawing...")
        time.sleep(1)
        
        char_name = state['character_name'].replace(' ', '_')
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"drawing_{char_name}_{timestamp}.png"
        
        # Chá»¥p mÃ n hÃ¬nh
        screenshot = pyautogui.screenshot()
        screenshot.save(filename)
        
        print(f"   âœ… Saved: {filename}")
        state['execution_log'].append(f"âœ“ Image: {filename}")
        
    except Exception as e:
        print(f"âŒ Executor error: {e}")
        state['error'] = f"Executor failed: {e}"
        traceback.print_exc()
    
    return state


# ============ BUILD GRAPH ============

def build_workflow(mode: str):
    """Build workflow dá»±a trÃªn mode"""
    workflow = StateGraph(StoryArtState)
    
    if mode == "story_only":
        # Chá»‰ viáº¿t truyá»‡n
        workflow.add_node("story_research", story_research_agent)
        workflow.add_node("story_outline", story_outline_agent)
        workflow.add_node("story_writer", story_writer_agent)
        workflow.add_node("story_formatter", story_formatter_agent)
        
        workflow.set_entry_point("story_research")
        workflow.add_edge("story_research", "story_outline")
        workflow.add_edge("story_outline", "story_writer")
        workflow.add_edge("story_writer", "story_formatter")
        workflow.add_edge("story_formatter", END)
        
    elif mode == "art_only":
        # Chá»‰ váº½ tranh - PURE VISION WORKFLOW
        workflow.add_node("art_preparation", art_preparation_agent)
        workflow.add_node("window_setup", window_setup_agent)
        workflow.add_node("cv_analyzer", art_cv_analyzer_agent)
        workflow.add_node("art_planner", art_planner_agent)
        workflow.add_node("art_executor", art_executor_agent)
        
        workflow.set_entry_point("art_preparation")
        workflow.add_edge("art_preparation", "window_setup")
        workflow.add_edge("window_setup", "cv_analyzer")
        workflow.add_edge("cv_analyzer", "art_planner")
        workflow.add_edge("art_planner", "art_executor")
        workflow.add_edge("art_executor", END)
        
    else:  # full
        # Cáº£ 2
        workflow.add_node("story_research", story_research_agent)
        workflow.add_node("story_outline", story_outline_agent)
        workflow.add_node("story_writer", story_writer_agent)
        workflow.add_node("story_formatter", story_formatter_agent)
        workflow.add_node("art_preparation", art_preparation_agent)
        workflow.add_node("window_setup", window_setup_agent)
        workflow.add_node("cv_analyzer", art_cv_analyzer_agent)
        workflow.add_node("art_planner", art_planner_agent)
        workflow.add_node("art_executor", art_executor_agent)
        
        workflow.set_entry_point("story_research")
        workflow.add_edge("story_research", "story_outline")
        workflow.add_edge("story_outline", "story_writer")
        workflow.add_edge("story_writer", "story_formatter")
        workflow.add_edge("story_formatter", "art_preparation")
        workflow.add_edge("art_preparation", "window_setup")
        workflow.add_edge("window_setup", "cv_analyzer")
        workflow.add_edge("cv_analyzer", "art_planner")
        workflow.add_edge("art_planner", "art_executor")
        workflow.add_edge("art_executor", END)
    
    return workflow.compile()


# ============ MAIN ============

def main():
    """Main function"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          ğŸ¨ğŸ“ ANIME STORY STUDIO V5                       â•‘
â•‘          Pure Computer Vision - No Windows Hotkeys        â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    print("\nğŸ“‹ MENU:")
    print("  1. Viáº¿t truyá»‡n + Váº½ nhÃ¢n váº­t (Full Auto)")
    print("  2. Chá»‰ viáº¿t truyá»‡n (Story Only)")
    print("  3. Chá»‰ váº½ tranh (Art Only) - PURE VISION")
    print("  0. ThoÃ¡t")
    
    choice = input("\nğŸ‘‰ Chá»n chá»©c nÄƒng (1-3): ").strip()
    
    if choice == '0':
        print("ğŸ‘‹ Goodbye!")
        return
    
    # XÃ¡c Ä‘á»‹nh mode
    mode_map = {
        '1': 'full',
        '2': 'story_only',
        '3': 'art_only'
    }
    mode = mode_map.get(choice, 'full')
    
    # Input thÃ´ng tin
    print("\n" + "="*60)
    character_name = input("ğŸ­ Nháº­p tÃªn nhÃ¢n váº­t (VD: Doraemon, Pikachu, Luffy): ").strip()
    
    if not character_name:
        character_name = "Doraemon"
        print(f"   âš ï¸  Sá»­ dá»¥ng máº·c Ä‘á»‹nh: {character_name}")
    
    story_theme = "adventure"
    story_length = 200
    
    if mode in ['full', 'story_only']:
        story_theme = input("ğŸ“– Chá»§ Ä‘á» truyá»‡n (adventure/friendship/funny): ").strip() or "adventure"
        story_length_input = input("ğŸ“ Äá»™ dÃ i truyá»‡n (sá»‘ tá»«, VD: 500): ").strip()
        try:
            story_length = int(story_length_input)
        except:
            story_length = 200
    
    # Khá»Ÿi táº¡o state
    initial_state = StoryArtState(
        character_name=character_name,
        story_theme=story_theme,
        story_length=story_length,
        mode=mode,
        character_info={},
        story_outline={},
        story_content="",
        story_file_path="",
        reference_image_b64="",
        paint_screenshot_b64="",
        tool_positions={},
        color_positions={},
        canvas_area={},
        drawing_steps=[],
        current_step=0,
        total_steps=0,
        paint_window_ready=False,
        paint_maximized=False,
        execution_log=[],
        is_complete=False,
        error=""
    )
    
    # Build vÃ  cháº¡y workflow
    print("\nğŸš€ Starting PURE VISION automation...")
    print("âš ï¸  Script sáº½ Ä‘iá»u khiá»ƒn chuá»™t (KHÃ”NG DÃ™NG PHÃM Táº®T WINDOWS)!")
    print("âš ï¸  KHÃ”NG DI CHUYá»‚N CHUá»˜T trong quÃ¡ trÃ¬nh váº½!")
    print("\nâ³ Báº¯t Ä‘áº§u sau 3 giÃ¢y...")
    time.sleep(3)
    
    graph = build_workflow(mode)
    
    try:
        final_state = graph.invoke(initial_state)
        
        # Summary
        print("\n" + "="*70)
        print("ğŸ“Š EXECUTION SUMMARY")
        print("="*70)
        
        if final_state.get('error'):
            print(f"âŒ Error: {final_state['error']}")
        else:
            print("âœ… Status: Completed!")
            
            if final_state.get('story_file_path'):
                print(f"ğŸ“ Story: {final_state['story_file_path']}")
            
            if final_state.get('is_complete'):
                print(f"ğŸ¨ Drawing: {final_state['total_steps']} steps completed")
        
        print("\nğŸ“œ Execution Log:")
        for log in final_state.get('execution_log', []):
            print(f"  {log}")
        
    except Exception as e:
        print(f"\nğŸ’¥ Critical error: {e}")
        traceback.print_exc()
    
    print("\n" + "="*70)
    print("ğŸ¤– Automation finished!")
    print("="*70)


if __name__ == "__main__":
    main()
