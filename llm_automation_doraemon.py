"""
======================================================================================
ANIME STORY STUDIO V5 - PURE COMPUTER VISION (NO HOTKEYS)
100% Mouse Click - Kh√¥ng d√πng ph√≠m t·∫Øt Windows
======================================================================================
"""

import os
import time
import base64
import json
import subprocess
from io import BytesIO
from datetime import datetime
from dotenv import load_dotenv
from PIL import Image, ImageDraw
import pyautogui
import cv2
import numpy as np
from typing import TypedDict, List, Dict, Tuple, Optional
from langgraph.graph import StateGraph, END
import google.generativeai as genai
import traceback
import pyperclip

# Load environment
load_dotenv()
genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))

# T·∫Øt fail-safe
pyautogui.FAILSAFE = False
pyautogui.PAUSE = 0.05

# ============ SHARED STATE ============

class StoryArtState(TypedDict):
    """State chung cho c·∫£ 2 agents"""
    # User Input
    character_name: str
    story_theme: str
    story_length: int
    mode: str
    
    # Story Writer State
    character_info: Dict
    story_outline: Dict
    story_content: str
    story_file_path: str
    
    # Art Creator State
    reference_image_b64: str
    paint_screenshot_b64: str
    tool_positions: Dict
    color_positions: Dict
    canvas_area: Dict
    drawing_steps: List[Dict]
    current_step: int
    total_steps: int
    
    # Window Management State
    paint_window_ready: bool
    paint_maximized: bool
    
    # Shared
    execution_log: List[str]
    is_complete: bool
    error: str


# ============ UTILITY FUNCTIONS ============

def screenshot_to_base64(region=None) -> str:
    """Ch·ª•p m√†n h√¨nh v√† convert sang base64"""
    if region:
        screenshot = pyautogui.screenshot(region=region)
    else:
        screenshot = pyautogui.screenshot()
    buffered = BytesIO()
    screenshot.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode()

def image_to_base64(image_path: str) -> str:
    """Convert ·∫£nh file sang base64"""
    with open(image_path, 'rb') as f:
        return base64.b64encode(f.read()).decode()

def call_gemini(prompt: str) -> str:
    """G·ªçi Gemini text-only"""
    model = genai.GenerativeModel('gemini-2.0-flash-exp')
    response = model.generate_content(prompt)
    return response.text

def call_gemini_vision(prompt: str, images: List[Image.Image]) -> str:
    """G·ªçi Gemini v·ªõi vision"""
    model = genai.GenerativeModel('gemini-2.0-flash-exp')
    content = images + [prompt]
    response = model.generate_content(content)
    return response.text

def simplify_image_for_drawing(image_path: str, output_path: str = "simplified.png"):
    """ƒê∆°n gi·∫£n h√≥a ·∫£nh th√†nh d·∫°ng cartoon/sketch d·ªÖ v·∫Ω"""
    img = cv2.imread(image_path)
    
    # Resize v·ªÅ k√≠ch th∆∞·ªõc v·ª´a ph·∫£i
    height, width = img.shape[:2]
    max_size = 300
    if max(height, width) > max_size:
        scale = max_size / max(height, width)
        img = cv2.resize(img, None, fx=scale, fy=scale)
    
    # Chuy·ªÉn sang cartoon style
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray, 5)
    
    # Detect edges
    edges = cv2.adaptiveThreshold(
        gray, 255, 
        cv2.ADAPTIVE_THRESH_MEAN_C, 
        cv2.THRESH_BINARY, 
        9, 9
    )
    
    # Smooth colors
    color = cv2.bilateralFilter(img, 9, 250, 250)
    
    # Combine
    cartoon = cv2.bitwise_and(color, color, mask=edges)
    
    cv2.imwrite(output_path, cartoon)
    print(f"   ‚úÖ Simplified image saved: {output_path}")
    return output_path


# ============ COMPUTER VISION MODULE ============

def find_button_by_template(screenshot_b64: str, button_name: str) -> Optional[Tuple[int, int]]:
    """
    T√¨m button b·∫±ng template matching
    """
    # Decode screenshot
    img_data = base64.b64decode(screenshot_b64)
    img = cv2.imdecode(np.frombuffer(img_data, np.uint8), cv2.IMREAD_COLOR)
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    
    # Template path (c·∫ßn chu·∫©n b·ªã tr∆∞·ªõc)
    template_path = f"templates/{button_name}.png"
    
    if not os.path.exists(template_path):
        return None
    
    template = cv2.imread(template_path, cv2.IMREAD_GRAYSCALE)
    
    # Template matching
    result = cv2.matchTemplate(gray, template, cv2.TM_CCOEFF_NORMED)
    min_val, max_val, min_loc, max_loc = cv2.minMaxLoc(result)
    
    if max_val > 0.7:  # Threshold
        # Tr·∫£ v·ªÅ t√¢m c·ªßa button
        h, w = template.shape
        center_x = max_loc[0] + w // 2
        center_y = max_loc[1] + h // 2
        return (center_x, center_y)
    
    return None


def detect_window_state_with_llm(screenshot_b64: str) -> Dict:
    """
    D√πng LLM ƒë·ªÉ ph√¢n t√≠ch tr·∫°ng th√°i window hi·ªán t·∫°i
    """
    img = Image.open(BytesIO(base64.b64decode(screenshot_b64)))
    img.thumbnail((1200, 1200), Image.Resampling.LANCZOS)
    
    prompt = """
Ph√¢n t√≠ch m√†n h√¨nh hi·ªán t·∫°i v√† tr·∫£ v·ªÅ JSON:

{{
  "window_type": "paint" | "dialog" | "desktop" | "other",
  "is_maximized": true/false,
  "has_dialog": true/false,
  "dialog_type": "share" | "save" | "close_confirm" | null,
  "action_needed": "maximize" | "close_dialog" | "click_canvas" | "ready",
  "maximize_button_position": {{"x": 1234, "y": 56}} or null,
  "close_button_position": {{"x": 1234, "y": 56}} or null,
  "canvas_visible": true/false,
  "description": "M√¥ t·∫£ ng·∫Øn g·ªçn"
}}

QUY T·∫ÆC:
1. N·∫øu th·∫•y dialog "Share" ‚Üí action_needed = "close_dialog"
2. N·∫øu Paint ch∆∞a maximize (th·∫•y n√∫t maximize ·ªü g√≥c tr√™n ph·∫£i) ‚Üí action_needed = "maximize"
3. N·∫øu Paint ƒë√£ maximize v√† kh√¥ng c√≥ dialog ‚Üí action_needed = "ready"
4. X√°c ƒë·ªãnh t·ªça ƒë·ªô CH√çNH X√ÅC c·ªßa n√∫t c·∫ßn click
"""
    
    response = call_gemini_vision(prompt, [img])
    
    # Extract JSON
    json_str = response
    if '```json' in response:
        json_str = response.split('```json')[1].split('```')[0]
    elif '```' in response:
        json_str = response.split('```')[1].split('```')[0]
    
    return json.loads(json_str.strip())


def find_maximize_button_cv(screenshot_b64: str) -> Optional[Tuple[int, int]]:
    """
    T√¨m n√∫t Maximize b·∫±ng Computer Vision (heuristic)
    N√∫t maximize th∆∞·ªùng ·ªü g√≥c tr√™n ph·∫£i, tr∆∞·ªõc n√∫t X
    """
    img_data = base64.b64decode(screenshot_b64)
    img = cv2.imdecode(np.frombuffer(img_data, np.uint8), cv2.IMREAD_COLOR)
    
    height, width = img.shape[:2]
    
    # V√πng title bar (ph√≠a tr√™n c√πng)
    title_bar = img[0:50, width-200:width]
    
    # Convert to grayscale
    gray = cv2.cvtColor(title_bar, cv2.COLOR_BGR2GRAY)
    
    # T√¨m c√°c c·∫°nh (buttons th∆∞·ªùng c√≥ vi·ªÅn)
    edges = cv2.Canny(gray, 50, 150)
    
    # T√¨m contours
    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    # L·ªçc contours c√≥ k√≠ch th∆∞·ªõc gi·ªëng button (20-40 pixels)
    buttons = []
    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        if 15 < w < 50 and 15 < h < 50:
            # T·ªça ƒë·ªô tuy·ªát ƒë·ªëi
            abs_x = (width - 200) + x + w // 2
            abs_y = y + h // 2
            buttons.append((abs_x, abs_y))
    
    # N√∫t maximize th∆∞·ªùng l√† n√∫t th·ª© 2 t·ª´ ph·∫£i sang (tr∆∞·ªõc n√∫t X)
    if len(buttons) >= 2:
        buttons.sort(key=lambda p: p[0], reverse=True)
        return buttons[1]  # N√∫t th·ª© 2
    
    # Fallback: ∆∞·ªõc l∆∞·ª£ng v·ªã tr√≠
    return (width - 90, 15)


def find_close_dialog_button_cv(screenshot_b64: str) -> Optional[Tuple[int, int]]:
    """
    T√¨m n√∫t X ƒë·ªÉ ƒë√≥ng dialog
    """
    img_data = base64.b64decode(screenshot_b64)
    img = cv2.imdecode(np.frombuffer(img_data, np.uint8), cv2.IMREAD_COLOR)
    
    height, width = img.shape[:2]
    
    # Dialog th∆∞·ªùng ·ªü gi·ªØa m√†n h√¨nh
    dialog_region = img[height//4:3*height//4, width//4:3*width//4]
    
    # T√¨m n√∫t X (th∆∞·ªùng ·ªü g√≥c tr√™n ph·∫£i c·ªßa dialog)
    gray = cv2.cvtColor(dialog_region, cv2.COLOR_BGR2GRAY)
    
    # Template matching cho n√∫t X
    # Ho·∫∑c t√¨m v√πng t·ªëi (n√∫t X th∆∞·ªùng c√≥ m√†u ƒë·ªè/t·ªëi)
    
    # Fallback: ∆Ø·ªõc l∆∞·ª£ng v·ªã tr√≠ n√∫t X c·ªßa dialog
    # Th∆∞·ªùng ·ªü g√≥c tr√™n ph·∫£i c·ªßa dialog
    dialog_x = width // 2 + 300  # Gi·∫£ s·ª≠ dialog r·ªông 600px
    dialog_y = height // 4 + 10
    
    return (dialog_x, dialog_y)


# ============ WINDOW MANAGEMENT AGENT ============

def window_setup_agent(state: StoryArtState) -> StoryArtState:
    """
    Agent setup Paint window - PURE VISION (NO HOTKEYS)
    """
    
    if state['mode'] == 'story_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("ü™ü WINDOW SETUP AGENT (Pure Vision)")
    print("="*70)
    
    MAX_ATTEMPTS = 10
    
    try:
        for attempt in range(MAX_ATTEMPTS):
            print(f"\n   üîÑ Attempt {attempt + 1}/{MAX_ATTEMPTS}")
            
            # 1. Ch·ª•p m√†n h√¨nh hi·ªán t·∫°i
            print("      üì∏ Capturing current screen...")
            screenshot_b64 = screenshot_to_base64()
            
            # 2. LLM ph√¢n t√≠ch tr·∫°ng th√°i
            print("      üß† LLM analyzing window state...")
            window_state = detect_window_state_with_llm(screenshot_b64)
            
            print(f"      üìä State: {window_state.get('description', 'N/A')}")
            print(f"      üéØ Action needed: {window_state.get('action_needed')}")
            
            action = window_state.get('action_needed')
            
            # 3. Th·ª±c hi·ªán action t∆∞∆°ng ·ª©ng
            if action == "ready":
                print("      ‚úÖ Paint is ready!")
                state['paint_window_ready'] = True
                state['paint_maximized'] = True
                state['paint_screenshot_b64'] = screenshot_b64
                break
                
            elif action == "close_dialog":
                print("      üö™ Closing dialog...")
                
                # L·∫•y v·ªã tr√≠ n√∫t close t·ª´ LLM
                close_pos = window_state.get('close_button_position')
                
                if not close_pos:
                    # Fallback: D√πng CV
                    print("         üîç CV finding close button...")
                    close_pos_tuple = find_close_dialog_button_cv(screenshot_b64)
                    if close_pos_tuple:
                        close_pos = {'x': close_pos_tuple[0], 'y': close_pos_tuple[1]}
                
                if close_pos:
                    print(f"         üñ±Ô∏è  Clicking close at ({close_pos['x']}, {close_pos['y']})")
                    pyautogui.click(close_pos['x'], close_pos['y'])
                    time.sleep(1)
                else:
                    # Fallback cu·ªëi: ESC key (ngo·∫°i l·ªá duy nh·∫•t)
                    print("         ‚ö†Ô∏è  Using ESC as fallback...")
                    pyautogui.press('esc')
                    time.sleep(0.5)
                
            elif action == "maximize":
                print("      üìê Maximizing window...")
                
                # L·∫•y v·ªã tr√≠ n√∫t maximize t·ª´ LLM
                max_pos = window_state.get('maximize_button_position')
                
                if not max_pos:
                    # Fallback: D√πng CV
                    print("         üîç CV finding maximize button...")
                    max_pos_tuple = find_maximize_button_cv(screenshot_b64)
                    if max_pos_tuple:
                        max_pos = {'x': max_pos_tuple[0], 'y': max_pos_tuple[1]}
                
                if max_pos:
                    print(f"         üñ±Ô∏è  Clicking maximize at ({max_pos['x']}, {max_pos['y']})")
                    pyautogui.click(max_pos['x'], max_pos['y'])
                    time.sleep(1)
                else:
                    # Fallback: Double-click title bar
                    print("         üîÑ Double-clicking title bar...")
                    screen_width, screen_height = pyautogui.size()
                    pyautogui.doubleClick(screen_width // 2, 10)
                    time.sleep(1)
                
            elif action == "click_canvas":
                print("      üñ±Ô∏è  Clicking canvas to focus...")
                screen_width, screen_height = pyautogui.size()
                pyautogui.click(screen_width // 2, screen_height // 2)
                time.sleep(0.5)
                
            else:
                print(f"      ‚ö†Ô∏è  Unknown action: {action}")
                time.sleep(1)
        
        if not state.get('paint_window_ready'):
            raise Exception("Failed to setup Paint window after max attempts")
        
        state['execution_log'].append("‚úì Window Setup: Paint ready")
        
    except Exception as e:
        print(f"‚ùå Window setup error: {e}")
        state['error'] = f"Window setup failed: {e}"
        traceback.print_exc()
    
    return state


# ============ AGENT 1: STORY WRITER (UNCHANGED) ============

def story_research_agent(state: StoryArtState) -> StoryArtState:
    """Agent t√¨m ki·∫øm th√¥ng tin v·ªÅ nh√¢n v·∫≠t"""
    
    if state['mode'] == 'art_only':
        print("\n‚è© Skipping story research (art_only mode)")
        return state
    
    print("\n" + "="*70)
    print("üìö STORY RESEARCH AGENT")
    print("="*70)
    
    try:
        prompt = f"""
T√¨m ki·∫øm th√¥ng tin v·ªÅ nh√¢n v·∫≠t ho·∫°t h√¨nh "{state['character_name']}".

Tr·∫£ v·ªÅ JSON v·ªõi format:
{{
    "name": "T√™n nh√¢n v·∫≠t",
    "origin": "Xu·∫•t x·ª© (anime/cartoon n√†o)",
    "personality": ["T√≠nh c√°ch 1", "T√≠nh c√°ch 2", ...],
    "appearance": "M√¥ t·∫£ ngo·∫°i h√¨nh",
    "special_abilities": ["Kh·∫£ nƒÉng ƒë·∫∑c bi·ªát 1", ...],
    "famous_quotes": ["C√¢u n√≥i n·ªïi ti·∫øng 1", ...]
}}
"""
        
        response = call_gemini(prompt)
        
        # Extract JSON
        json_str = response
        if '```json' in response:
            json_str = response.split('```json')[1].split('```')[0]
        elif '```' in response:
            json_str = response.split('```')[1].split('```')[0]
        
        character_info = json.loads(json_str.strip())
        state['character_info'] = character_info
        
        print(f"\n‚úÖ Found info about: {character_info['name']}")
        print(f"   Origin: {character_info['origin']}")
        
        state['execution_log'].append(f"‚úì Research: Found info about {character_info['name']}")
        
    except Exception as e:
        print(f"‚ùå Research error: {e}")
        state['error'] = f"Research failed: {e}"
    
    return state


def story_outline_agent(state: StoryArtState) -> StoryArtState:
    """Agent t·∫°o d√†n √Ω truy·ªán"""
    
    if state['mode'] == 'art_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("üìù STORY OUTLINE AGENT")
    print("="*70)
    
    try:
        char_info = state['character_info']
        
        prompt = f"""
T·∫°o d√†n √Ω cho m·ªôt c√¢u chuy·ªán ng·∫Øn v·ªÅ {char_info['name']}.

TH√îNG TIN NH√ÇN V·∫¨T:
- Xu·∫•t x·ª©: {char_info['origin']}
- T√≠nh c√°ch: {', '.join(char_info['personality'])}

CH·ª¶ ƒê·ªÄ: {state['story_theme']}
ƒê·ªò D√ÄI: {state['story_length']} t·ª´

JSON FORMAT:
{{
    "title": "Ti√™u ƒë·ªÅ h·∫•p d·∫´n",
    "setting": "B·ªëi c·∫£nh",
    "act1": "M·ªü ƒë·∫ßu",
    "act2": "Ph√°t tri·ªÉn",
    "act3": "K·∫øt th√∫c",
    "moral": "B√†i h·ªçc"
}}
"""
        
        response = call_gemini(prompt)
        
        json_str = response
        if '```json' in response:
            json_str = response.split('```json')[1].split('```')[0]
        elif '```' in response:
            json_str = response.split('```')[1].split('```')[0]
        
        outline = json.loads(json_str.strip())
        state['story_outline'] = outline
        
        print(f"\n‚úÖ Outline: {outline['title']}")
        state['execution_log'].append("‚úì Outline created")
        
    except Exception as e:
        print(f"‚ùå Outline error: {e}")
        state['error'] = f"Outline failed: {e}"
    
    return state


def story_writer_agent(state: StoryArtState) -> StoryArtState:
    """Agent vi·∫øt n·ªôi dung truy·ªán"""
    
    if state['mode'] == 'art_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("‚úçÔ∏è STORY WRITER AGENT")
    print("="*70)
    
    try:
        char_info = state['character_info']
        outline = state['story_outline']
        
        prompt = f"""
Vi·∫øt m·ªôt c√¢u chuy·ªán ho√†n ch·ªânh v·ªÅ {char_info['name']}.

TI√äU ƒê·ªÄ: {outline['title']}
D√ÄN √ù:
- M·ªü ƒë·∫ßu: {outline['act1']}
- Ph√°t tri·ªÉn: {outline['act2']}
- K·∫øt th√∫c: {outline['act3']}

Y√äU C·∫¶U:
- ƒê·ªô d√†i: {state['story_length']} t·ª´
- Ng√¥n ng·ªØ: Ti·∫øng Vi·ªát, sinh ƒë·ªông
- C√≥ tho·∫°i tr·ª±c ti·∫øp

Ch·ªâ vi·∫øt n·ªôi dung truy·ªán.
"""
        
        print("   ü§ñ AI ƒëang vi·∫øt truy·ªán...")
        response = call_gemini(prompt)
        
        story_content = f"""
{'='*70}
{outline['title'].upper()}
{'='*70}

{response.strip()}

{'='*70}
B√†i h·ªçc: {outline['moral']}
{'='*70}
"""
        
        state['story_content'] = story_content
        
        word_count = len(response.split())
        print(f"\n‚úÖ Story written: {word_count} words")
        state['execution_log'].append(f"‚úì Story: {word_count} words")
        
    except Exception as e:
        print(f"‚ùå Writer error: {e}")
        state['error'] = f"Writer failed: {e}"
    
    return state


def story_formatter_agent(state: StoryArtState) -> StoryArtState:
    """Agent m·ªü Notepad v√† ghi truy·ªán - D√ôNG MOUSE CLICK"""
    
    if state['mode'] == 'art_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("üíæ STORY FORMATTER AGENT")
    print("="*70)
    
    try:
        # 1. M·ªü Notepad
        print("   üìù Opening Notepad...")
        subprocess.Popen(['notepad'])
        time.sleep(2)
        
        # 2. Maximize b·∫±ng double-click title bar (KH√îNG D√ôNG HOTKEY)
        print("   üìê Maximizing Notepad...")
        screen_width, screen_height = pyautogui.size()
        pyautogui.doubleClick(screen_width // 2, 10)
        time.sleep(1)
        
        # 3. Paste n·ªôi dung
        print("   ‚å®Ô∏è  Pasting story content...")
        pyperclip.copy(state['story_content'])
        pyautogui.hotkey('ctrl', 'v')  # Ctrl+V l√† OK (kh√¥ng ph·∫£i Windows hotkey)
        time.sleep(1)
        
        # 4. Save file b·∫±ng menu click (KH√îNG D√ôNG Ctrl+S)
        print("   üíæ Saving file...")
        
        # Click v√†o File menu
        pyautogui.click(15, 30)  # V·ªã tr√≠ File menu
        time.sleep(0.5)
        
        # Click v√†o Save
        pyautogui.click(15, 80)  # V·ªã tr√≠ Save
        time.sleep(1)
        
        # Nh·∫≠p t√™n file
        char_name = state['character_name'].replace(' ', '_')
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"story_{char_name}_{timestamp}.txt"
        
        pyperclip.copy(filename)
        pyautogui.hotkey('ctrl', 'a')
        time.sleep(0.2)
        pyautogui.hotkey('ctrl', 'v')
        time.sleep(0.5)
        
        pyautogui.press('enter')
        time.sleep(0.5)
        
        state['story_file_path'] = filename
        
        print(f"\n‚úÖ Story saved: {filename}")
        state['execution_log'].append(f"‚úì Saved: {filename}")
        
        # ƒê√≥ng Notepad b·∫±ng click n√∫t X
        print("   üö™ Closing Notepad...")
        pyautogui.click(screen_width - 15, 10)
        time.sleep(1)
        
    except Exception as e:
        print(f"‚ùå Formatter error: {e}")
        state['error'] = f"Formatter failed: {e}"
    
    return state


# ============ AGENT 2: ART CREATOR ============

def art_preparation_agent(state: StoryArtState) -> StoryArtState:
    """Agent chu·∫©n b·ªã ·∫£nh tham kh·∫£o v√† m·ªü Paint - NO HOTKEYS"""
    
    if state['mode'] == 'story_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("üé® ART PREPARATION AGENT")
    print("="*70)
    
    IMAGE_FOLDER = "images"
    char_name = state['character_name'].replace(' ', '_').lower()
    REFERENCE_IMAGE_PATH = os.path.join(IMAGE_FOLDER, f"{char_name}.jpg")
    
    try:
        # 1. Ki·ªÉm tra ·∫£nh tham kh·∫£o
        if not os.path.exists(REFERENCE_IMAGE_PATH):
            REFERENCE_IMAGE_PATH = os.path.join(IMAGE_FOLDER, f"{char_name}.png")
            
            if not os.path.exists(REFERENCE_IMAGE_PATH):
                print(f"\n‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y ·∫£nh: {REFERENCE_IMAGE_PATH}")
                
                import webbrowser
                search_url = f"https://www.google.com/search?q={state['character_name']}+simple+drawing&tbm=isch"
                webbrowser.open(search_url)
                
                input("\n   ‚è∏Ô∏è  T·∫£i ·∫£nh v√† l∆∞u v√†o images/, nh·∫•n Enter...")
                
                if not os.path.exists(REFERENCE_IMAGE_PATH):
                    raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y: {REFERENCE_IMAGE_PATH}")
        
        print(f"   ‚úÖ Found: {REFERENCE_IMAGE_PATH}")
        
        # 2. ƒê∆°n gi·∫£n h√≥a ·∫£nh
        print("   üñºÔ∏è  Simplifying image...")
        simplified_path = simplify_image_for_drawing(REFERENCE_IMAGE_PATH)
        
        # 3. Load ·∫£nh v√†o state
        state['reference_image_b64'] = image_to_base64(simplified_path)
        
        # 4. ƒê√≥ng Paint c≈© b·∫±ng taskkill
        print("\n   üßπ Closing old Paint...")
        try:
            subprocess.run(['taskkill', '/F', '/IM', 'mspaint.exe'], 
                          capture_output=True, 
                          timeout=3)
            time.sleep(1)
        except:
            pass
        
        # 5. M·ªü Paint m·ªõi
        print("   üé® Opening Paint...")
        subprocess.Popen(['mspaint'])
        time.sleep(3)
        
        state['execution_log'].append("‚úì Preparation: Image ready, Paint opened")
        
    except Exception as e:
        print(f"‚ùå Preparation error: {e}")
        state['error'] = f"Preparation failed: {e}"
        traceback.print_exc()
    
    return state


def detect_canvas_area(img_cv: np.ndarray) -> Dict:
    """T√¨m v√πng canvas (v√πng tr·∫Øng l·ªõn nh·∫•t) trong Paint"""
    print("   üîç Detecting canvas area...")
    
    gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
    _, binary = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY)
    
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if not contours:
        raise Exception("Cannot find canvas area!")
    
    canvas_contour = max(contours, key=cv2.contourArea)
    x, y, w, h = cv2.boundingRect(canvas_contour)
    
    margin = 20
    canvas = {
        'x': x + margin,
        'y': y + margin,
        'width': w - 2*margin,
        'height': h - 2*margin
    }
    
    print(f"   ‚úÖ Canvas: ({canvas['x']}, {canvas['y']}) - {canvas['width']}x{canvas['height']}")
    
    return canvas


def art_cv_analyzer_agent(state: StoryArtState) -> StoryArtState:
    """Agent ph√¢n t√≠ch giao di·ªán Paint b·∫±ng Computer Vision"""
    
    if state['mode'] == 'story_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("üî¨ COMPUTER VISION ANALYSIS")
    print("="*70)
    
    try:
        # Decode screenshot
        img_data = base64.b64decode(state['paint_screenshot_b64'])
        img_pil = Image.open(BytesIO(img_data))
        img_cv = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
        
        screen_height, screen_width = img_cv.shape[:2]
        print(f"   üìê Screen: {screen_width}x{screen_height}")
        
        # 1. Detect Canvas
        canvas_area = detect_canvas_area(img_cv)
        state['canvas_area'] = canvas_area
        
        # 2. Detect Colors & Tools b·∫±ng LLM Vision
        print("\n   üß† LLM detecting tools and colors...")
        
        prompt = """
Ph√¢n t√≠ch giao di·ªán Paint v√† tr·∫£ v·ªÅ JSON:

{{
  "tool_positions": {{
    "pencil": {{"x": 334, "y": 65}},
    "brush": {{"x": 350, "y": 81}},
    "fill": {{"x": 306, "y": 81}},
    "eraser": {{"x": 290, "y": 65}},
    "color_picker": {{"x": 274, "y": 81}},
    "text": {{"x": 386, "y": 65}}, 
    "line": {{"x": 370, "y": 65}},
    "curve": {{"x": 386, "y": 81}},
    "rectangle": {{"x": 418, "y": 65}},
    "polygon": {{"x": 434, "y": 65}},
    "ellipse": {{"x": 402, "y": 81}},
    "rounded_rectangle": {{"x": 450, "y": 65}}
  }},
  "color_positions": {{
    "black": {{"x": 573, "y": 63}},
    "white": {{"x": 619, "y": 99}},
    "gray": {{"x": 589, "y": 63}},
    "red": {{"x": 638, "y": 63}},
    "orange": {{"x": 654, "y": 63}},
    "yellow": {{"x": 692, "y": 63}},
    "green": {{"x": 710, "y": 63}},
    "blue": {{"x": 728, "y": 63}},
    "purple": {{"x": 746, "y": 63}},
    "brown": {{"x": 670, "y": 63}}
  }},
  "other_buttons": {{
    "size": {{"x": 48, "y": 133}},
    "outline": {{"x": 244, "y": 81}}
  }}
}}

Y√äU C·∫¶U:
- X√°c ƒë·ªãnh t·ªça ƒë·ªô CH√çNH X√ÅC c·ªßa T·ª™NG tool trong toolbar
- X√°c ƒë·ªãnh t·ªça ƒë·ªô CH√çNH X√ÅC c·ªßa T·ª™NG m√†u trong color palette
- T·ªça ƒë·ªô ph·∫£i l√† pixel tuy·ªát ƒë·ªëi tr√™n m√†n h√¨nh
"""
        
        img_pil_small = img_pil.copy()
        img_pil_small.thumbnail((1200, 1200), Image.Resampling.LANCZOS)
        
        response = call_gemini_vision(prompt, [img_pil_small])
        
        # Extract JSON
        json_str = response
        if '```json' in response:
            json_str = response.split('```json')[1].split('```')[0]
        elif '```' in response:
            json_str = response.split('```')[1].split('```')[0]
        
        detection = json.loads(json_str.strip())
        
        state['tool_positions'] = detection.get('tool_positions', {})
        state['color_positions'] = detection.get('color_positions', {})
        
        print(f"\n   ‚úÖ Detected {len(state['tool_positions'])} tools")
        print(f"   ‚úÖ Detected {len(state['color_positions'])} colors")
        
        state['execution_log'].append("‚úì CV Analysis: Interface mapped")
        
    except Exception as e:
        print(f"‚ùå CV Analysis error: {e}")
        state['error'] = f"CV Analysis failed: {e}"
        traceback.print_exc()
    
    return state


def art_planner_agent(state: StoryArtState) -> StoryArtState:
    """Agent t·∫°o k·∫ø ho·∫°ch v·∫Ω ƒê∆†N GI·∫¢N"""
    
    if state['mode'] == 'story_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("üß† ART PLANNER AGENT")
    print("="*70)
    
    try:
        # Load reference image
        ref_img = Image.open(BytesIO(base64.b64decode(state['reference_image_b64'])))
        ref_img.thumbnail((800, 800), Image.Resampling.LANCZOS)
        
        canvas = state['canvas_area']
        
        prompt = f"""
T·∫°o k·∫ø ho·∫°ch v·∫Ω SI√äU ƒê∆†N GI·∫¢N cho nh√¢n v·∫≠t "{state['character_name']}" trong Paint.

·∫¢NH THAM KH·∫¢O: ·∫¢nh ƒë√£ ƒë∆∞·ª£c ƒë∆°n gi·∫£n h√≥a

TH√îNG TIN CANVAS:
- V·ªã tr√≠: ({canvas['x']}, {canvas['y']})
- K√≠ch th∆∞·ªõc: {canvas['width']}x{canvas['height']}

TOOLS C√ì S·∫¥N:
{json.dumps(list(state['tool_positions'].keys()), indent=2)}

COLORS C√ì S·∫¥N:
{json.dumps(list(state['color_positions'].keys()), indent=2)}

T·∫†O K·∫æ HO·∫†CH V·∫º:
- CH·ªà 6-8 B∆Ø·ªöC ƒê∆†N GI·∫¢N
- D√πng ellipse v√† rectangle ƒë·ªÉ t·∫°o h√¨nh c∆° b·∫£n
- T√¥ m√†u 2-3 m√†u ch√≠nh
- KH√îNG V·∫º CHI TI·∫æT NH·ªé

JSON FORMAT:
{{
  "character_analysis": {{
    "main_shapes": ["head (ellipse)", "body (rectangle)", ...],
    "main_colors": ["yellow", "red", "black"],
    "complexity": "simple"
  }},
  "steps": [
    {{
      "step": 1,
      "description": "V·∫Ω ƒë·∫ßu (ellipse l·ªõn)",
      "tool": "ellipse",
      "color": "black",
      "action": "drag",
      "start_x": 600,
      "start_y": 300,
      "end_x": 800,
      "end_y": 450,
      "note": "Outline c·ªßa ƒë·∫ßu"
    }},
    {{
      "step": 2,
      "description": "T√¥ m√†u ƒë·∫ßu",
      "tool": "fill",
      "color": "yellow",
      "action": "click",
      "click_x": 700,
      "click_y": 375,
      "note": "Fill m√†u da/l√¥ng"
    }},
    {{
      "step": 3,
      "description": "V·∫Ω th√¢n",
      "tool": "rectangle",
      "color": "black",
      "action": "drag",
      "start_x": 650,
      "start_y": 430,
      "end_x": 750,
      "end_y": 600,
      "note": "Outline c·ªßa th√¢n"
    }}
  ]
}}

L∆ØU √ù:
- T·ªça ƒë·ªô ph·∫£i n·∫±m TRONG canvas: x ‚àà [{canvas['x']}, {canvas['x'] + canvas['width']}], y ‚àà [{canvas['y']}, {canvas['y'] + canvas['height']}]
- action = "drag" cho ellipse/rectangle/line (c·∫ßn start_x, start_y, end_x, end_y)
- action = "click" cho fill (ch·ªâ c·∫ßn click_x, click_y)
- CH·ªà 6-8 B∆Ø·ªöC
"""
        
        print("   ü§ñ AI creating simple drawing plan...")
        response = call_gemini_vision(prompt, [ref_img])
        
        # Extract JSON
        json_str = response
        if '```json' in response:
            json_str = response.split('```json')[1].split('```')[0]
        elif '```' in response:
            json_str = response.split('```')[1].split('```')[0]
        
        plan = json.loads(json_str.strip())
        
        state['drawing_steps'] = plan.get('steps', [])
        state['current_step'] = 0
        state['total_steps'] = len(state['drawing_steps'])
        
        print(f"\n‚úÖ Plan created:")
        print(f"   Character: {plan.get('character_analysis', {}).get('main_shapes', [])}")
        print(f"   Colors: {plan.get('character_analysis', {}).get('main_colors', [])}")
        print(f"   Total steps: {state['total_steps']}")
        
        # In ra c√°c b∆∞·ªõc
        for step in state['drawing_steps']:
            print(f"   Step {step['step']}: {step['description']}")
        
        state['execution_log'].append(f"‚úì Plan: {state['total_steps']} steps")
        
    except Exception as e:
        print(f"‚ùå Planner error: {e}")
        state['error'] = f"Planner failed: {e}"
        traceback.print_exc()
    
    return state


def safe_click_tool(tool_name: str, tool_positions: Dict, retry: int = 2) -> bool:
    """Click v√†o tool v·ªõi retry"""
    if tool_name not in tool_positions:
        print(f"      ‚ö†Ô∏è  Tool '{tool_name}' not found in positions")
        return False
    
    pos = tool_positions[tool_name]
    
    for attempt in range(retry):
        try:
            print(f"      üîß Clicking {tool_name} at ({pos['x']}, {pos['y']})...")
            pyautogui.click(pos['x'], pos['y'])
            time.sleep(0.3)
            return True
        except Exception as e:
            print(f"         ‚ö†Ô∏è  Attempt {attempt+1} failed: {e}")
            time.sleep(0.2)
    
    return False


def safe_click_color(color_name: str, color_positions: Dict, retry: int = 2) -> bool:
    """Click v√†o m√†u v·ªõi retry"""
    if color_name not in color_positions:
        print(f"      ‚ö†Ô∏è  Color '{color_name}' not found in positions")
        return False
    
    pos = color_positions[color_name]
    
    for attempt in range(retry):
        try:
            print(f"      üé® Clicking {color_name} at ({pos['x']}, {pos['y']})...")
            pyautogui.click(pos['x'], pos['y'])
            time.sleep(0.3)
            return True
        except Exception as e:
            print(f"         ‚ö†Ô∏è  Attempt {attempt+1} failed: {e}")
            time.sleep(0.2)
    
    return False


def safe_drag(start_x: int, start_y: int, end_x: int, end_y: int, duration: float = 0.5):
    """Th·ª±c hi·ªán drag an to√†n"""
    try:
        print(f"      ‚úèÔ∏è  Dragging from ({start_x},{start_y}) to ({end_x},{end_y})...")
        
        # Di chuy·ªÉn ƒë·∫øn v·ªã tr√≠ b·∫Øt ƒë·∫ßu
        pyautogui.moveTo(start_x, start_y, duration=0.2)
        time.sleep(0.1)
        
        # Gi·ªØ chu·ªôt tr√°i v√† k√©o
        pyautogui.mouseDown(button='left')
        time.sleep(0.1)
        
        pyautogui.moveTo(end_x, end_y, duration=duration)
        time.sleep(0.1)
        
        pyautogui.mouseUp(button='left')
        time.sleep(0.2)
        
        return True
        
    except Exception as e:
        print(f"         ‚ùå Drag failed: {e}")
        # ƒê·∫£m b·∫£o th·∫£ chu·ªôt n·∫øu c√≥ l·ªói
        try:
            pyautogui.mouseUp(button='left')
        except:
            pass
        return False


def art_executor_agent(state: StoryArtState) -> StoryArtState:
    """Agent th·ª±c thi v·∫Ω TO√ÄN B·ªò c√°c b∆∞·ªõc - PURE MOUSE"""
    
    if state['mode'] == 'story_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("‚öôÔ∏è ART EXECUTOR AGENT - FULL AUTO DRAWING")
    print("="*70)
    
    tool_positions = state['tool_positions']
    color_positions = state['color_positions']
    steps = state['drawing_steps']
    
    try:
        # Click v√†o canvas tr∆∞·ªõc ƒë·ªÉ focus
        canvas = state['canvas_area']
        canvas_center_x = canvas['x'] + canvas['width'] // 2
        canvas_center_y = canvas['y'] + canvas['height'] // 2
        
        print(f"\n   üñ±Ô∏è  Focusing canvas at ({canvas_center_x}, {canvas_center_y})...")
        pyautogui.click(canvas_center_x, canvas_center_y)
        time.sleep(0.5)
        
        # V·∫º TO√ÄN B·ªò KH√îNG D·ª™NG
        for i, step_data in enumerate(steps):
            step_num = i + 1
            print(f"\n   [{step_num}/{len(steps)}] {step_data['description']}")
            
            tool = step_data.get('tool', 'ellipse')
            color = step_data.get('color', 'black')
            action = step_data.get('action', 'drag')
            
            # 1. Ch·ªçn tool
            if not safe_click_tool(tool, tool_positions):
                print(f"      ‚ö†Ô∏è  Skipping step {step_num} - tool selection failed")
                continue
            
            # 2. Ch·ªçn m√†u
            if not safe_click_color(color, color_positions):
                print(f"      ‚ö†Ô∏è  Warning: color selection failed, continuing anyway...")
            
            # 3. Th·ª±c hi·ªán v·∫Ω
            if action == 'drag':
                sx = step_data.get('start_x', 600)
                sy = step_data.get('start_y', 300)
                ex = step_data.get('end_x', 800)
                ey = step_data.get('end_y', 450)
                
                if not safe_drag(sx, sy, ex, ey):
                    print(f"      ‚ö†Ô∏è  Step {step_num} drag failed")
                
            elif action == 'click':
                cx = step_data.get('click_x', 700)
                cy = step_data.get('click_y', 400)
                
                print(f"      üñ±Ô∏è  Clicking at ({cx},{cy})...")
                pyautogui.click(cx, cy)
                time.sleep(0.3)
            
            time.sleep(0.5)
            
            print(f"      ‚úÖ Step {step_num} done!")
            state['current_step'] = step_num
        
        # ƒê√°nh d·∫•u ho√†n th√†nh
        state['is_complete'] = True
        
        print(f"\n   üéâ ALL {len(steps)} STEPS COMPLETED!")
        state['execution_log'].append(f"‚úì Drawing: {len(steps)} steps completed")
        
        # L∆∞u ·∫£nh cu·ªëi c√πng
        print("\n   üíæ Saving final drawing...")
        time.sleep(1)
        
        char_name = state['character_name'].replace(' ', '_')
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"drawing_{char_name}_{timestamp}.png"
        
        # Ch·ª•p m√†n h√¨nh
        screenshot = pyautogui.screenshot()
        screenshot.save(filename)
        
        print(f"   ‚úÖ Saved: {filename}")
        state['execution_log'].append(f"‚úì Image: {filename}")
        
    except Exception as e:
        print(f"‚ùå Executor error: {e}")
        state['error'] = f"Executor failed: {e}"
        traceback.print_exc()
    
    return state


# ============ BUILD GRAPH ============

def build_workflow(mode: str):
    """Build workflow d·ª±a tr√™n mode"""
    workflow = StateGraph(StoryArtState)
    
    if mode == "story_only":
        # Ch·ªâ vi·∫øt truy·ªán
        workflow.add_node("story_research", story_research_agent)
        workflow.add_node("story_outline", story_outline_agent)
        workflow.add_node("story_writer", story_writer_agent)
        workflow.add_node("story_formatter", story_formatter_agent)
        
        workflow.set_entry_point("story_research")
        workflow.add_edge("story_research", "story_outline")
        workflow.add_edge("story_outline", "story_writer")
        workflow.add_edge("story_writer", "story_formatter")
        workflow.add_edge("story_formatter", END)
        
    elif mode == "art_only":
        # Ch·ªâ v·∫Ω tranh - PURE VISION WORKFLOW
        workflow.add_node("art_preparation", art_preparation_agent)
        workflow.add_node("window_setup", window_setup_agent)
        workflow.add_node("cv_analyzer", art_cv_analyzer_agent)
        workflow.add_node("art_planner", art_planner_agent)
        workflow.add_node("art_executor", art_executor_agent)
        
        workflow.set_entry_point("art_preparation")
        workflow.add_edge("art_preparation", "window_setup")
        workflow.add_edge("window_setup", "cv_analyzer")
        workflow.add_edge("cv_analyzer", "art_planner")
        workflow.add_edge("art_planner", "art_executor")
        workflow.add_edge("art_executor", END)
        
    else:  # full
        # C·∫£ 2
        workflow.add_node("story_research", story_research_agent)
        workflow.add_node("story_outline", story_outline_agent)
        workflow.add_node("story_writer", story_writer_agent)
        workflow.add_node("story_formatter", story_formatter_agent)
        workflow.add_node("art_preparation", art_preparation_agent)
        workflow.add_node("window_setup", window_setup_agent)
        workflow.add_node("cv_analyzer", art_cv_analyzer_agent)
        workflow.add_node("art_planner", art_planner_agent)
        workflow.add_node("art_executor", art_executor_agent)
        
        workflow.set_entry_point("story_research")
        workflow.add_edge("story_research", "story_outline")
        workflow.add_edge("story_outline", "story_writer")
        workflow.add_edge("story_writer", "story_formatter")
        workflow.add_edge("story_formatter", "art_preparation")
        workflow.add_edge("art_preparation", "window_setup")
        workflow.add_edge("window_setup", "cv_analyzer")
        workflow.add_edge("cv_analyzer", "art_planner")
        workflow.add_edge("art_planner", "art_executor")
        workflow.add_edge("art_executor", END)
    
    return workflow.compile()


# ============ MAIN ============

def main():
    """Main function"""
    print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë          üé®üìù ANIME STORY STUDIO V5                       ‚ïë
‚ïë          Pure Computer Vision - No Windows Hotkeys        ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)
    
    print("\nüìã MENU:")
    print("  1. Vi·∫øt truy·ªán + V·∫Ω nh√¢n v·∫≠t (Full Auto)")
    print("  2. Ch·ªâ vi·∫øt truy·ªán (Story Only)")
    print("  3. Ch·ªâ v·∫Ω tranh (Art Only) - PURE VISION")
    print("  0. Tho√°t")
    
    choice = input("\nüëâ Ch·ªçn ch·ª©c nƒÉng (1-3): ").strip()
    
    if choice == '0':
        print("üëã Goodbye!")
        return
    
    # X√°c ƒë·ªãnh mode
    mode_map = {
        '1': 'full',
        '2': 'story_only',
        '3': 'art_only'
    }
    mode = mode_map.get(choice, 'full')
    
    # Input th√¥ng tin
    print("\n" + "="*60)
    character_name = input("üé≠ Nh·∫≠p t√™n nh√¢n v·∫≠t (VD: Doraemon, Pikachu, Luffy): ").strip()
    
    if not character_name:
        character_name = "Doraemon"
        print(f"   ‚ö†Ô∏è  S·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh: {character_name}")
    
    story_theme = "adventure"
    story_length = 200
    
    if mode in ['full', 'story_only']:
        story_theme = input("üìñ Ch·ªß ƒë·ªÅ truy·ªán (adventure/friendship/funny): ").strip() or "adventure"
        story_length_input = input("üìè ƒê·ªô d√†i truy·ªán (s·ªë t·ª´, VD: 500): ").strip()
        try:
            story_length = int(story_length_input)
        except:
            story_length = 200
    
    # Kh·ªüi t·∫°o state
    initial_state = StoryArtState(
        character_name=character_name,
        story_theme=story_theme,
        story_length=story_length,
        mode=mode,
        character_info={},
        story_outline={},
        story_content="",
        story_file_path="",
        reference_image_b64="",
        paint_screenshot_b64="",
        tool_positions={},
        color_positions={},
        canvas_area={},
        drawing_steps=[],
        current_step=0,
        total_steps=0,
        paint_window_ready=False,
        paint_maximized=False,
        execution_log=[],
        is_complete=False,
        error=""
    )
    
    # Build v√† ch·∫°y workflow
    print("\nüöÄ Starting PURE VISION automation...")
    print("‚ö†Ô∏è  Script s·∫Ω ƒëi·ªÅu khi·ªÉn chu·ªôt (KH√îNG D√ôNG PH√çM T·∫ÆT WINDOWS)!")
    print("‚ö†Ô∏è  KH√îNG DI CHUY·ªÇN CHU·ªòT trong qu√° tr√¨nh v·∫Ω!")
    print("\n‚è≥ B·∫Øt ƒë·∫ßu sau 3 gi√¢y...")
    time.sleep(3)
    
    graph = build_workflow(mode)
    
    try:
        final_state = graph.invoke(initial_state)
        
        # Summary
        print("\n" + "="*70)
        print("üìä EXECUTION SUMMARY")
        print("="*70)
        
        if final_state.get('error'):
            print(f"‚ùå Error: {final_state['error']}")
        else:
            print("‚úÖ Status: Completed!")
            
            if final_state.get('story_file_path'):
                print(f"üìù Story: {final_state['story_file_path']}")
            
            if final_state.get('is_complete'):
                print(f"üé® Drawing: {final_state['total_steps']} steps completed")
        
        print("\nüìú Execution Log:")
        for log in final_state.get('execution_log', []):
            print(f"  {log}")
        
    except Exception as e:
        print(f"\nüí• Critical error: {e}")
        traceback.print_exc()
    
    print("\n" + "="*70)
    print("ü§ñ Automation finished!")
    print("="*70)


if __name__ == "__main__":
    main()
