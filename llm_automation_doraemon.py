# ======================================================================================
# ======================================================================================
"""
LangGraph Multi-Agent System for Paint Automation
Optimized for drawing from a local file.
Architecture: Preparation ‚Üí Planner ‚Üí Analyzer ‚Üí Executor ‚Üí Validator
"""

import os
import time
import base64
import json
import subprocess
from io import BytesIO
from datetime import datetime
from dotenv import load_dotenv
from PIL import Image
import pyautogui
from typing import TypedDict, List, Dict
from langgraph.graph import StateGraph, END
import google.generativeai as genai
import traceback
import webbrowser 

# Load environment variables
load_dotenv()
GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')

# Configure Gemini
genai.configure(api_key=GOOGLE_API_KEY)

# ============ STATE DEFINITION ============

class DrawingState(TypedDict):
    """State shared across all agents"""
    subject: str
    search_query: str
    reference_image_b64: str
    screenshot_b64: str
    canvas_bounds: Dict[str, int]
    overall_plan: Dict
    current_phase: str
    current_step: int
    total_steps: int
    step_actions: List[Dict]
    execution_log: List[str]
    validation_result: Dict
    is_complete: bool
    error: str


# ============ UTILITY FUNCTIONS ============

def screenshot_to_base64() -> str:
    """Ch·ª•p m√†n h√¨nh v√† convert sang base64"""
    screenshot = pyautogui.screenshot()
    buffered = BytesIO()
    screenshot.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode()


def save_screenshot(prefix: str = "verify") -> str:
    """L∆∞u screenshot v·ªõi timestamp"""
    screenshot = pyautogui.screenshot()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"{prefix}_{timestamp}.png"
    screenshot.save(filename)
    print(f"   üíæ Saved: {filename}")
    return filename


def image_to_base64(image_path: str) -> str:
    """Convert ·∫£nh file sang base64"""
    with open(image_path, 'rb') as f:
        return base64.b64encode(f.read()).decode()



def call_gemini_vision(prompt: str, images: List[Image.Image]) -> str:
    """G·ªçi Gemini v·ªõi vision"""
    model = genai.GenerativeModel('gemini-2.5-flash')
    content = images + [prompt]
    # G·ªçi h√†m m·ªôt c√°ch b√¨nh th∆∞·ªùng, kh√¥ng c√≥ request_options
    response = model.generate_content(content)
    return response.text

# ============ AGENT 0: PREPARATION AGENT (SIMPLIFIED) ============

def preparation_agent(state: DrawingState) -> DrawingState:
    """
    Agent n√†y chu·∫©n b·ªã m√¥i tr∆∞·ªùng: m·ªü tr√¨nh duy·ªát cho ng∆∞·ªùi d√πng t√¨m ·∫£nh,
    ch·ªù ng∆∞·ªùi d√πng t·∫£i ·∫£nh th·ªß c√¥ng, sau ƒë√≥ m·ªü Paint.
    """
    print("\n" + "="*70)
    print("üöÄ PREPARATION AGENT")
    print("="*70)
    
    # --- C·∫•u h√¨nh ƒë∆∞·ªùng d·∫´n ·∫£nh ---
    IMAGE_FOLDER = "images"
    REFERENCE_IMAGE_FILENAME = "doraemon.jpg"
    REFERENCE_IMAGE_PATH = os.path.join(IMAGE_FOLDER, REFERENCE_IMAGE_FILENAME)
    
    try:
        # 1. M·ªü Chrome ƒë·ªÉ ng∆∞·ªùi d√πng t√¨m ·∫£nh (h·ªó tr·ª£)
        query = state['search_query']
        search_url = f"https://www.google.com/search?q={query.replace(' ', '+')}&tbm=isch"
        print(f"\nüåê M·ªü Chrome ƒë·ªÉ b·∫°n t√¨m ·∫£nh: {search_url}")
        webbrowser.open(search_url)

        # 2. H∆∞·ªõng d·∫´n v√† ch·ªù ng∆∞·ªùi d√πng t·∫£i ·∫£nh
        print("\n" + "!"*70)
        print("ACTION REQUIRED: Vui l√≤ng t√¨m v√† t·∫£i ·∫£nh b·∫°n mu·ªën v·∫Ω.")
        print(f"üëâ H√£y l∆∞u ·∫£nh v√†o ƒë∆∞·ªùng d·∫´n sau: {REFERENCE_IMAGE_PATH}")
        print("!"*70)
        
        # V√≤ng l·∫∑p ch·ªù cho ƒë·∫øn khi file t·ªìn t·∫°i
        while not os.path.exists(REFERENCE_IMAGE_PATH):
            input("Nh·∫•n Enter khi b·∫°n ƒë√£ l∆∞u ·∫£nh xong...")
            if not os.path.exists(REFERENCE_IMAGE_PATH):
                print(f"‚ùå Kh√¥ng t√¨m th·∫•y file t·∫°i '{REFERENCE_IMAGE_PATH}'. Vui l√≤ng ki·ªÉm tra l·∫°i.")

        print(f"\n‚úÖ ƒê√£ t√¨m th·∫•y ·∫£nh tham kh·∫£o: {REFERENCE_IMAGE_PATH}")
        state['reference_image_b64'] = image_to_base64(REFERENCE_IMAGE_PATH)
        
        # 3. M·ªü Paint
        print("\nüé® M·ªü Paint...")
        subprocess.Popen(['mspaint'])
        print("‚è≥ Ch·ªù Paint m·ªü (3 gi√¢y)...")
        time.sleep(3)
        
        # 4. Maximize Paint
        pyautogui.hotkey('win', 'up')
        time.sleep(0.5)
        
        # 5. Ch·ª•p screenshot Paint ban ƒë·∫ßu
        print("\nüì∏ Ch·ª•p m√†n h√¨nh canvas Paint...")
        state['screenshot_b64'] = screenshot_to_base64()
        state['execution_log'].append("‚úì Preparation: User provided reference image.")
        
    except Exception as e:
        print(f"‚ùå Preparation error: {e}")
        state['error'] = f"Preparation failed: {e}"
        traceback.print_exc()

    return state


# ============ AGENT 1: PLANNER ============

def planner_agent(state: DrawingState) -> DrawingState:
    """
    Agent l·∫≠p k·∫ø ho·∫°ch t·ªïng th·ªÉ
    """
    print("\n" + "="*70)
    print("üß† PLANNER AGENT")
    print("="*70)
    
    if state['error']: return state

    try:
        # Prepare images
        ref_img = Image.open(BytesIO(base64.b64decode(state['reference_image_b64'])))
        screen_img = Image.open(BytesIO(base64.b64decode(state['screenshot_b64'])))

        # T·ªëi ∆∞u h√≥a k√≠ch th∆∞·ªõc ·∫£nh ƒë·ªÉ tr√°nh timeout
        MAX_SIZE = (1024, 1024)
        ref_img.thumbnail(MAX_SIZE, Image.Resampling.LANCZOS)
        screen_img.thumbnail(MAX_SIZE, Image.Resampling.LANCZOS)
        print(f"   üñºÔ∏è  Reference image resized to: {ref_img.size}")
        print(f"   üñºÔ∏è  Screenshot resized to: {screen_img.size}")

        prompt = f"""B·∫°n l√† Planner Agent chuy√™n nghi·ªáp.

    NHI·ªÜM V·ª§: T·∫°o k·∫ø ho·∫°ch chi ti·∫øt ƒë·ªÉ v·∫Ω "{state['subject']}" trong Paint, d·ª±a tr√™n ·∫£nh tham kh·∫£o.

    ·∫¢NH 1: ·∫¢nh tham kh·∫£o (·∫£nh m·∫´u do ng∆∞·ªùi d√πng cung c·∫•p).
    ·∫¢NH 2: Screenshot m√†n h√¨nh Paint tr·ªëng.

    PH√ÇN T√çCH V√Ä L·∫¨P K·∫æ HO·∫†CH:
    1.  Ph√¢n t√≠ch k·ªπ l∆∞·ª°ng ·∫¢nh 1 ƒë·ªÉ x√°c ƒë·ªãnh c√°c th√†nh ph·∫ßn ch√≠nh (ƒë·∫ßu, m·∫Øt, m≈©i, mi·ªáng, th√¢n, tay, ch√¢n, ph·ª• ki·ªán...).
    2.  X√°c ƒë·ªãnh v√πng canvas Paint t·ª´ ·∫¢nh 2.
    3.  T·∫°o m·ªôt k·∫ø ho·∫°ch v·∫Ω chi ti·∫øt, chia th√†nh 3 GIAI ƒêO·∫†N: SKETCHING (ph√°c th·∫£o), DETAILING (v·∫Ω chi ti·∫øt), v√† COLORING (t√¥ m√†u).
    4.  M·ªói giai ƒëo·∫°n ph·∫£i c√≥ t·ª´ 4-6 B∆Ø·ªöC nh·ªè, c·ª• th·ªÉ. M·ªói b∆∞·ªõc ph·∫£i ch·ªâ r√µ: c√¥ng c·ª• (`tool`), v·ªã tr√≠ (`position`), k√≠ch th∆∞·ªõc (`size`), v√† m√†u s·∫Øc (`color`).
    5.  C√°c t·ªça ƒë·ªô ph·∫£i ƒë∆∞·ª£c t√≠nh to√°n ƒë·ªÉ n·∫±m trong v√πng canvas.

    Y√äU C·∫¶U ƒê·ªäNH D·∫†NG: Ch·ªâ tr·∫£ v·ªÅ m·ªôt ƒë·ªëi t∆∞·ª£ng JSON h·ª£p l·ªá, kh√¥ng c√≥ b·∫•t k·ª≥ vƒÉn b·∫£n gi·∫£i th√≠ch n√†o kh√°c.
    
    V√≠ d·ª• JSON:
    {{
      "canvas_bounds": {{"x": 290, "y": 140, "width": 1600, "height": 800}},
      "reference_analysis": "·∫¢nh tham kh·∫£o l√† Doraemon ƒëang ƒë·ª©ng th·∫≥ng. C√°c th√†nh ph·∫ßn ch√≠nh bao g·ªìm ƒë·∫ßu tr√≤n m√†u xanh, m·∫∑t tr·∫Øng, m·∫Øt, m≈©i, mi·ªáng c∆∞·ªùi, v√≤ng c·ªï ƒë·ªè v·ªõi chu√¥ng v√†ng, th√¢n xanh, t√∫i b√°n nguy·ªát v√† tay ch√¢n tr√≤n.",
      "color_palette": ["blue", "white", "red", "yellow", "black"],
      "phases": [
        {{
          "phase_name": "SKETCHING",
          "description": "V·∫Ω c√°c h√¨nh d·∫°ng c∆° b·∫£n cho ƒë·∫ßu v√† th√¢n.",
          "steps": [
            {{
              "step_id": 1,
              "description": "V·∫Ω m·ªôt h√¨nh tr√≤n l·ªõn cho c√°i ƒë·∫ßu",
              "tool": "oval",
              "position": {{"center_x": 700, "center_y": 450}},
              "size": {{"width": 300, "height": 300}},
              "color": "black"
            }}
          ]
        }},
        {{
            "phase_name": "DETAILING",
            "description": "Th√™m c√°c chi ti·∫øt cho khu√¥n m·∫∑t v√† c∆° th·ªÉ.",
            "steps": []
        }},
        {{
            "phase_name": "COLORING",
            "description": "T√¥ m√†u cho b·ª©c tranh.",
            "steps": []
        }}
      ]
    }}
    """
        response = call_gemini_vision(prompt, [ref_img, screen_img])
        
        # Logic tr√≠ch xu·∫•t JSON m·∫°nh m·∫Ω
        json_string = response
        if '```json' in response:
            json_string = response.split('```json', 1)[1].rsplit('```', 1)
        elif '```' in response:
             json_string = response.split('```', 1).rsplit('```', 1)[0]
        
        plan = json.loads(json_string.strip())
        
        # C·∫≠p nh·∫≠t state
        state['overall_plan'] = plan
        state['canvas_bounds'] = plan.get('canvas_bounds', {'x': 290, 'y': 140, 'width': 900, 'height': 600})
        state['current_phase'] = plan['phases'][0]['phase_name']
        state['current_step'] = 0
        
        total = sum(len(p.get('steps', [])) for p in plan.get('phases', []))
        state['total_steps'] = total
        
        print("\nüìä Plan created successfully:")
        print(f"   Canvas: {state['canvas_bounds']}")
        print(f"   Colors: {plan.get('color_palette', [])}")
        print(f"   Total phases: {len(plan.get('phases', []))}")
        print(f"   Total steps: {total}")
        
        state['execution_log'].append(f"‚úì Planner: Created plan with {total} steps.")
        
    except Exception as e:
        print(f"‚ùå Planner error: {e}")
        state['error'] = f"Planner failed: {e}"
        traceback.print_exc()
    
    return state


# ============ AGENT 2: ANALYZER ============

def analyzer_agent(state: DrawingState) -> DrawingState:
    """
    Agent ph√¢n t√≠ch step hi·ªán t·∫°i v√† sinh actions c·ª• th·ªÉ
    """
    print("\n" + "="*70)
    print("üîç ANALYZER AGENT")
    print("="*70)
    
    if state['error']: return state
    
    plan = state['overall_plan']
    current_step_idx = state['current_step']
    
    # T√¨m step hi·ªán t·∫°i
    step_count = 0
    current_step_data = None
    current_phase_name = None
    
    for phase in plan.get('phases', []):
        for step in phase.get('steps', []):
            if step_count == current_step_idx:
                current_step_data = step
                current_phase_name = phase.get('phase_name', 'Unknown')
                break
            step_count += 1
        if current_step_data:
            break
    
    if not current_step_data:
        print("‚ö†Ô∏è No more steps found in the plan!")
        state['is_complete'] = True
        return state
    
    print(f"\nüìç Phase: {current_phase_name}")
    print(f"üìç Step {current_step_idx + 1}/{state['total_steps']}")
    print(f"üìù Description: {current_step_data.get('description', 'N/A')}")
    
    # Sinh actions
    actions = []
    
    if current_phase_name in ["SKETCHING", "DETAILING"]:
        tool = current_step_data.get('tool', 'oval')
        pos = current_step_data.get('position', {})
        size = current_step_data.get('size', {})
        color = current_step_data.get('color', 'black').lower()
        
        tool_map = {
            'oval': (402, 81), 'rectangle': (418, 65), 'line': (350, 65)
        }
        tool_pos = tool_map.get(tool, (402, 81))
        actions.append({'action': 'click', 'x': tool_pos[0], 'y': tool_pos[1], 'reason': f"Ch·ªçn tool: {tool}"})
        
        color_map = {
            'black': (573, 63), 'white': (619, 99), 'red': (638, 63), 
            'yellow': (692, 63), 'blue': (728, 63)
        }
        color_pos = color_map.get(color, (573, 63))
        actions.append({'action': 'click', 'x': color_pos[0], 'y': color_pos[1], 'reason': f"Ch·ªçn m√†u: {color}"})
        
        if tool in ['oval', 'rectangle']:
            cx, cy = pos.get('center_x', 600), pos.get('center_y', 400)
            w, h = size.get('width', 100), size.get('height', 100)
            sx, sy, ex, ey = cx - w // 2, cy - h // 2, cx + w // 2, cy + h // 2
            actions.append({'action': 'drag', 'start_x': sx, 'start_y': sy, 'end_x': ex, 'end_y': ey, 'duration': 0.5})
    
    elif current_phase_name == "COLORING":
        color = current_step_data.get('color', 'blue').lower()
        fill_pos = current_step_data.get('fill_position', {})
        
        actions.append({'action': 'click', 'x': 306, 'y': 81, 'reason': "Ch·ªçn Fill tool"}) # Fill bucket
        
        color_map = {
            'black': (573, 63), 'white': (619, 99), 'red': (638, 63), 
            'yellow': (692, 63), 'blue': (728, 63)
        }
        color_pos = color_map.get(color, (728, 63))
        actions.append({'action': 'click', 'x': color_pos[0], 'y': color_pos[1], 'reason': f"Ch·ªçn m√†u t√¥: {color}"})
        
        fx, fy = fill_pos.get('x', 600), fill_pos.get('y', 400)
        actions.append({'action': 'click', 'x': fx, 'y': fy, 'reason': f"T√¥ m√†u t·∫°i ({fx},{fy})"})
    
    actions.append({'action': 'screenshot_verify'})
    
    state['step_actions'] = actions
    state['execution_log'].append(f"‚úì Analyzer: Generated {len(actions)} actions for step {current_step_idx + 1}")
    
    return state


# ============ AGENT 3: EXECUTOR ============

def executor_agent(state: DrawingState) -> DrawingState:
    """
    Agent th·ª±c thi c√°c actions
    """
    print("\n" + "="*70)
    print("‚öôÔ∏è EXECUTOR AGENT")
    print("="*70)
    
    if state['error']: return state
    
    for action in state.get('step_actions', []):
        act_type = action.get('action')
        print(f"   -> Executing: {act_type} - {action.get('reason', '')}")
        try:
            time.sleep(0.5) # Th√™m ƒë·ªô tr·ªÖ nh·ªè gi·ªØa c√°c action
            if act_type == 'click':
                pyautogui.click(action['x'], action['y'])
            elif act_type == 'drag':
                pyautogui.moveTo(action['start_x'], action['start_y'], duration=0.2)
                pyautogui.dragTo(action['end_x'], action['end_y'], duration=action.get('duration', 0.5), button='left')
            elif act_type == 'screenshot_verify':
                save_screenshot(f"step_{state['current_step'] + 1:02d}")
                state['screenshot_b64'] = screenshot_to_base64()
        except Exception as e:
            error_msg = f"Executor failed on action '{act_type}': {e}"
            print(f"   ‚ùå Execution Error: {error_msg}")
            state['error'] = error_msg
            return state
    
    state['execution_log'].append(f"‚úì Executor: Completed actions for step {state['current_step'] + 1}")
    print("\n‚úÖ Execution for this step is complete!")
    return state


# ============ AGENT 4: VALIDATOR ============

def validator_agent(state: DrawingState) -> DrawingState:
    """
    Agent ki·ªÉm tra k·∫øt qu·∫£
    """
    print("\n" + "="*70)
    print("‚úÖ VALIDATOR AGENT")
    print("="*70)

    if state['error']: return state

    screen_img = Image.open(BytesIO(base64.b64decode(state['screenshot_b64'])))
    ref_img = Image.open(BytesIO(base64.b64decode(state['reference_image_b64'])))
    
    prompt = f"""B·∫°n l√† Validator Agent, m·ªôt chuy√™n gia ƒë√°nh gi√° ngh·ªá thu·∫≠t.

    ·∫¢NH 1: ·∫¢nh tham kh·∫£o g·ªëc.
    ·∫¢NH 2: T√°c ph·∫©m ƒëang v·∫Ω trong Paint.

    NHI·ªÜM V·ª§: So s√°nh t√°c ph·∫©m hi·ªán t·∫°i (·∫¢nh 2) v·ªõi ·∫£nh tham kh·∫£o (·∫¢nh 1), ƒë√°nh gi√° ch·∫•t l∆∞·ª£ng v√† quy·∫øt ƒë·ªãnh h√†nh ƒë·ªông ti·∫øp theo.

    ƒê·ªäNH D·∫†NG JSON:
    {{
      "quality_score": 8.0,
      "analysis": "ƒê√£ v·∫Ω xong ph·∫ßn ƒë·∫ßu. T·ª∑ l·ªá kh√° ch√≠nh x√°c. C·∫ßn ti·∫øp t·ª•c v·ªõi ph·∫ßn th√¢n.",
      "decision": "continue"
    }}
    (Quy·∫øt ƒë·ªãnh c√≥ th·ªÉ l√† "continue", "retry", ho·∫∑c "complete")
    """
    try:
        response = call_gemini_vision(prompt, [ref_img, screen_img])
        
        json_string = response
        if '```json' in response:
            json_string = response.split('```json', 1)[1].rsplit('```', 1)
        
        result = json.loads(json_string.strip())
        state['validation_result'] = result
        
        score = result.get('quality_score', 5)
        decision = result.get('decision', 'continue').lower()
        
        print(f"\nüìä Quality Score: {score}/10")
        print(f"üìù Analysis: {result.get('analysis', 'N/A')}")
        print(f"üéØ AI Decision: {decision.upper()}")
        
        if decision == 'complete':
            state['is_complete'] = True
        elif decision == 'continue':
            state['current_step'] += 1
        
        state['execution_log'].append(f"‚úì Validator: Score={score}, Decision={decision}")
        
    except Exception as e:
        print(f"‚ùå Validator error: {e}. Defaulting to 'continue'.")
        state['current_step'] += 1
        state['validation_result'] = {'decision': 'continue', 'error': str(e)}
    
    return state


# ============ ROUTING ============

def should_continue(state: DrawingState) -> str:
    """Routing logic"""
    if state.get('error'): return "end"
    if state.get('is_complete'): return "end"
    if state['current_step'] >= state['total_steps']:
        print("\nüèÅ All planned steps have been executed.")
        return "end"
    
    user_input = input(f"\n‚è∏Ô∏è Press Enter to continue to step {state['current_step'] + 1}, or 'n' to stop: ").strip().lower()
    return "end" if user_input == 'n' else "continue"


# ============ BUILD GRAPH ============

def build_graph():
    """Build LangGraph workflow"""
    workflow = StateGraph(DrawingState)
    
    workflow.add_node("preparation", preparation_agent)
    workflow.add_node("planner", planner_agent)
    workflow.add_node("analyzer", analyzer_agent)
    workflow.add_node("executor", executor_agent)
    workflow.add_node("validator", validator_agent)
    
    workflow.set_entry_point("preparation")
    workflow.add_edge("preparation", "planner")
    workflow.add_edge("planner", "analyzer")
    workflow.add_edge("analyzer", "executor")
    workflow.add_edge("executor", "validator")
    
    workflow.add_conditional_edges(
        "validator",
        should_continue,
        {"continue": "analyzer", "end": END}
    )
    
    return workflow.compile()


# ============ MAIN ============

def run_automation():
    print("="*70)
    print("üé® LANGGRAPH PAINT AUTOMATION (FILE-BASED)")
    print("="*70)
    
    initial_state = DrawingState(
        subject="Doraemon",
        search_query="simple doraemon drawing for kids easy",
        reference_image_b64="",
        screenshot_b64="",
        canvas_bounds={},
        overall_plan={},
        current_phase="",
        current_step=0,
        total_steps=0,
        step_actions=[],
        execution_log=[],
        validation_result={},
        is_complete=False,
        error=""
    )
    
    graph = build_graph()
    
    try:
        final_state = graph.invoke(initial_state)
        print("\n" + "="*70)
        print("üìã EXECUTION SUMMARY")
        print("="*70)
        print(f"Status: {'‚úÖ Complete' if final_state.get('is_complete') or not final_state.get('error') else '‚ùå Halted'}")
        if final_state.get('error'):
            print(f"üö® Error: {final_state['error']}")
        print("\nüìú Log:")
        for log in final_state.get('execution_log', []):
            print(f"  {log}")
    except Exception as e:
        print(f"\nüí• A critical error occurred during the workflow: {e}")
        traceback.print_exc()

    print("\n" + "="*70)
    print("ü§ñ Automation finished.")


if __name__ == "__main__":
    print("\nüö® IMPORTANT: This script will take control of your mouse and keyboard.")
    print("    To stop it manually, move your mouse to any corner of the screen.")
    print("    You have 5 seconds to cancel (Ctrl+C).")
    time.sleep(5)
    
    run_automation()