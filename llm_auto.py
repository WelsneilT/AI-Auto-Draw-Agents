"""
======================================================================================
ANIME STORY STUDIO V4 - HYBRID CV + LLM
Computer Vision ƒë·ªÉ detect interface + LLM ƒë·ªÉ t·∫°o l·ªánh v·∫Ω th√¥ng minh
======================================================================================
"""

import os
import time
import base64
import json
import subprocess
from io import BytesIO
from datetime import datetime
from dotenv import load_dotenv
from PIL import Image
import pyautogui
import cv2
import numpy as np
from typing import TypedDict, List, Dict, Tuple
from langgraph.graph import StateGraph, END
import google.generativeai as genai
import traceback
import pyperclip
import pygetwindow as gw
# Load environment
load_dotenv()
genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))

# T·∫Øt fail-safe
pyautogui.FAILSAFE = False
pyautogui.PAUSE = 0.05

# ============ SHARED STATE ============

class StoryArtState(TypedDict):
    """State chung cho c·∫£ 2 agents"""
    # User Input
    character_name: str
    story_theme: str
    story_length: int
    mode: str
    
    # Story Writer State
    character_info: Dict
    story_outline: Dict
    story_content: str
    story_file_path: str
    
    # Art Creator State
    reference_image_b64: str
    paint_screenshot_b64: str
    tool_positions: Dict
    color_positions: Dict
    canvas_area: Dict
    drawing_steps: List[Dict]
    current_step: int
    total_steps: int
    
    # Shared
    execution_log: List[str]
    is_complete: bool
    error: str


# ============ UTILITY FUNCTIONS ============

def screenshot_to_base64(region=None) -> str:
    """Ch·ª•p m√†n h√¨nh v√† convert sang base64"""
    if region:
        screenshot = pyautogui.screenshot(region=region)
    else:
        screenshot = pyautogui.screenshot()
    buffered = BytesIO()
    screenshot.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode()

def image_to_base64(image_path: str) -> str:
    """Convert ·∫£nh file sang base64"""
    with open(image_path, 'rb') as f:
        return base64.b64encode(f.read()).decode()

def call_gemini(prompt: str) -> str:
    """G·ªçi Gemini text-only"""
    model = genai.GenerativeModel('gemini-2.0-flash-exp')
    response = model.generate_content(prompt)
    return response.text

def call_gemini_vision(prompt: str, images: List[Image.Image]) -> str:
    """G·ªçi Gemini v·ªõi vision"""
    model = genai.GenerativeModel('gemini-2.0-flash-exp')
    content = images + [prompt]
    response = model.generate_content(content)
    return response.text

def simplify_image_for_drawing(image_path: str, output_path: str = "simplified.png"):
    """ƒê∆°n gi·∫£n h√≥a ·∫£nh th√†nh d·∫°ng cartoon/sketch d·ªÖ v·∫Ω"""
    img = cv2.imread(image_path)
    
    # Resize v·ªÅ k√≠ch th∆∞·ªõc v·ª´a ph·∫£i
    height, width = img.shape[:2]
    max_size = 300
    if max(height, width) > max_size:
        scale = max_size / max(height, width)
        img = cv2.resize(img, None, fx=scale, fy=scale)
    
    # Chuy·ªÉn sang cartoon style
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray, 5)
    
    # Detect edges
    edges = cv2.adaptiveThreshold(
        gray, 255, 
        cv2.ADAPTIVE_THRESH_MEAN_C, 
        cv2.THRESH_BINARY, 
        9, 9
    )
    
    # Smooth colors
    color = cv2.bilateralFilter(img, 9, 250, 250)
    
    # Combine
    cartoon = cv2.bitwise_and(color, color, mask=edges)
    
    cv2.imwrite(output_path, cartoon)
    print(f"   ‚úÖ Simplified image saved: {output_path}")
    return output_path


# ============ COMPUTER VISION MODULE ============

def detect_canvas_area(img_cv: np.ndarray) -> Dict:
    """
    T√¨m v√πng canvas (v√πng tr·∫Øng l·ªõn nh·∫•t) trong Paint
    """
    print("   üîç Detecting canvas area...")
    
    # Convert to grayscale
    gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
    
    # Threshold ƒë·ªÉ t√¨m v√πng tr·∫Øng (canvas)
    _, binary = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY)
    
    # T√¨m contours
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if not contours:
        raise Exception("Cannot find canvas area!")
    
    # T√¨m contour l·ªõn nh·∫•t (canvas)
    canvas_contour = max(contours, key=cv2.contourArea)
    x, y, w, h = cv2.boundingRect(canvas_contour)
    
    # Th√™m margin nh·ªè ƒë·ªÉ tr√°nh v·∫Ω s√°t m√©p
    margin = 20
    canvas = {
        'x': x + margin,
        'y': y + margin,
        'width': w - 2*margin,
        'height': h - 2*margin
    }
    
    print(f"   ‚úÖ Canvas: ({canvas['x']}, {canvas['y']}) - {canvas['width']}x{canvas['height']}")
    
    return canvas


def detect_color_palette(img_cv: np.ndarray) -> Dict:
    """
    T√¨m v·ªã tr√≠ c√°c m√†u trong b·∫£ng m√†u Paint b·∫±ng color matching
    """
    print("   üé® Detecting color palette...")
    
    screen_height, screen_width = img_cv.shape[:2]
    
    # V√πng ch·ª©a colors th∆∞·ªùng ·ªü ph√≠a tr√™n, gi·ªØa m√†n h√¨nh
    # ƒêi·ªÅu ch·ªânh theo layout Paint
    color_region_y1 = 50
    color_region_y2 = 110
    color_region_x1 = int(screen_width * 0.3)
    color_region_x2 = int(screen_width * 0.7)
    
    color_region = img_cv[color_region_y1:color_region_y2, color_region_x1:color_region_x2]
    
    # ƒê·ªãnh nghƒ©a m√†u c·∫ßn t√¨m (BGR format + tolerance)
    color_targets = {
        'black': ([0, 0, 0], 30),
        'white': ([255, 255, 255], 30),
        'gray': ([128, 128, 128], 40),
        'red': ([0, 0, 200], 60),
        'orange': ([0, 165, 255], 60),
        'yellow': ([0, 255, 255], 60),
        'green': ([0, 200, 0], 60),
        'blue': ([200, 0, 0], 60),
        'purple': ([200, 0, 200], 60),
        'brown': ([42, 82, 165], 60)
    }
    
    color_positions = {}
    
    for color_name, (target_bgr, tolerance) in color_targets.items():
        # T·∫°o mask cho m√†u
        lower = np.array([max(0, c - tolerance) for c in target_bgr])
        upper = np.array([min(255, c + tolerance) for c in target_bgr])
        
        mask = cv2.inRange(color_region, lower, upper)
        
        # T√¨m v·ªã tr√≠
        coords = cv2.findNonZero(mask)
        if coords is not None and len(coords) > 10:  # ƒê·ªß l·ªõn
            # L·∫•y t√¢m c·ªßa v√πng m√†u
            M = cv2.moments(mask)
            if M["m00"] != 0:
                cx = int(M["m10"] / M["m00"]) + color_region_x1
                cy = int(M["m01"] / M["m00"]) + color_region_y1
                color_positions[color_name] = {'x': cx, 'y': cy}
                print(f"      ‚Ä¢ {color_name}: ({cx}, {cy})")
    
    if len(color_positions) < 3:
        print("      ‚ö†Ô∏è  Warning: Only found", len(color_positions), "colors")
    
    return color_positions


def detect_tool_positions(img_cv: np.ndarray) -> Dict:
    """
    T√¨m v·ªã tr√≠ c√°c tools trong Paint
    D√πng heuristic + pattern matching
    """
    print("   üîß Detecting tool positions...")
    
    screen_height, screen_width = img_cv.shape[:2]
    
    # Paint tools th∆∞·ªùng ·ªü b√™n tr√°i ho·∫∑c ph√≠a tr√™n
    # Ta d√πng heuristic d·ª±a tr√™n layout chu·∫©n c·ªßa Paint
    
    # V√πng tools (ph√≠a tr√™n, b√™n tr√°i)
    tool_region_y = 60
    tool_region_x_start = 150
    tool_spacing = 30
    
    tool_positions = {
        'pencil': {'x': tool_region_x_start, 'y': tool_region_y},
        'fill': {'x': tool_region_x_start + tool_spacing, 'y': tool_region_y + 20},
        'eraser': {'x': tool_region_x_start + tool_spacing*2, 'y': tool_region_y},
        'color_picker': {'x': tool_region_x_start + tool_spacing*3, 'y': tool_region_y},
        'text': {'x': tool_region_x_start + tool_spacing*4, 'y': tool_region_y},
        'line': {'x': tool_region_x_start + tool_spacing*5, 'y': tool_region_y},
        'curve': {'x': tool_region_x_start + tool_spacing*6, 'y': tool_region_y},
        'rectangle': {'x': tool_region_x_start + tool_spacing*7, 'y': tool_region_y},
        'oval': {'x': tool_region_x_start + tool_spacing*8, 'y': tool_region_y},
        'brush': {'x': tool_region_x_start + tool_spacing*1, 'y': tool_region_y}
    }
    
    print(f"      ‚Ä¢ Estimated {len(tool_positions)} tool positions")
    
    return tool_positions


def analyze_paint_interface(screenshot_b64: str) -> Dict:
    """
    MAIN FUNCTION: Ph√¢n t√≠ch to√†n b·ªô giao di·ªán Paint b·∫±ng Computer Vision
    """
    print("\n" + "="*70)
    print("üî¨ COMPUTER VISION ANALYSIS")
    print("="*70)
    
    # Decode screenshot
    img_data = base64.b64decode(screenshot_b64)
    img_pil = Image.open(BytesIO(img_data))
    img_cv = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
    
    screen_height, screen_width = img_cv.shape[:2]
    print(f"   üìê Screen resolution: {screen_width}x{screen_height}")
    
    # 1. Detect Canvas
    canvas_area = detect_canvas_area(img_cv)
    
    # 2. Detect Colors
    color_positions = detect_color_palette(img_cv)
    
    # 3. Detect Tools
    tool_positions = detect_tool_positions(img_cv)
    
    print("\n‚úÖ Computer Vision Analysis Complete!")
    
    return {
        'canvas_area': canvas_area,
        'color_positions': color_positions,
        'tool_positions': tool_positions,
        'screen_width': screen_width,
        'screen_height': screen_height
    }


# ============ AGENT 1: STORY WRITER ============

def story_research_agent(state: StoryArtState) -> StoryArtState:
    """Agent t√¨m ki·∫øm th√¥ng tin v·ªÅ nh√¢n v·∫≠t"""
    
    if state['mode'] == 'art_only':
        print("\n‚è© Skipping story research (art_only mode)")
        return state
    
    print("\n" + "="*70)
    print("üìö STORY RESEARCH AGENT")
    print("="*70)
    
    try:
        prompt = f"""
T√¨m ki·∫øm th√¥ng tin v·ªÅ nh√¢n v·∫≠t ho·∫°t h√¨nh "{state['character_name']}".

Tr·∫£ v·ªÅ JSON v·ªõi format:
{{
    "name": "T√™n nh√¢n v·∫≠t",
    "origin": "Xu·∫•t x·ª© (anime/cartoon n√†o)",
    "personality": ["T√≠nh c√°ch 1", "T√≠nh c√°ch 2", ...],
    "appearance": "M√¥ t·∫£ ngo·∫°i h√¨nh",
    "special_abilities": ["Kh·∫£ nƒÉng ƒë·∫∑c bi·ªát 1", ...],
    "famous_quotes": ["C√¢u n√≥i n·ªïi ti·∫øng 1", ...]
}}
"""
        
        response = call_gemini(prompt)
        
        # Extract JSON
        json_str = response
        if '```json' in response:
            json_str = response.split('```json')[1].split('```')[0]
        elif '```' in response:
            json_str = response.split('```')[1].split('```')[0]
        
        character_info = json.loads(json_str.strip())
        state['character_info'] = character_info
        
        print(f"\n‚úÖ Found info about: {character_info['name']}")
        print(f"   Origin: {character_info['origin']}")
        
        state['execution_log'].append(f"‚úì Research: Found info about {character_info['name']}")
        
    except Exception as e:
        print(f"‚ùå Research error: {e}")
        state['error'] = f"Research failed: {e}"
    
    return state


def maximize_paint_safely():
    """
    Maximize Paint m·ªôt c√°ch AN TO√ÄN - ch·ªâ maximize khi ch∆∞a full
    """
    try:
        # T√¨m window Paint
        paint_windows = gw.getWindowsWithTitle('Paint')
        
        if not paint_windows:
            print("   ‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y Paint window!")
            return False
        
        paint_window = paint_windows[0]
        
        # Ki·ªÉm tra tr·∫°ng th√°i
        if paint_window.isMaximized:
            print("   ‚úÖ Paint ƒë√£ maximized r·ªìi, kh√¥ng c·∫ßn l√†m g√¨")
        else:
            print("   üìê Maximizing Paint...")
            paint_window.maximize()
            time.sleep(0.5)
        
        # ƒê·∫£m b·∫£o Paint ƒë∆∞·ª£c focus
        paint_window.activate()
        time.sleep(0.3)
        
        return True
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è  Kh√¥ng th·ªÉ maximize Paint: {e}")
        print("   üîÑ Th·ª≠ ph∆∞∆°ng ph√°p d·ª± ph√≤ng...")
        
        # Fallback: Click v√†o thanh title bar r·ªìi maximize b·∫±ng double-click
        pyautogui.click(500, 10)  # Click v√†o title bar
        time.sleep(0.2)
        pyautogui.doubleClick(500, 10)  # Double-click ƒë·ªÉ maximize
        time.sleep(0.5)
        
        return True
    

def story_outline_agent(state: StoryArtState) -> StoryArtState:
    """Agent t·∫°o d√†n √Ω truy·ªán"""
    
    if state['mode'] == 'art_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("üìù STORY OUTLINE AGENT")
    print("="*70)
    
    try:
        char_info = state['character_info']
        
        prompt = f"""
T·∫°o d√†n √Ω cho m·ªôt c√¢u chuy·ªán ng·∫Øn v·ªÅ {char_info['name']}.

TH√îNG TIN NH√ÇN V·∫¨T:
- Xu·∫•t x·ª©: {char_info['origin']}
- T√≠nh c√°ch: {', '.join(char_info['personality'])}

CH·ª¶ ƒê·ªÄ: {state['story_theme']}
ƒê·ªò D√ÄI: {state['story_length']} t·ª´

JSON FORMAT:
{{
    "title": "Ti√™u ƒë·ªÅ h·∫•p d·∫´n",
    "setting": "B·ªëi c·∫£nh",
    "act1": "M·ªü ƒë·∫ßu",
    "act2": "Ph√°t tri·ªÉn",
    "act3": "K·∫øt th√∫c",
    "moral": "B√†i h·ªçc"
}}
"""
        
        response = call_gemini(prompt)
        
        json_str = response
        if '```json' in response:
            json_str = response.split('```json')[1].split('```')[0]
        elif '```' in response:
            json_str = response.split('```')[1].split('```')[0]
        
        outline = json.loads(json_str.strip())
        state['story_outline'] = outline
        
        print(f"\n‚úÖ Outline: {outline['title']}")
        state['execution_log'].append("‚úì Outline created")
        
    except Exception as e:
        print(f"‚ùå Outline error: {e}")
        state['error'] = f"Outline failed: {e}"
    
    return state


def story_writer_agent(state: StoryArtState) -> StoryArtState:
    """Agent vi·∫øt n·ªôi dung truy·ªán"""
    
    if state['mode'] == 'art_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("‚úçÔ∏è STORY WRITER AGENT")
    print("="*70)
    
    try:
        char_info = state['character_info']
        outline = state['story_outline']
        
        prompt = f"""
Vi·∫øt m·ªôt c√¢u chuy·ªán ho√†n ch·ªânh v·ªÅ {char_info['name']}.

TI√äU ƒê·ªÄ: {outline['title']}
D√ÄN √ù:
- M·ªü ƒë·∫ßu: {outline['act1']}
- Ph√°t tri·ªÉn: {outline['act2']}
- K·∫øt th√∫c: {outline['act3']}

Y√äU C·∫¶U:
- ƒê·ªô d√†i: {state['story_length']} t·ª´
- Ng√¥n ng·ªØ: Ti·∫øng Vi·ªát, sinh ƒë·ªông
- C√≥ tho·∫°i tr·ª±c ti·∫øp

Ch·ªâ vi·∫øt n·ªôi dung truy·ªán.
"""
        
        print("   ü§ñ AI ƒëang vi·∫øt truy·ªán...")
        response = call_gemini(prompt)
        
        story_content = f"""
{'='*70}
{outline['title'].upper()}
{'='*70}

{response.strip()}

{'='*70}
B√†i h·ªçc: {outline['moral']}
{'='*70}
"""
        
        state['story_content'] = story_content
        
        word_count = len(response.split())
        print(f"\n‚úÖ Story written: {word_count} words")
        state['execution_log'].append(f"‚úì Story: {word_count} words")
        
    except Exception as e:
        print(f"‚ùå Writer error: {e}")
        state['error'] = f"Writer failed: {e}"
    
    return state


def story_formatter_agent(state: StoryArtState) -> StoryArtState:
    """Agent m·ªü Notepad v√† ghi truy·ªán"""
    
    if state['mode'] == 'art_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("üíæ STORY FORMATTER AGENT")
    print("="*70)
    
    try:
        # 1. M·ªü Notepad
        print("   üìù Opening Notepad...")
        subprocess.Popen(['notepad'])
        time.sleep(2)
        
        # 2. Maximize
        pyautogui.hotkey('win', 'up')
        time.sleep(0.5)
        
        # 3. Paste n·ªôi dung
        print("   ‚å®Ô∏è  Pasting story content...")
        pyperclip.copy(state['story_content'])
        pyautogui.hotkey('ctrl', 'v')
        time.sleep(1)
        
        # 4. Save file
        print("   üíæ Saving file...")
        pyautogui.hotkey('ctrl', 's')
        time.sleep(1)
        
        # T·∫°o t√™n file
        char_name = state['character_name'].replace(' ', '_')
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"story_{char_name}_{timestamp}.txt"
        
        pyperclip.copy(filename)
        pyautogui.hotkey('ctrl', 'a')
        time.sleep(0.2)
        pyautogui.hotkey('ctrl', 'v')
        time.sleep(0.5)
        
        pyautogui.press('enter')
        time.sleep(0.5)
        
        state['story_file_path'] = filename
        
        print(f"\n‚úÖ Story saved: {filename}")
        state['execution_log'].append(f"‚úì Saved: {filename}")
        
        # ƒê√≥ng Notepad
        print("   üö™ Closing Notepad...")
        time.sleep(1)
        pyautogui.hotkey('alt', 'f4')
        time.sleep(1)
        
    except Exception as e:
        print(f"‚ùå Formatter error: {e}")
        state['error'] = f"Formatter failed: {e}"
    
    return state


# ============ AGENT 2: ART CREATOR ============
def art_preparation_agent(state: StoryArtState) -> StoryArtState:
    """Agent chu·∫©n b·ªã ·∫£nh tham kh·∫£o v√† m·ªü Paint - FIXED VERSION"""
    
    if state['mode'] == 'story_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("üé® ART PREPARATION AGENT")
    print("="*70)
    
    IMAGE_FOLDER = "images"
    char_name = state['character_name'].replace(' ', '_').lower()
    REFERENCE_IMAGE_PATH = os.path.join(IMAGE_FOLDER, f"{char_name}.jpg")
    
    try:
        # 1. Ki·ªÉm tra ·∫£nh tham kh·∫£o
        if not os.path.exists(REFERENCE_IMAGE_PATH):
            REFERENCE_IMAGE_PATH = os.path.join(IMAGE_FOLDER, f"{char_name}.png")
            
            if not os.path.exists(REFERENCE_IMAGE_PATH):
                print(f"\n‚ö†Ô∏è  Kh√¥ng t√¨m th·∫•y ·∫£nh: {REFERENCE_IMAGE_PATH}")
                
                import webbrowser
                search_url = f"https://www.google.com/search?q={state['character_name']}+simple+drawing&tbm=isch"
                webbrowser.open(search_url)
                
                input("\n   ‚è∏Ô∏è  T·∫£i ·∫£nh v√† l∆∞u v√†o images/, nh·∫•n Enter...")
                
                if not os.path.exists(REFERENCE_IMAGE_PATH):
                    raise FileNotFoundError(f"Kh√¥ng t√¨m th·∫•y: {REFERENCE_IMAGE_PATH}")
        
        print(f"   ‚úÖ Found: {REFERENCE_IMAGE_PATH}")
        
        # 2. ƒê∆°n gi·∫£n h√≥a ·∫£nh
        print("   üñºÔ∏è  Simplifying image...")
        simplified_path = simplify_image_for_drawing(REFERENCE_IMAGE_PATH)
        
        # 3. Load ·∫£nh v√†o state
        state['reference_image_b64'] = image_to_base64(simplified_path)
        
        # 4. Setup Paint - PH∆Ø∆†NG PH√ÅP AN TO√ÄN (kh√¥ng d√πng activate())
        print("\n   üîç Setting up Paint...")
        paint_windows = gw.getWindowsWithTitle('Paint')
        
        if paint_windows:
            print("   ‚úÖ Paint ƒë√£ m·ªü")
            paint_window = paint_windows[0]
            
            # Ch·ªâ d√πng maximize v√† click, KH√îNG d√πng activate()
            try:
                if not paint_window.isMaximized:
                    print("   üìê Maximizing Paint...")
                    paint_window.maximize()
                    time.sleep(1.0)
                else:
                    print("   ‚úÖ Paint ƒë√£ maximized")
            except Exception as e:
                print(f"   ‚ö†Ô∏è  Maximize error: {e}, using keyboard shortcut...")
                pyautogui.hotkey('win', 'up')
                time.sleep(1.0)
            
            # Focus b·∫±ng c√°ch click v√†o window (AN TO√ÄN h∆°n activate())
            print("   üñ±Ô∏è  Focusing Paint window...")
            try:
                # Click v√†o gi·ªØa window
                x, y, w, h = paint_window.left, paint_window.top, paint_window.width, paint_window.height
                pyautogui.click(x + w // 2, y + h // 2)
                time.sleep(0.5)
            except:
                # Fallback: click v√†o gi·ªØa m√†n h√¨nh
                screen_w, screen_h = pyautogui.size()
                pyautogui.click(screen_w // 2, screen_h // 2)
                time.sleep(0.5)
            
        else:
            # 5. M·ªü Paint m·ªõi
            print("   üé® Opening new Paint...")
            subprocess.Popen(['mspaint'])
            time.sleep(3.5)
            
            # Maximize b·∫±ng keyboard
            print("   üìê Maximizing Paint...")
            pyautogui.hotkey('win', 'up')
            time.sleep(1.0)
            
            # Click ƒë·ªÉ focus
            screen_w, screen_h = pyautogui.size()
            pyautogui.click(screen_w // 2, screen_h // 2)
            time.sleep(0.5)
        
        # 6. Click v√†o canvas area ƒë·ªÉ ƒë·∫£m b·∫£o ready
        print("   üñ±Ô∏è  Preparing canvas...")
        pyautogui.click(700, 400)
        time.sleep(0.5)
        
        # 7. Ch·ª•p screenshot Paint
        print("   üì∏ Capturing Paint interface...")
        time.sleep(1.0)
        state['paint_screenshot_b64'] = screenshot_to_base64()
        
        print("   ‚úÖ Paint setup complete!")
        state['execution_log'].append("‚úì Preparation: Paint ready")
        
    except Exception as e:
        print(f"‚ùå Preparation error: {e}")
        state['error'] = f"Preparation failed: {e}"
        traceback.print_exc()
    
    return state

def art_cv_analyzer_agent(state: StoryArtState) -> StoryArtState:
    """
    Agent ph√¢n t√≠ch giao di·ªán Paint b·∫±ng Computer Vision
    """
    
    if state['mode'] == 'story_only' or state['error']:
        return state
    
    try:
        # Ph√¢n t√≠ch b·∫±ng CV
        cv_result = analyze_paint_interface(state['paint_screenshot_b64'])
        
        # L∆∞u v√†o state
        state['canvas_area'] = cv_result['canvas_area']
        state['color_positions'] = cv_result['color_positions']
        state['tool_positions'] = cv_result['tool_positions']
        
        state['execution_log'].append("‚úì CV Analysis: Interface detected")
        
    except Exception as e:
        print(f"‚ùå CV Analyzer error: {e}")
        state['error'] = f"CV Analysis failed: {e}"
        traceback.print_exc()
    
    return state


def art_llm_planner_agent(state: StoryArtState) -> StoryArtState:
    """
    Agent d√πng LLM ƒë·ªÉ t·∫°o k·∫ø ho·∫°ch v·∫Ω D·ª±A TR√äN T·ªåA ƒê·ªò TH·∫¨T t·ª´ CV
    """
    
    if state['mode'] == 'story_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("üß† LLM PLANNER AGENT (AI Strategy)")
    print("="*70)
    
    try:
        canvas = state['canvas_area']
        colors = list(state['color_positions'].keys())
        tools = list(state['tool_positions'].keys())
        
        # Load reference image
        ref_img = Image.open(BytesIO(base64.b64decode(state['reference_image_b64'])))
        ref_img.thumbnail((800, 800), Image.Resampling.LANCZOS)
        
        prompt = f"""
B·∫°n l√† AI Drawing Planner. T·∫°o k·∫ø ho·∫°ch v·∫Ω "{state['character_name']}" trong Paint.

TH√îNG TIN CANVAS (ƒë√£ ƒë∆∞·ª£c Computer Vision ph√°t hi·ªán):
- V·ªã tr√≠: ({canvas['x']}, {canvas['y']})
- K√≠ch th∆∞·ªõc: {canvas['width']}x{canvas['height']}
- V√πng v·∫Ω h·ª£p l·ªá:
  * X: t·ª´ {canvas['x']} ƒë·∫øn {canvas['x'] + canvas['width']}
  * Y: t·ª´ {canvas['y']} ƒë·∫øn {canvas['y'] + canvas['height']}

TOOLS C√ì S·∫¥N: {', '.join(tools)}
COLORS C√ì S·∫¥N: {', '.join(colors)}

Y√äU C·∫¶U:
1. Ph√¢n t√≠ch ·∫£nh tham kh·∫£o
2. T·∫°o 5-7 b∆∞·ªõc v·∫Ω ƒê∆†N GI·∫¢N
3. D√πng oval/rectangle cho h√¨nh c∆° b·∫£n
4. D√πng fill ƒë·ªÉ t√¥ m√†u
5. T·ªåA ƒê·ªò PH·∫¢I N·∫∞M TRONG CANVAS!

JSON FORMAT:
{{
  "analysis": "M√¥ t·∫£ ng·∫Øn v·ªÅ nh√¢n v·∫≠t v√† c√°ch v·∫Ω",
  "steps": [
    {{
      "step": 1,
      "description": "V·∫Ω ƒë·∫ßu (oval l·ªõn)",
      "tool": "oval",
      "color": "black",
      "action": "drag",
      "start_x": {canvas['x'] + 200},
      "start_y": {canvas['y'] + 100},
      "end_x": {canvas['x'] + 400},
      "end_y": {canvas['y'] + 250}
    }},
    {{
      "step": 2,
      "description": "T√¥ m√†u ƒë·∫ßu",
      "tool": "fill",
      "color": "yellow",
      "action": "click",
      "click_x": {canvas['x'] + 300},
      "click_y": {canvas['y'] + 175}
    }},
    {{
      "step": 3,
      "description": "V·∫Ω th√¢n (rectangle)",
      "tool": "rectangle",
      "color": "red",
      "action": "drag",
      "start_x": {canvas['x'] + 250},
      "start_y": {canvas['y'] + 250},
      "end_x": {canvas['x'] + 350},
      "end_y": {canvas['y'] + 400}
    }}
  ]
}}

‚ö†Ô∏è QUAN TR·ªåNG:
- action="drag" c·∫ßn: start_x, start_y, end_x, end_y
- action="click" c·∫ßn: click_x, click_y
- T·∫§T C·∫¢ t·ªça ƒë·ªô PH·∫¢I trong kho·∫£ng canvas ƒë√£ cho
- CH·ªà d√πng tools v√† colors c√≥ s·∫µn
"""
        
        print("   ü§ñ LLM analyzing reference image and creating plan...")
        response = call_gemini_vision(prompt, [ref_img])
        
        # Extract JSON
        json_str = response
        if '```json' in response:
            json_str = response.split('```json')[1].split('```')[0]
        elif '```' in response:
            json_str = response.split('```')[1].split('```')[0]
        
        plan = json.loads(json_str.strip())
        
        print(f"\n   üìã AI Analysis: {plan.get('analysis', 'N/A')}")
        
        # VALIDATE v√† CLAMP t·ªça ƒë·ªô
        validated_steps = []
        for step in plan.get('steps', []):
            # Ki·ªÉm tra tool v√† color c√≥ t·ªìn t·∫°i kh√¥ng
            if step.get('tool') not in tools:
                print(f"      ‚ö†Ô∏è  Step {step['step']}: Tool '{step.get('tool')}' not available, using 'pencil'")
                step['tool'] = 'pencil' if 'pencil' in tools else tools[0]
            
            if step.get('color') not in colors:
                print(f"      ‚ö†Ô∏è  Step {step['step']}: Color '{step.get('color')}' not available, using 'black'")
                step['color'] = 'black' if 'black' in colors else colors[0]
            
            # Clamp t·ªça ƒë·ªô v√†o canvas
            if step.get('action') == 'drag':
                step['start_x'] = max(canvas['x'], min(step['start_x'], canvas['x'] + canvas['width']))
                step['start_y'] = max(canvas['y'], min(step['start_y'], canvas['y'] + canvas['height']))
                step['end_x'] = max(canvas['x'], min(step['end_x'], canvas['x'] + canvas['width']))
                step['end_y'] = max(canvas['y'], min(step['end_y'], canvas['y'] + canvas['height']))
            
            elif step.get('action') == 'click':
                step['click_x'] = max(canvas['x'], min(step['click_x'], canvas['x'] + canvas['width']))
                step['click_y'] = max(canvas['y'], min(step['click_y'], canvas['y'] + canvas['height']))
            
            validated_steps.append(step)
        
        state['drawing_steps'] = validated_steps
        state['total_steps'] = len(validated_steps)
        state['current_step'] = 0
        
        print(f"\n‚úÖ Drawing plan created: {state['total_steps']} steps")
        for step in validated_steps:
            print(f"   Step {step['step']}: {step['description']}")
            if step.get('action') == 'drag':
                print(f"      ‚Üí Drag from ({step['start_x']},{step['start_y']}) to ({step['end_x']},{step['end_y']})")
            elif step.get('action') == 'click':
                print(f"      ‚Üí Click at ({step['click_x']},{step['click_y']})")
        
        state['execution_log'].append(f"‚úì LLM Plan: {state['total_steps']} steps")
        
    except Exception as e:
        print(f"‚ùå LLM Planner error: {e}")
        state['error'] = f"LLM Planner failed: {e}"
        traceback.print_exc()
    
    return state


def art_executor_agent(state: StoryArtState) -> StoryArtState:
    """Agent th·ª±c thi v·∫Ω TO√ÄN B·ªò c√°c b∆∞·ªõc"""
    
    if state['mode'] == 'story_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("‚öôÔ∏è ART EXECUTOR AGENT - FULL AUTO DRAWING")
    print("="*70)
    
    tool_positions = state['tool_positions']
    color_positions = state['color_positions']
    steps = state['drawing_steps']
    
    try:
        for i, step_data in enumerate(steps):
            step_num = i + 1
            print(f"\n   [{step_num}/{len(steps)}] {step_data['description']}")
            
            tool = step_data.get('tool', 'pencil')
            color = step_data.get('color', 'black')
            action = step_data.get('action', 'drag')
            
            # 1. Ch·ªçn tool
            if tool in tool_positions:
                tool_pos = tool_positions[tool]
                print(f"      üîß Tool: {tool} at ({tool_pos['x']}, {tool_pos['y']})")
                pyautogui.click(tool_pos['x'], tool_pos['y'])
                time.sleep(0.3)
            else:
                print(f"      ‚ö†Ô∏è  Tool '{tool}' not found!")
            
            # 2. Ch·ªçn m√†u
            if color in color_positions:
                color_pos = color_positions[color]
                print(f"      üé® Color: {color} at ({color_pos['x']}, {color_pos['y']})")
                pyautogui.click(color_pos['x'], color_pos['y'])
                time.sleep(0.3)
            else:
                print(f"      ‚ö†Ô∏è  Color '{color}' not found!")
            
            # 3. Th·ª±c hi·ªán v·∫Ω
            if action == 'drag':
                sx = step_data.get('start_x')
                sy = step_data.get('start_y')
                ex = step_data.get('end_x')
                ey = step_data.get('end_y')
                
                print(f"      ‚úèÔ∏è  Dragging from ({sx},{sy}) to ({ex},{ey})...")
                
                pyautogui.moveTo(sx, sy, duration=0.2)
                time.sleep(0.1)
                pyautogui.drag(ex - sx, ey - sy, duration=0.5, button='left')
                
            elif action == 'click':
                cx = step_data.get('click_x')
                cy = step_data.get('click_y')
                
                print(f"      üñ±Ô∏è  Clicking at ({cx},{cy})...")
                pyautogui.click(cx, cy)
            
            time.sleep(0.5)
            print(f"      ‚úÖ Step {step_num} done!")
        
        # Ho√†n th√†nh
        state['current_step'] = len(steps)
        state['is_complete'] = True
        
        print(f"\n   üéâ ALL {len(steps)} STEPS COMPLETED!")
        state['execution_log'].append(f"‚úì Drawing: {len(steps)} steps completed")
        
        # L∆∞u ·∫£nh
        print("\n   üíæ Saving final drawing...")
        time.sleep(1)
        
        char_name = state['character_name'].replace(' ', '_')
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"drawing_{char_name}_{timestamp}.png"
        
        screenshot = pyautogui.screenshot()
        screenshot.save(filename)
        
        print(f"   ‚úÖ Saved: {filename}")
        state['execution_log'].append(f"‚úì Image: {filename}")
        
    except Exception as e:
        print(f"‚ùå Executor error: {e}")
        state['error'] = f"Executor failed: {e}"
        traceback.print_exc()
    
    return state


# ============ BUILD WORKFLOW ============

def build_workflow(mode: str):
    """Build workflow d·ª±a tr√™n mode"""
    workflow = StateGraph(StoryArtState)
    
    if mode == "story_only":
        workflow.add_node("story_research", story_research_agent)
        workflow.add_node("story_outline", story_outline_agent)
        workflow.add_node("story_writer", story_writer_agent)
        workflow.add_node("story_formatter", story_formatter_agent)
        
        workflow.set_entry_point("story_research")
        workflow.add_edge("story_research", "story_outline")
        workflow.add_edge("story_outline", "story_writer")
        workflow.add_edge("story_writer", "story_formatter")
        workflow.add_edge("story_formatter", END)
        
    elif mode == "art_only":
        workflow.add_node("art_preparation", art_preparation_agent)
        workflow.add_node("art_cv_analyzer", art_cv_analyzer_agent)
        workflow.add_node("art_llm_planner", art_llm_planner_agent)
        workflow.add_node("art_executor", art_executor_agent)
        
        workflow.set_entry_point("art_preparation")
        workflow.add_edge("art_preparation", "art_cv_analyzer")
        workflow.add_edge("art_cv_analyzer", "art_llm_planner")
        workflow.add_edge("art_llm_planner", "art_executor")
        workflow.add_edge("art_executor", END)
        
    else:  # full
        workflow.add_node("story_research", story_research_agent)
        workflow.add_node("story_outline", story_outline_agent)
        workflow.add_node("story_writer", story_writer_agent)
        workflow.add_node("story_formatter", story_formatter_agent)
        workflow.add_node("art_preparation", art_preparation_agent)
        workflow.add_node("art_cv_analyzer", art_cv_analyzer_agent)
        workflow.add_node("art_llm_planner", art_llm_planner_agent)
        workflow.add_node("art_executor", art_executor_agent)
        
        workflow.set_entry_point("story_research")
        workflow.add_edge("story_research", "story_outline")
        workflow.add_edge("story_outline", "story_writer")
        workflow.add_edge("story_writer", "story_formatter")
        workflow.add_edge("story_formatter", "art_preparation")
        workflow.add_edge("art_preparation", "art_cv_analyzer")
        workflow.add_edge("art_cv_analyzer", "art_llm_planner")
        workflow.add_edge("art_llm_planner", "art_executor")
        workflow.add_edge("art_executor", END)
    
    return workflow.compile()


# ============ MAIN ============

def main():
    """Main function"""
    print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë          üé®üìù ANIME STORY STUDIO V4                       ‚ïë
‚ïë          Hybrid CV + LLM - Smart Drawing                  ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)
    
    print("\nüìã MENU:")
    print("  1. Vi·∫øt truy·ªán + V·∫Ω nh√¢n v·∫≠t (Full Auto)")
    print("  2. Ch·ªâ vi·∫øt truy·ªán (Story Only)")
    print("  3. Ch·ªâ v·∫Ω tranh (Art Only)")
    print("  0. Tho√°t")
    
    choice = input("\nüëâ Ch·ªçn ch·ª©c nƒÉng (1-3): ").strip()
    
    if choice == '0':
        print("üëã Goodbye!")
        return
    
    # X√°c ƒë·ªãnh mode
    mode_map = {
        '1': 'full',
        '2': 'story_only',
        '3': 'art_only'
    }
    mode = mode_map.get(choice, 'full')
    
    # Input th√¥ng tin
    print("\n" + "="*60)
    character_name = input("üé≠ Nh·∫≠p t√™n nh√¢n v·∫≠t (VD: Doraemon, Pikachu, Naruto): ").strip()
    
    if not character_name:
        character_name = "Doraemon"
        print(f"   ‚ö†Ô∏è  S·ª≠ d·ª•ng m·∫∑c ƒë·ªãnh: {character_name}")
    
    story_theme = "adventure"
    story_length = 200
    
    if mode in ['full', 'story_only']:
        story_theme = input("üìñ Ch·ªß ƒë·ªÅ truy·ªán (adventure/friendship/funny): ").strip() or "adventure"
        story_length_input = input("üìè ƒê·ªô d√†i truy·ªán (s·ªë t·ª´, VD: 500): ").strip()
        try:
            story_length = int(story_length_input)
        except:
            story_length = 200
    
    # Kh·ªüi t·∫°o state
    initial_state = StoryArtState(
        character_name=character_name,
        story_theme=story_theme,
        story_length=story_length,
        mode=mode,
        character_info={},
        story_outline={},
        story_content="",
        story_file_path="",
        reference_image_b64="",
        paint_screenshot_b64="",
        tool_positions={},
        color_positions={},
        canvas_area={},
        drawing_steps=[],
        current_step=0,
        total_steps=0,
        execution_log=[],
        is_complete=False,
        error=""
    )
    
    # Build v√† ch·∫°y workflow
    print("\nüöÄ Starting automation...")
    print("‚ö†Ô∏è  Script s·∫Ω ƒëi·ªÅu khi·ªÉn chu·ªôt v√† b√†n ph√≠m!")
    print("‚ö†Ô∏è  KH√îNG DI CHUY·ªÇN CHU·ªòT trong qu√° tr√¨nh v·∫Ω!")
    time.sleep(3)
    
    graph = build_workflow(mode)
    
    try:
        final_state = graph.invoke(initial_state)
        
        # Summary
        print("\n" + "="*70)
        print("üìä EXECUTION SUMMARY")
        print("="*70)
        
        if final_state.get('error'):
            print(f"‚ùå Error: {final_state['error']}")
        else:
            print("‚úÖ Status: Completed!")
            
            if final_state.get('story_file_path'):
                print(f"üìù Story: {final_state['story_file_path']}")
            
            if final_state.get('is_complete'):
                print(f"üé® Drawing: {final_state['total_steps']} steps completed")
        
        print("\nüìú Execution Log:")
        for log in final_state.get('execution_log', []):
            print(f"  {log}")
        
    except Exception as e:
        print(f"\nüí• Critical error: {e}")
        traceback.print_exc()
    
    print("\n" + "="*70)
    print("ü§ñ Automation finished!")


if __name__ == "__main__":
    main()