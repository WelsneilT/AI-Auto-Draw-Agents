"""
======================================================================================
ANIME STORY STUDIO V4 - HYBRID CV + LLM
Computer Vision Ä‘á»ƒ detect interface + LLM Ä‘á»ƒ táº¡o lá»‡nh váº½ thÃ´ng minh
======================================================================================
"""

import os
import time
import base64
import json
import subprocess
from io import BytesIO
from datetime import datetime
from dotenv import load_dotenv
from PIL import Image
import pyautogui
import cv2
import numpy as np
from typing import TypedDict, List, Dict, Tuple
from langgraph.graph import StateGraph, END
import google.generativeai as genai
import traceback
import pyperclip
import pygetwindow as gw
# Load environment
load_dotenv()
genai.configure(api_key=os.getenv('GOOGLE_API_KEY'))

# Táº¯t fail-safe
pyautogui.FAILSAFE = False
pyautogui.PAUSE = 0.05

# ============ SHARED STATE ============

class StoryArtState(TypedDict):
    """State chung cho cáº£ 2 agents"""
    # User Input
    character_name: str
    story_theme: str
    story_length: int
    mode: str
    
    # Story Writer State
    character_info: Dict
    story_outline: Dict
    story_content: str
    story_file_path: str
    
    # Art Creator State
    reference_image_b64: str
    paint_screenshot_b64: str
    tool_positions: Dict
    color_positions: Dict
    canvas_area: Dict
    drawing_steps: List[Dict]
    current_step: int
    total_steps: int
    
    # Shared
    execution_log: List[str]
    is_complete: bool
    error: str


# ============ UTILITY FUNCTIONS ============

def screenshot_to_base64(region=None) -> str:
    """Chá»¥p mÃ n hÃ¬nh vÃ  convert sang base64"""
    if region:
        screenshot = pyautogui.screenshot(region=region)
    else:
        screenshot = pyautogui.screenshot()
    buffered = BytesIO()
    screenshot.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode()

def image_to_base64(image_path: str) -> str:
    """Convert áº£nh file sang base64"""
    with open(image_path, 'rb') as f:
        return base64.b64encode(f.read()).decode()

def call_gemini(prompt: str) -> str:
    """Gá»i Gemini text-only"""
    model = genai.GenerativeModel('gemini-2.0-flash-exp')
    response = model.generate_content(prompt)
    return response.text

def call_gemini_vision(prompt: str, images: List[Image.Image]) -> str:
    """Gá»i Gemini vá»›i vision"""
    model = genai.GenerativeModel('gemini-2.0-flash-exp')
    content = images + [prompt]
    response = model.generate_content(content)
    return response.text

def simplify_image_for_drawing(image_path: str, output_path: str = "simplified.png"):
    """ÄÆ¡n giáº£n hÃ³a áº£nh thÃ nh dáº¡ng cartoon/sketch dá»… váº½"""
    img = cv2.imread(image_path)
    
    # Resize vá» kÃ­ch thÆ°á»›c vá»«a pháº£i
    height, width = img.shape[:2]
    max_size = 300
    if max(height, width) > max_size:
        scale = max_size / max(height, width)
        img = cv2.resize(img, None, fx=scale, fy=scale)
    
    # Chuyá»ƒn sang cartoon style
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    gray = cv2.medianBlur(gray, 5)
    
    # Detect edges
    edges = cv2.adaptiveThreshold(
        gray, 255, 
        cv2.ADAPTIVE_THRESH_MEAN_C, 
        cv2.THRESH_BINARY, 
        9, 9
    )
    
    # Smooth colors
    color = cv2.bilateralFilter(img, 9, 250, 250)
    
    # Combine
    cartoon = cv2.bitwise_and(color, color, mask=edges)
    
    cv2.imwrite(output_path, cartoon)
    print(f"   âœ… Simplified image saved: {output_path}")
    return output_path


# ============ COMPUTER VISION MODULE ============

def detect_canvas_area(img_cv: np.ndarray) -> Dict:
    """
    TÃ¬m vÃ¹ng canvas (vÃ¹ng tráº¯ng lá»›n nháº¥t) trong Paint
    """
    print("   ğŸ” Detecting canvas area...")
    
    # Convert to grayscale
    gray = cv2.cvtColor(img_cv, cv2.COLOR_BGR2GRAY)
    
    # Threshold Ä‘á»ƒ tÃ¬m vÃ¹ng tráº¯ng (canvas)
    _, binary = cv2.threshold(gray, 240, 255, cv2.THRESH_BINARY)
    
    # TÃ¬m contours
    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    
    if not contours:
        raise Exception("Cannot find canvas area!")
    
    # TÃ¬m contour lá»›n nháº¥t (canvas)
    canvas_contour = max(contours, key=cv2.contourArea)
    x, y, w, h = cv2.boundingRect(canvas_contour)
    
    # ThÃªm margin nhá» Ä‘á»ƒ trÃ¡nh váº½ sÃ¡t mÃ©p
    margin = 20
    canvas = {
        'x': x + margin,
        'y': y + margin,
        'width': w - 2*margin,
        'height': h - 2*margin
    }
    
    print(f"   âœ… Canvas: ({canvas['x']}, {canvas['y']}) - {canvas['width']}x{canvas['height']}")
    
    return canvas


def detect_color_palette(img_cv: np.ndarray) -> Dict:
    """
    TÃ¬m vá»‹ trÃ­ cÃ¡c mÃ u trong báº£ng mÃ u Paint báº±ng color matching
    """
    print("   ğŸ¨ Detecting color palette...")
    
    screen_height, screen_width = img_cv.shape[:2]
    
    # VÃ¹ng chá»©a colors thÆ°á»ng á»Ÿ phÃ­a trÃªn, giá»¯a mÃ n hÃ¬nh
    # Äiá»u chá»‰nh theo layout Paint
    color_region_y1 = 50
    color_region_y2 = 110
    color_region_x1 = int(screen_width * 0.3)
    color_region_x2 = int(screen_width * 0.7)
    
    color_region = img_cv[color_region_y1:color_region_y2, color_region_x1:color_region_x2]
    
    # Äá»‹nh nghÄ©a mÃ u cáº§n tÃ¬m (BGR format + tolerance)
    color_targets = {
        'black': ([0, 0, 0], 30),
        'white': ([255, 255, 255], 30),
        'gray': ([128, 128, 128], 40),
        'red': ([0, 0, 200], 60),
        'orange': ([0, 165, 255], 60),
        'yellow': ([0, 255, 255], 60),
        'green': ([0, 200, 0], 60),
        'blue': ([200, 0, 0], 60),
        'purple': ([200, 0, 200], 60),
        'brown': ([42, 82, 165], 60)
    }
    
    color_positions = {}
    
    for color_name, (target_bgr, tolerance) in color_targets.items():
        # Táº¡o mask cho mÃ u
        lower = np.array([max(0, c - tolerance) for c in target_bgr])
        upper = np.array([min(255, c + tolerance) for c in target_bgr])
        
        mask = cv2.inRange(color_region, lower, upper)
        
        # TÃ¬m vá»‹ trÃ­
        coords = cv2.findNonZero(mask)
        if coords is not None and len(coords) > 10:  # Äá»§ lá»›n
            # Láº¥y tÃ¢m cá»§a vÃ¹ng mÃ u
            M = cv2.moments(mask)
            if M["m00"] != 0:
                cx = int(M["m10"] / M["m00"]) + color_region_x1
                cy = int(M["m01"] / M["m00"]) + color_region_y1
                color_positions[color_name] = {'x': cx, 'y': cy}
                print(f"      â€¢ {color_name}: ({cx}, {cy})")
    
    if len(color_positions) < 3:
        print("      âš ï¸  Warning: Only found", len(color_positions), "colors")
    
    return color_positions


def detect_tool_positions(img_cv: np.ndarray) -> Dict:
    """
    TÃ¬m vá»‹ trÃ­ cÃ¡c tools trong Paint
    DÃ¹ng heuristic + pattern matching
    """
    print("   ğŸ”§ Detecting tool positions...")
    
    screen_height, screen_width = img_cv.shape[:2]
    
    # Paint tools thÆ°á»ng á»Ÿ bÃªn trÃ¡i hoáº·c phÃ­a trÃªn
    # Ta dÃ¹ng heuristic dá»±a trÃªn layout chuáº©n cá»§a Paint
    
    # VÃ¹ng tools (phÃ­a trÃªn, bÃªn trÃ¡i)
    tool_region_y = 60
    tool_region_x_start = 150
    tool_spacing = 30
    
    tool_positions = {
        'pencil': {'x': tool_region_x_start, 'y': tool_region_y},
        'fill': {'x': tool_region_x_start + tool_spacing, 'y': tool_region_y + 20},
        'eraser': {'x': tool_region_x_start + tool_spacing*2, 'y': tool_region_y},
        'color_picker': {'x': tool_region_x_start + tool_spacing*3, 'y': tool_region_y},
        'text': {'x': tool_region_x_start + tool_spacing*4, 'y': tool_region_y},
        'line': {'x': tool_region_x_start + tool_spacing*5, 'y': tool_region_y},
        'curve': {'x': tool_region_x_start + tool_spacing*6, 'y': tool_region_y},
        'rectangle': {'x': tool_region_x_start + tool_spacing*7, 'y': tool_region_y},
        'oval': {'x': tool_region_x_start + tool_spacing*8, 'y': tool_region_y},
        'brush': {'x': tool_region_x_start + tool_spacing*1, 'y': tool_region_y}
    }
    
    print(f"      â€¢ Estimated {len(tool_positions)} tool positions")
    
    return tool_positions


def analyze_paint_interface(screenshot_b64: str) -> Dict:
    """
    MAIN FUNCTION: PhÃ¢n tÃ­ch toÃ n bá»™ giao diá»‡n Paint báº±ng Computer Vision
    """
    print("\n" + "="*70)
    print("ğŸ”¬ COMPUTER VISION ANALYSIS")
    print("="*70)
    
    # Decode screenshot
    img_data = base64.b64decode(screenshot_b64)
    img_pil = Image.open(BytesIO(img_data))
    img_cv = cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)
    
    screen_height, screen_width = img_cv.shape[:2]
    print(f"   ğŸ“ Screen resolution: {screen_width}x{screen_height}")
    
    # 1. Detect Canvas
    canvas_area = detect_canvas_area(img_cv)
    
    # 2. Detect Colors
    color_positions = detect_color_palette(img_cv)
    
    # 3. Detect Tools
    tool_positions = detect_tool_positions(img_cv)
    
    print("\nâœ… Computer Vision Analysis Complete!")
    
    return {
        'canvas_area': canvas_area,
        'color_positions': color_positions,
        'tool_positions': tool_positions,
        'screen_width': screen_width,
        'screen_height': screen_height
    }


# ============ AGENT 1: STORY WRITER ============

def story_research_agent(state: StoryArtState) -> StoryArtState:
    """Agent tÃ¬m kiáº¿m thÃ´ng tin vá» nhÃ¢n váº­t"""
    
    if state['mode'] == 'art_only':
        print("\nâ© Skipping story research (art_only mode)")
        return state
    
    print("\n" + "="*70)
    print("ğŸ“š STORY RESEARCH AGENT")
    print("="*70)
    
    try:
        prompt = f"""
TÃ¬m kiáº¿m thÃ´ng tin vá» nhÃ¢n váº­t hoáº¡t hÃ¬nh "{state['character_name']}".

Tráº£ vá» JSON vá»›i format:
{{
    "name": "TÃªn nhÃ¢n váº­t",
    "origin": "Xuáº¥t xá»© (anime/cartoon nÃ o)",
    "personality": ["TÃ­nh cÃ¡ch 1", "TÃ­nh cÃ¡ch 2", ...],
    "appearance": "MÃ´ táº£ ngoáº¡i hÃ¬nh",
    "special_abilities": ["Kháº£ nÄƒng Ä‘áº·c biá»‡t 1", ...],
    "famous_quotes": ["CÃ¢u nÃ³i ná»•i tiáº¿ng 1", ...]
}}
"""
        
        response = call_gemini(prompt)
        
        # Extract JSON
        json_str = response
        if '```json' in response:
            json_str = response.split('```json')[1].split('```')[0]
        elif '```' in response:
            json_str = response.split('```')[1].split('```')[0]
        
        character_info = json.loads(json_str.strip())
        state['character_info'] = character_info
        
        print(f"\nâœ… Found info about: {character_info['name']}")
        print(f"   Origin: {character_info['origin']}")
        
        state['execution_log'].append(f"âœ“ Research: Found info about {character_info['name']}")
        
    except Exception as e:
        print(f"âŒ Research error: {e}")
        state['error'] = f"Research failed: {e}"
    
    return state


def maximize_paint_safely():
    """
    Maximize Paint má»™t cÃ¡ch AN TOÃ€N - chá»‰ maximize khi chÆ°a full
    """
    try:
        # TÃ¬m window Paint
        paint_windows = gw.getWindowsWithTitle('Paint')
        
        if not paint_windows:
            print("   âš ï¸  KhÃ´ng tÃ¬m tháº¥y Paint window!")
            return False
        
        paint_window = paint_windows[0]
        
        # Kiá»ƒm tra tráº¡ng thÃ¡i
        if paint_window.isMaximized:
            print("   âœ… Paint Ä‘Ã£ maximized rá»“i, khÃ´ng cáº§n lÃ m gÃ¬")
        else:
            print("   ğŸ“ Maximizing Paint...")
            paint_window.maximize()
            time.sleep(0.5)
        
        # Äáº£m báº£o Paint Ä‘Æ°á»£c focus
        paint_window.activate()
        time.sleep(0.3)
        
        return True
        
    except Exception as e:
        print(f"   âš ï¸  KhÃ´ng thá»ƒ maximize Paint: {e}")
        print("   ğŸ”„ Thá»­ phÆ°Æ¡ng phÃ¡p dá»± phÃ²ng...")
        
        # Fallback: Click vÃ o thanh title bar rá»“i maximize báº±ng double-click
        pyautogui.click(500, 10)  # Click vÃ o title bar
        time.sleep(0.2)
        pyautogui.doubleClick(500, 10)  # Double-click Ä‘á»ƒ maximize
        time.sleep(0.5)
        
        return True
    

def story_outline_agent(state: StoryArtState) -> StoryArtState:
    """Agent táº¡o dÃ n Ã½ truyá»‡n"""
    
    if state['mode'] == 'art_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("ğŸ“ STORY OUTLINE AGENT")
    print("="*70)
    
    try:
        char_info = state['character_info']
        
        prompt = f"""
Táº¡o dÃ n Ã½ cho má»™t cÃ¢u chuyá»‡n ngáº¯n vá» {char_info['name']}.

THÃ”NG TIN NHÃ‚N Váº¬T:
- Xuáº¥t xá»©: {char_info['origin']}
- TÃ­nh cÃ¡ch: {', '.join(char_info['personality'])}

CHá»¦ Äá»€: {state['story_theme']}
Äá»˜ DÃ€I: {state['story_length']} tá»«

JSON FORMAT:
{{
    "title": "TiÃªu Ä‘á» háº¥p dáº«n",
    "setting": "Bá»‘i cáº£nh",
    "act1": "Má»Ÿ Ä‘áº§u",
    "act2": "PhÃ¡t triá»ƒn",
    "act3": "Káº¿t thÃºc",
    "moral": "BÃ i há»c"
}}
"""
        
        response = call_gemini(prompt)
        
        json_str = response
        if '```json' in response:
            json_str = response.split('```json')[1].split('```')[0]
        elif '```' in response:
            json_str = response.split('```')[1].split('```')[0]
        
        outline = json.loads(json_str.strip())
        state['story_outline'] = outline
        
        print(f"\nâœ… Outline: {outline['title']}")
        state['execution_log'].append("âœ“ Outline created")
        
    except Exception as e:
        print(f"âŒ Outline error: {e}")
        state['error'] = f"Outline failed: {e}"
    
    return state


def story_writer_agent(state: StoryArtState) -> StoryArtState:
    """Agent viáº¿t ná»™i dung truyá»‡n"""
    
    if state['mode'] == 'art_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("âœï¸ STORY WRITER AGENT")
    print("="*70)
    
    try:
        char_info = state['character_info']
        outline = state['story_outline']
        
        prompt = f"""
Viáº¿t má»™t cÃ¢u chuyá»‡n hoÃ n chá»‰nh vá» {char_info['name']}.

TIÃŠU Äá»€: {outline['title']}
DÃ€N Ã:
- Má»Ÿ Ä‘áº§u: {outline['act1']}
- PhÃ¡t triá»ƒn: {outline['act2']}
- Káº¿t thÃºc: {outline['act3']}

YÃŠU Cáº¦U:
- Äá»™ dÃ i: {state['story_length']} tá»«
- NgÃ´n ngá»¯: Tiáº¿ng Viá»‡t, sinh Ä‘á»™ng
- CÃ³ thoáº¡i trá»±c tiáº¿p

Chá»‰ viáº¿t ná»™i dung truyá»‡n.
"""
        
        print("   ğŸ¤– AI Ä‘ang viáº¿t truyá»‡n...")
        response = call_gemini(prompt)
        
        story_content = f"""
{'='*70}
{outline['title'].upper()}
{'='*70}

{response.strip()}

{'='*70}
BÃ i há»c: {outline['moral']}
{'='*70}
"""
        
        state['story_content'] = story_content
        
        word_count = len(response.split())
        print(f"\nâœ… Story written: {word_count} words")
        state['execution_log'].append(f"âœ“ Story: {word_count} words")
        
    except Exception as e:
        print(f"âŒ Writer error: {e}")
        state['error'] = f"Writer failed: {e}"
    
    return state


def story_formatter_agent(state: StoryArtState) -> StoryArtState:
    """Agent má»Ÿ Notepad vÃ  ghi truyá»‡n"""
    
    if state['mode'] == 'art_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("ğŸ’¾ STORY FORMATTER AGENT")
    print("="*70)
    
    try:
        # 1. Má»Ÿ Notepad
        print("   ğŸ“ Opening Notepad...")
        subprocess.Popen(['notepad'])
        time.sleep(2)
        
        # 2. Maximize
        pyautogui.hotkey('win', 'up')
        time.sleep(0.5)
        
        # 3. Paste ná»™i dung
        print("   âŒ¨ï¸  Pasting story content...")
        pyperclip.copy(state['story_content'])
        pyautogui.hotkey('ctrl', 'v')
        time.sleep(1)
        
        # 4. Save file
        print("   ğŸ’¾ Saving file...")
        pyautogui.hotkey('ctrl', 's')
        time.sleep(1)
        
        # Táº¡o tÃªn file
        char_name = state['character_name'].replace(' ', '_')
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"story_{char_name}_{timestamp}.txt"
        
        pyperclip.copy(filename)
        pyautogui.hotkey('ctrl', 'a')
        time.sleep(0.2)
        pyautogui.hotkey('ctrl', 'v')
        time.sleep(0.5)
        
        pyautogui.press('enter')
        time.sleep(0.5)
        
        state['story_file_path'] = filename
        
        print(f"\nâœ… Story saved: {filename}")
        state['execution_log'].append(f"âœ“ Saved: {filename}")
        
        # ÄÃ³ng Notepad
        print("   ğŸšª Closing Notepad...")
        time.sleep(1)
        pyautogui.hotkey('alt', 'f4')
        time.sleep(1)
        
    except Exception as e:
        print(f"âŒ Formatter error: {e}")
        state['error'] = f"Formatter failed: {e}"
    
    return state


# ============ AGENT 2: ART CREATOR ============
def art_preparation_agent(state: StoryArtState) -> StoryArtState:
    """Agent chuáº©n bá»‹ áº£nh tham kháº£o vÃ  má»Ÿ Paint - FIXED VERSION"""
    
    if state['mode'] == 'story_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("ğŸ¨ ART PREPARATION AGENT")
    print("="*70)
    
    IMAGE_FOLDER = "images"
    char_name = state['character_name'].replace(' ', '_').lower()
    REFERENCE_IMAGE_PATH = os.path.join(IMAGE_FOLDER, f"{char_name}.jpg")
    
    try:
        # 1. Kiá»ƒm tra áº£nh tham kháº£o
        if not os.path.exists(REFERENCE_IMAGE_PATH):
            REFERENCE_IMAGE_PATH = os.path.join(IMAGE_FOLDER, f"{char_name}.png")
            
            if not os.path.exists(REFERENCE_IMAGE_PATH):
                print(f"\nâš ï¸  KhÃ´ng tÃ¬m tháº¥y áº£nh: {REFERENCE_IMAGE_PATH}")
                
                import webbrowser
                search_url = f"https://www.google.com/search?q={state['character_name']}+simple+drawing&tbm=isch"
                webbrowser.open(search_url)
                
                input("\n   â¸ï¸  Táº£i áº£nh vÃ  lÆ°u vÃ o images/, nháº¥n Enter...")
                
                if not os.path.exists(REFERENCE_IMAGE_PATH):
                    raise FileNotFoundError(f"KhÃ´ng tÃ¬m tháº¥y: {REFERENCE_IMAGE_PATH}")
        
        print(f"   âœ… Found: {REFERENCE_IMAGE_PATH}")
        
        # 2. ÄÆ¡n giáº£n hÃ³a áº£nh
        print("   ğŸ–¼ï¸  Simplifying image...")
        simplified_path = simplify_image_for_drawing(REFERENCE_IMAGE_PATH)
        
        # 3. Load áº£nh vÃ o state
        state['reference_image_b64'] = image_to_base64(simplified_path)
        
        # 4. Setup Paint - PHÆ¯Æ NG PHÃP AN TOÃ€N (khÃ´ng dÃ¹ng activate())
        print("\n   ğŸ” Setting up Paint...")
        paint_windows = gw.getWindowsWithTitle('Paint')
        
        if paint_windows:
            print("   âœ… Paint Ä‘Ã£ má»Ÿ")
            paint_window = paint_windows[0]
            
            # Chá»‰ dÃ¹ng maximize vÃ  click, KHÃ”NG dÃ¹ng activate()
            try:
                if not paint_window.isMaximized:
                    print("   ğŸ“ Maximizing Paint...")
                    paint_window.maximize()
                    time.sleep(1.0)
                else:
                    print("   âœ… Paint Ä‘Ã£ maximized")
            except Exception as e:
                print(f"   âš ï¸  Maximize error: {e}, using keyboard shortcut...")
                pyautogui.hotkey('win', 'up')
                time.sleep(1.0)
            
            # Focus báº±ng cÃ¡ch click vÃ o window (AN TOÃ€N hÆ¡n activate())
            print("   ğŸ–±ï¸  Focusing Paint window...")
            try:
                # Click vÃ o giá»¯a window
                x, y, w, h = paint_window.left, paint_window.top, paint_window.width, paint_window.height
                pyautogui.click(x + w // 2, y + h // 2)
                time.sleep(0.5)
            except:
                # Fallback: click vÃ o giá»¯a mÃ n hÃ¬nh
                screen_w, screen_h = pyautogui.size()
                pyautogui.click(screen_w // 2, screen_h // 2)
                time.sleep(0.5)
            
        else:
            # 5. Má»Ÿ Paint má»›i
            print("   ğŸ¨ Opening new Paint...")
            subprocess.Popen(['mspaint'])
            time.sleep(3.5)
            
            # Maximize báº±ng keyboard
            print("   ğŸ“ Maximizing Paint...")
            pyautogui.hotkey('win', 'up')
            time.sleep(1.0)
            
            # Click Ä‘á»ƒ focus
            screen_w, screen_h = pyautogui.size()
            pyautogui.click(screen_w // 2, screen_h // 2)
            time.sleep(0.5)
        
        # 6. Click vÃ o canvas area Ä‘á»ƒ Ä‘áº£m báº£o ready
        print("   ğŸ–±ï¸  Preparing canvas...")
        pyautogui.click(700, 400)
        time.sleep(0.5)
        
        # 7. Chá»¥p screenshot Paint
        print("   ğŸ“¸ Capturing Paint interface...")
        time.sleep(1.0)
        state['paint_screenshot_b64'] = screenshot_to_base64()
        
        print("   âœ… Paint setup complete!")
        state['execution_log'].append("âœ“ Preparation: Paint ready")
        
    except Exception as e:
        print(f"âŒ Preparation error: {e}")
        state['error'] = f"Preparation failed: {e}"
        traceback.print_exc()
    
    return state

def art_cv_analyzer_agent(state: StoryArtState) -> StoryArtState:
    """
    Agent phÃ¢n tÃ­ch giao diá»‡n Paint báº±ng Computer Vision
    """
    
    if state['mode'] == 'story_only' or state['error']:
        return state
    
    try:
        # PhÃ¢n tÃ­ch báº±ng CV
        cv_result = analyze_paint_interface(state['paint_screenshot_b64'])
        
        # LÆ°u vÃ o state
        state['canvas_area'] = cv_result['canvas_area']
        state['color_positions'] = cv_result['color_positions']
        state['tool_positions'] = cv_result['tool_positions']
        
        state['execution_log'].append("âœ“ CV Analysis: Interface detected")
        
    except Exception as e:
        print(f"âŒ CV Analyzer error: {e}")
        state['error'] = f"CV Analysis failed: {e}"
        traceback.print_exc()
    
    return state


def art_llm_planner_agent(state: StoryArtState) -> StoryArtState:
    """
    Agent dÃ¹ng LLM Ä‘á»ƒ táº¡o káº¿ hoáº¡ch váº½ Dá»±A TRÃŠN Tá»ŒA Äá»˜ THáº¬T tá»« CV
    """
    
    if state['mode'] == 'story_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("ğŸ§  LLM PLANNER AGENT (AI Strategy)")
    print("="*70)
    
    try:
        canvas = state['canvas_area']
        colors = list(state['color_positions'].keys())
        tools = list(state['tool_positions'].keys())
        
        # Load reference image
        ref_img = Image.open(BytesIO(base64.b64decode(state['reference_image_b64'])))
        ref_img.thumbnail((800, 800), Image.Resampling.LANCZOS)
        
        prompt = f"""
Báº¡n lÃ  AI Drawing Planner. Táº¡o káº¿ hoáº¡ch váº½ "{state['character_name']}" trong Paint.

THÃ”NG TIN CANVAS (Ä‘Ã£ Ä‘Æ°á»£c Computer Vision phÃ¡t hiá»‡n):
- Vá»‹ trÃ­: ({canvas['x']}, {canvas['y']})
- KÃ­ch thÆ°á»›c: {canvas['width']}x{canvas['height']}
- VÃ¹ng váº½ há»£p lá»‡:
  * X: tá»« {canvas['x']} Ä‘áº¿n {canvas['x'] + canvas['width']}
  * Y: tá»« {canvas['y']} Ä‘áº¿n {canvas['y'] + canvas['height']}

TOOLS CÃ“ Sáº´N: {', '.join(tools)}
COLORS CÃ“ Sáº´N: {', '.join(colors)}

YÃŠU Cáº¦U:
1. PhÃ¢n tÃ­ch áº£nh tham kháº£o
2. Táº¡o 5-7 bÆ°á»›c váº½ ÄÆ N GIáº¢N
3. DÃ¹ng oval/rectangle cho hÃ¬nh cÆ¡ báº£n
4. DÃ¹ng fill Ä‘á»ƒ tÃ´ mÃ u
5. Tá»ŒA Äá»˜ PHáº¢I Náº°M TRONG CANVAS!

JSON FORMAT:
{{
  "analysis": "MÃ´ táº£ ngáº¯n vá» nhÃ¢n váº­t vÃ  cÃ¡ch váº½",
  "steps": [
    {{
      "step": 1,
      "description": "Váº½ Ä‘áº§u (oval lá»›n)",
      "tool": "oval",
      "color": "black",
      "action": "drag",
      "start_x": {canvas['x'] + 200},
      "start_y": {canvas['y'] + 100},
      "end_x": {canvas['x'] + 400},
      "end_y": {canvas['y'] + 250}
    }},
    {{
      "step": 2,
      "description": "TÃ´ mÃ u Ä‘áº§u",
      "tool": "fill",
      "color": "yellow",
      "action": "click",
      "click_x": {canvas['x'] + 300},
      "click_y": {canvas['y'] + 175}
    }},
    {{
      "step": 3,
      "description": "Váº½ thÃ¢n (rectangle)",
      "tool": "rectangle",
      "color": "red",
      "action": "drag",
      "start_x": {canvas['x'] + 250},
      "start_y": {canvas['y'] + 250},
      "end_x": {canvas['x'] + 350},
      "end_y": {canvas['y'] + 400}
    }}
  ]
}}

âš ï¸ QUAN TRá»ŒNG:
- action="drag" cáº§n: start_x, start_y, end_x, end_y
- action="click" cáº§n: click_x, click_y
- Táº¤T Cáº¢ tá»a Ä‘á»™ PHáº¢I trong khoáº£ng canvas Ä‘Ã£ cho
- CHá»ˆ dÃ¹ng tools vÃ  colors cÃ³ sáºµn
"""
        
        print("   ğŸ¤– LLM analyzing reference image and creating plan...")
        response = call_gemini_vision(prompt, [ref_img])
        
        # Extract JSON
        json_str = response
        if '```json' in response:
            json_str = response.split('```json')[1].split('```')[0]
        elif '```' in response:
            json_str = response.split('```')[1].split('```')[0]
        
        plan = json.loads(json_str.strip())
        
        print(f"\n   ğŸ“‹ AI Analysis: {plan.get('analysis', 'N/A')}")
        
        # VALIDATE vÃ  CLAMP tá»a Ä‘á»™
        validated_steps = []
        for step in plan.get('steps', []):
            # Kiá»ƒm tra tool vÃ  color cÃ³ tá»“n táº¡i khÃ´ng
            if step.get('tool') not in tools:
                print(f"      âš ï¸  Step {step['step']}: Tool '{step.get('tool')}' not available, using 'pencil'")
                step['tool'] = 'pencil' if 'pencil' in tools else tools[0]
            
            if step.get('color') not in colors:
                print(f"      âš ï¸  Step {step['step']}: Color '{step.get('color')}' not available, using 'black'")
                step['color'] = 'black' if 'black' in colors else colors[0]
            
            # Clamp tá»a Ä‘á»™ vÃ o canvas
            if step.get('action') == 'drag':
                step['start_x'] = max(canvas['x'], min(step['start_x'], canvas['x'] + canvas['width']))
                step['start_y'] = max(canvas['y'], min(step['start_y'], canvas['y'] + canvas['height']))
                step['end_x'] = max(canvas['x'], min(step['end_x'], canvas['x'] + canvas['width']))
                step['end_y'] = max(canvas['y'], min(step['end_y'], canvas['y'] + canvas['height']))
            
            elif step.get('action') == 'click':
                step['click_x'] = max(canvas['x'], min(step['click_x'], canvas['x'] + canvas['width']))
                step['click_y'] = max(canvas['y'], min(step['click_y'], canvas['y'] + canvas['height']))
            
            validated_steps.append(step)
        
        state['drawing_steps'] = validated_steps
        state['total_steps'] = len(validated_steps)
        state['current_step'] = 0
        
        print(f"\nâœ… Drawing plan created: {state['total_steps']} steps")
        for step in validated_steps:
            print(f"   Step {step['step']}: {step['description']}")
            if step.get('action') == 'drag':
                print(f"      â†’ Drag from ({step['start_x']},{step['start_y']}) to ({step['end_x']},{step['end_y']})")
            elif step.get('action') == 'click':
                print(f"      â†’ Click at ({step['click_x']},{step['click_y']})")
        
        state['execution_log'].append(f"âœ“ LLM Plan: {state['total_steps']} steps")
        
    except Exception as e:
        print(f"âŒ LLM Planner error: {e}")
        state['error'] = f"LLM Planner failed: {e}"
        traceback.print_exc()
    
    return state


def art_executor_agent(state: StoryArtState) -> StoryArtState:
    """Agent thá»±c thi váº½ TOÃ€N Bá»˜ cÃ¡c bÆ°á»›c"""
    
    if state['mode'] == 'story_only' or state['error']:
        return state
    
    print("\n" + "="*70)
    print("âš™ï¸ ART EXECUTOR AGENT - FULL AUTO DRAWING")
    print("="*70)
    
    tool_positions = state['tool_positions']
    color_positions = state['color_positions']
    steps = state['drawing_steps']
    
    try:
        for i, step_data in enumerate(steps):
            step_num = i + 1
            print(f"\n   [{step_num}/{len(steps)}] {step_data['description']}")
            
            tool = step_data.get('tool', 'pencil')
            color = step_data.get('color', 'black')
            action = step_data.get('action', 'drag')
            
            # 1. Chá»n tool
            if tool in tool_positions:
                tool_pos = tool_positions[tool]
                print(f"      ğŸ”§ Tool: {tool} at ({tool_pos['x']}, {tool_pos['y']})")
                pyautogui.click(tool_pos['x'], tool_pos['y'])
                time.sleep(0.3)
            else:
                print(f"      âš ï¸  Tool '{tool}' not found!")
            
            # 2. Chá»n mÃ u
            if color in color_positions:
                color_pos = color_positions[color]
                print(f"      ğŸ¨ Color: {color} at ({color_pos['x']}, {color_pos['y']})")
                pyautogui.click(color_pos['x'], color_pos['y'])
                time.sleep(0.3)
            else:
                print(f"      âš ï¸  Color '{color}' not found!")
            
            # 3. Thá»±c hiá»‡n váº½
            if action == 'drag':
                sx = step_data.get('start_x')
                sy = step_data.get('start_y')
                ex = step_data.get('end_x')
                ey = step_data.get('end_y')
                
                print(f"      âœï¸  Dragging from ({sx},{sy}) to ({ex},{ey})...")
                
                pyautogui.moveTo(sx, sy, duration=0.2)
                time.sleep(0.1)
                pyautogui.drag(ex - sx, ey - sy, duration=0.5, button='left')
                
            elif action == 'click':
                cx = step_data.get('click_x')
                cy = step_data.get('click_y')
                
                print(f"      ğŸ–±ï¸  Clicking at ({cx},{cy})...")
                pyautogui.click(cx, cy)
            
            time.sleep(0.5)
            print(f"      âœ… Step {step_num} done!")
        
        # HoÃ n thÃ nh
        state['current_step'] = len(steps)
        state['is_complete'] = True
        
        print(f"\n   ğŸ‰ ALL {len(steps)} STEPS COMPLETED!")
        state['execution_log'].append(f"âœ“ Drawing: {len(steps)} steps completed")
        
        # LÆ°u áº£nh
        print("\n   ğŸ’¾ Saving final drawing...")
        time.sleep(1)
        
        char_name = state['character_name'].replace(' ', '_')
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"drawing_{char_name}_{timestamp}.png"
        
        screenshot = pyautogui.screenshot()
        screenshot.save(filename)
        
        print(f"   âœ… Saved: {filename}")
        state['execution_log'].append(f"âœ“ Image: {filename}")
        
    except Exception as e:
        print(f"âŒ Executor error: {e}")
        state['error'] = f"Executor failed: {e}"
        traceback.print_exc()
    
    return state


# ============ BUILD WORKFLOW ============

def build_workflow(mode: str):
    """Build workflow dá»±a trÃªn mode"""
    workflow = StateGraph(StoryArtState)
    
    if mode == "story_only":
        workflow.add_node("story_research", story_research_agent)
        workflow.add_node("story_outline", story_outline_agent)
        workflow.add_node("story_writer", story_writer_agent)
        workflow.add_node("story_formatter", story_formatter_agent)
        
        workflow.set_entry_point("story_research")
        workflow.add_edge("story_research", "story_outline")
        workflow.add_edge("story_outline", "story_writer")
        workflow.add_edge("story_writer", "story_formatter")
        workflow.add_edge("story_formatter", END)
        
    elif mode == "art_only":
        workflow.add_node("art_preparation", art_preparation_agent)
        workflow.add_node("art_cv_analyzer", art_cv_analyzer_agent)
        workflow.add_node("art_llm_planner", art_llm_planner_agent)
        workflow.add_node("art_executor", art_executor_agent)
        
        workflow.set_entry_point("art_preparation")
        workflow.add_edge("art_preparation", "art_cv_analyzer")
        workflow.add_edge("art_cv_analyzer", "art_llm_planner")
        workflow.add_edge("art_llm_planner", "art_executor")
        workflow.add_edge("art_executor", END)
        
    else:  # full
        workflow.add_node("story_research", story_research_agent)
        workflow.add_node("story_outline", story_outline_agent)
        workflow.add_node("story_writer", story_writer_agent)
        workflow.add_node("story_formatter", story_formatter_agent)
        workflow.add_node("art_preparation", art_preparation_agent)
        workflow.add_node("art_cv_analyzer", art_cv_analyzer_agent)
        workflow.add_node("art_llm_planner", art_llm_planner_agent)
        workflow.add_node("art_executor", art_executor_agent)
        
        workflow.set_entry_point("story_research")
        workflow.add_edge("story_research", "story_outline")
        workflow.add_edge("story_outline", "story_writer")
        workflow.add_edge("story_writer", "story_formatter")
        workflow.add_edge("story_formatter", "art_preparation")
        workflow.add_edge("art_preparation", "art_cv_analyzer")
        workflow.add_edge("art_cv_analyzer", "art_llm_planner")
        workflow.add_edge("art_llm_planner", "art_executor")
        workflow.add_edge("art_executor", END)
    
    return workflow.compile()


# ============ MAIN ============

def main():
    """Main function"""
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘          ğŸ¨ğŸ“ ANIME STORY STUDIO V4                       â•‘
â•‘          Hybrid CV + LLM - Smart Drawing                  â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    print("\nğŸ“‹ MENU:")
    print("  1. Viáº¿t truyá»‡n + Váº½ nhÃ¢n váº­t (Full Auto)")
    print("  2. Chá»‰ viáº¿t truyá»‡n (Story Only)")
    print("  3. Chá»‰ váº½ tranh (Art Only)")
    print("  0. ThoÃ¡t")
    
    choice = input("\nğŸ‘‰ Chá»n chá»©c nÄƒng (1-3): ").strip()
    
    if choice == '0':
        print("ğŸ‘‹ Goodbye!")
        return
    
    # XÃ¡c Ä‘á»‹nh mode
    mode_map = {
        '1': 'full',
        '2': 'story_only',
        '3': 'art_only'
    }
    mode = mode_map.get(choice, 'full')
    
    # Input thÃ´ng tin
    print("\n" + "="*60)
    character_name = input("ğŸ­ Nháº­p tÃªn nhÃ¢n váº­t (VD: Doraemon, Pikachu, Naruto): ").strip()
    
    if not character_name:
        character_name = "Doraemon"
        print(f"   âš ï¸  Sá»­ dá»¥ng máº·c Ä‘á»‹nh: {character_name}")
    
    story_theme = "adventure"
    story_length = 200
    
    if mode in ['full', 'story_only']:
        story_theme = input("ğŸ“– Chá»§ Ä‘á» truyá»‡n (adventure/friendship/funny): ").strip() or "adventure"
        story_length_input = input("ğŸ“ Äá»™ dÃ i truyá»‡n (sá»‘ tá»«, VD: 500): ").strip()
        try:
            story_length = int(story_length_input)
        except:
            story_length = 200
    
    # Khá»Ÿi táº¡o state
    initial_state = StoryArtState(
        character_name=character_name,
        story_theme=story_theme,
        story_length=story_length,
        mode=mode,
        character_info={},
        story_outline={},
        story_content="",
        story_file_path="",
        reference_image_b64="",
        paint_screenshot_b64="",
        tool_positions={},
        color_positions={},
        canvas_area={},
        drawing_steps=[],
        current_step=0,
        total_steps=0,
        execution_log=[],
        is_complete=False,
        error=""
    )
    
    # Build vÃ  cháº¡y workflow
    print("\nğŸš€ Starting automation...")
    print("âš ï¸  Script sáº½ Ä‘iá»u khiá»ƒn chuá»™t vÃ  bÃ n phÃ­m!")
    print("âš ï¸  KHÃ”NG DI CHUYá»‚N CHUá»˜T trong quÃ¡ trÃ¬nh váº½!")
    time.sleep(3)
    
    graph = build_workflow(mode)
    
    try:
        final_state = graph.invoke(initial_state)
        
        # Summary
        print("\n" + "="*70)
        print("ğŸ“Š EXECUTION SUMMARY")
        print("="*70)
        
        if final_state.get('error'):
            print(f"âŒ Error: {final_state['error']}")
        else:
            print("âœ… Status: Completed!")
            
            if final_state.get('story_file_path'):
                print(f"ğŸ“ Story: {final_state['story_file_path']}")
            
            if final_state.get('is_complete'):
                print(f"ğŸ¨ Drawing: {final_state['total_steps']} steps completed")
        
        print("\nğŸ“œ Execution Log:")
        for log in final_state.get('execution_log', []):
            print(f"  {log}")
        
    except Exception as e:
        print(f"\nğŸ’¥ Critical error: {e}")
        traceback.print_exc()
    
    print("\n" + "="*70)
    print("ğŸ¤– Automation finished!")


if __name__ == "__main__":
    main()