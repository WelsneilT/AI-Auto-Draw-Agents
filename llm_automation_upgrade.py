"""
======================================================================================
ANIME STORY STUDIO V7.3 - RELIABLE WINDOW MAXIMIZE
Zero Hotkeys + Guaranteed Maximize + CV-Powered
======================================================================================
"""

import os
import time
import json
import subprocess
import ctypes
from io import BytesIO
from datetime import datetime
from dotenv import load_dotenv
from PIL import Image, ImageGrab
import pyautogui
import cv2
import numpy as np
from typing import Dict, Tuple
import traceback
import pygetwindow as gw # <<< TH√äM TH∆Ø VI·ªÜN ƒê·ªÇ ƒêI·ªÄU KHI·ªÇN C·ª¨A S·ªî
from paint_cv_detector import detect_paint_interface_cv
from llm_helper import GeminiAssistant, interactive_character_selection
# Load environment
load_dotenv()

# Config pyautogui
pyautogui.FAILSAFE = False
pyautogui.PAUSE = 0.1

# Global scale factor
SCALE_FACTOR = 1.0

# ============ SCREEN SCALING ============

def get_screen_scale_factor() -> float:
    try:
        ctypes.windll.shcore.SetProcessDpiAwareness(2)
    except:
        pass
    logical_width, logical_height = pyautogui.size()
    screenshot = ImageGrab.grab()
    physical_width, physical_height = screenshot.size
    scale_factor = physical_width / logical_width
    
    print(f"\n   üìê Screen Detection:")
    print(f"      Logical size:  {logical_width}x{logical_height}")
    print(f"      Physical size: {physical_width}x{physical_height}")
    print(f"      Scale factor:  {scale_factor:.2f}x ({scale_factor*100:.0f}%)")
    
    return scale_factor

def scale_coords(x: int, y: int) -> Tuple[int, int]:
    global SCALE_FACTOR
    return (int(x / SCALE_FACTOR), int(y / SCALE_FACTOR))

# ============ UTILITY FUNCTIONS ============

def screenshot_full() -> Image.Image:
    return ImageGrab.grab()

def slow_click(x: int, y: int, clicks: int = 1):
    scaled_x, scaled_y = scale_coords(x, y)
    pyautogui.moveTo(scaled_x, scaled_y, duration=0.3)
    pyautogui.click(clicks=clicks)
    time.sleep(0.3)

# ============ VISION FUNCTIONS ============

def detect_paint_interface(screenshot: Image.Image) -> Dict:
    """Ph√¢n t√≠ch giao di·ªán Paint b·∫±ng Computer Vision."""
    print("   üî¨ Analyzing Paint interface via CV...")
    return detect_paint_interface_cv(screenshot, templates_dir="templates")

# ============ IMAGE PROCESSING ============

def preprocess_image(image_path: str, max_size: int = 200) -> np.ndarray:
    print(f"\n   üìê Processing image: {image_path}")
    original = cv2.imread(image_path)
    if original is None:
        raise FileNotFoundError(f"Cannot read image: {image_path}")
    
    height, width = original.shape[:2]
    scale = min(max_size / width, max_size / height)
    new_width, new_height = int(width * scale), int(height * scale)
    
    resized = cv2.resize(original, (new_width, new_height), interpolation=cv2.INTER_AREA)
    gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)
    _, bw = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
    
    print(f"   ‚úÖ Processed: {new_width}x{new_height} pixels")
    
    preview_path = "preview_bw.png"
    cv2.imwrite(preview_path, bw)
    print(f"   üíæ Preview saved: {preview_path}")
    
    return bw

# ============ MAIN WORKFLOW ============

def setup_paint_window():
    # <<< H√ÄM N√ÄY ƒê∆Ø·ª¢C VI·∫æT L·∫†I HO√ÄN TO√ÄN ƒê·ªÇ ƒê·∫¢M B·∫¢O ƒê·ªò TIN C·∫¨Y
    """
    M·ªü, t√¨m, v√† ch·∫Øc ch·∫Øn ph√≥ng to c·ª≠a s·ªï Paint.
    """
    print("\n" + "="*70)
    print("üé® SETUP PAINT WINDOW (RELIABLE)")
    print("="*70)
    
    # 1. ƒê√≥ng t·∫•t c·∫£ c√°c ti·∫øn tr√¨nh Paint c≈©
    print("\n   üßπ Closing old Paint processes...")
    try:
        subprocess.run(['taskkill', '/F', '/IM', 'mspaint.exe'], capture_output=True, timeout=3)
        time.sleep(1)
    except Exception as e:
        print(f"      (Info) No old Paint process found or could not kill: {e}")

    # 2. M·ªü m·ªôt ti·∫øn tr√¨nh Paint m·ªõi
    print("   üöÄ Opening a new Paint instance...")
    subprocess.Popen(['mspaint'])
    time.sleep(4) # Ch·ªù cho Paint c√≥ th·ªùi gian kh·ªüi ƒë·ªông

    # 3. T√¨m c·ª≠a s·ªï Paint v·ª´a m·ªü
    print("   üîç Searching for the Paint window...")
    paint_window = None
    # Th·ª≠ t√¨m trong v√†i gi√¢y, v√¨ c·ª≠a s·ªï c√≥ th·ªÉ xu·∫•t hi·ªán ch·∫≠m
    for _ in range(5):
        # T√¨m ki·∫øm c√°c ti√™u ƒë·ªÅ ph·ªï bi·∫øn c·ªßa Paint
        windows = gw.getWindowsWithTitle('Untitled - Paint') + gw.getWindowsWithTitle('Paint')
        if windows:
            paint_window = windows[0]
            print(f"   ‚úÖ Found window: '{paint_window.title}'")
            break
        time.sleep(1)

    if not paint_window:
        raise Exception("Fatal Error: Could not find the Paint window after opening it.")

    # 4. K√≠ch ho·∫°t v√† Ph√≥ng to c·ª≠a s·ªï m·ªôt c√°ch ch·∫Øc ch·∫Øn
    print("   üìê Activating and Maximizing window...")
    paint_window.activate()
    time.sleep(0.5)

    if not paint_window.isMaximized:
        paint_window.maximize()
        print("      Window was not maximized. Sent maximize command.")
        time.sleep(1) # Ch·ªù cho hi·ªáu ·ª©ng ph√≥ng to ho√†n t·∫•t
    else:
        print("      Window is already maximized.")

    # 5. Ch·ª•p l·∫°i m√†n h√¨nh sau khi ƒë√£ ch·∫Øc ch·∫Øn ph√≥ng to
    print("   üì∏ Taking screenshot of the maximized and ready window...")
    return screenshot_full()


def execute_drawing(reference_image_path: str):
    """Quy tr√¨nh th·ª±c thi v·∫Ω ch√≠nh."""
    global SCALE_FACTOR
    
    print("\n" + "="*70)
    print("üé® DRAWING EXECUTION (CV-POWERED)")
    print("="*70)
    
    SCALE_FACTOR = get_screen_scale_factor()
    bw_image = preprocess_image(reference_image_path, max_size=150)
    paint_screenshot = setup_paint_window()
    
    interface = detect_paint_interface(paint_screenshot)
    
    canvas = interface.get('canvas_area', {})
    pencil = interface.get('tools', {}).get('pencil', {})
    black = interface.get('colors', {}).get('black', {})
    
    print(f"   ‚úÖ Canvas found: {canvas}")
    print(f"   ‚úÖ Pencil found: {pencil}")
    print(f"   ‚úÖ Black color found: {black}")
    print(f"   üñºÔ∏è Debug image saved at: {interface.get('debug', {}).get('path')}")
    
    if not all([canvas, pencil, black]):
        print("\n‚ùå L·ªñI: Kh√¥ng th·ªÉ x√°c ƒë·ªãnh ƒë·∫ßy ƒë·ªß giao di·ªán Paint b·∫±ng CV.")
        print("   Vui l√≤ng ki·ªÉm tra file debug/ui_detect_debug.png.")
        print("   H√£y ch·∫Øc ch·∫Øn ·∫£nh m·∫´u trong 'templates/' c·∫Øt chu·∫©n v√† Paint ƒëang ·ªü ƒë√∫ng tr·∫°ng th√°i.")
        raise Exception("Cannot detect Paint interface properly by CV!")
    
    draw_pixel_by_pixel_runs(
        bw_image,
        canvas['x'],
        canvas['y'],
        pencil,
        black
    )
    
    print("\n   üíæ Saving final result...")
    time.sleep(1)
    
    final_screenshot = screenshot_full()
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    output_path = f"drawing_final_{timestamp}.png"
    final_screenshot.save(output_path)
    
    print(f"   ‚úÖ Saved: {output_path}")
    
    print("\n" + "="*70)
    print("üéâ MISSION COMPLETE! DRAWING FINISHED!")
    print("="*70)

def draw_pixel_by_pixel_runs(bw_image: np.ndarray, canvas_x: int, canvas_y: int, 
                             pencil_pos: Dict, black_pos: Dict):
    """V·∫Ω theo c√°c ƒëo·∫°n pixel li√™n ti·∫øp (nhanh h∆°n)."""
    print("\n" + "="*70)
    print("‚úèÔ∏è  RUN-LENGTH DRAWING (OPTIMIZED)")
    print("="*70)
    
    print(f"\n   üñäÔ∏è  Selecting pencil...")
    slow_click(pencil_pos['x'], pencil_pos['y'])
    
    print(f"   üé® Selecting black color...")
    slow_click(black_pos['x'], black_pos['y'])
    
    print(f"\n   ‚úçÔ∏è  Drawing {bw_image.shape[1]}x{bw_image.shape[0]} image...")
    
    h, w = bw_image.shape
    total_runs = 0
    original_pause = pyautogui.PAUSE
    pyautogui.PAUSE = 0.001
    
    for y in range(h):
        row = bw_image[y]
        x = 0
        while x < w:
            if row[x] == 0:
                start_x = x
                while x < w and row[x] == 0: x += 1
                end_x = x - 1
                
                canvas_start_x, canvas_y_pos, canvas_end_x = canvas_x + start_x, canvas_y + y, canvas_x + end_x
                
                scaled_start_x, scaled_y = scale_coords(canvas_start_x, canvas_y_pos)
                scaled_end_x, _ = scale_coords(canvas_end_x, canvas_y_pos)
                
                pyautogui.moveTo(scaled_start_x, scaled_y)
                pyautogui.mouseDown()
                if scaled_start_x != scaled_end_x:
                    pyautogui.moveTo(scaled_end_x, scaled_y)
                pyautogui.mouseUp()
                
                total_runs += 1
            else:
                x += 1
    
    pyautogui.PAUSE = original_pause
    print(f"\n   ‚úÖ Drawing completed with {total_runs} runs.")

# ============ MAIN ============

def main():
    print("""
‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë          üé® ANIME STORY STUDIO V8.0                       ‚ïë
‚ïë          Gemini-Powered Character Recognition             ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
    """)
    
    # Kh·ªüi t·∫°o Gemini
    gemini = GeminiAssistant(model_name="gemini-2.5-flash")  # Ho·∫∑c gemini-1.5-pro
    
    # Cho ph√©p user m√¥ t·∫£ nh√¢n v·∫≠t b·∫±ng ng√¥n ng·ªØ t·ª± nhi√™n
    image_path = interactive_character_selection(gemini)
    
    if not image_path:
        print("\n‚ùå Kh√¥ng th·ªÉ ti·∫øp t·ª•c v√¨ kh√¥ng t√¨m th·∫•y ·∫£nh.")
        return
    
    # (T√ôY CH·ªåN) Ph√¢n t√≠ch ·∫£nh ƒë·ªÉ t·ªëi ∆∞u tham s·ªë
    optimize = input("\nü§ñ Cho ph√©p Gemini t·ªëi ∆∞u tham s·ªë v·∫Ω? (y/n): ").strip().lower()
    
    if optimize == 'y':
        print("\n   üî¨ Gemini ƒëang ph√¢n t√≠ch ·∫£nh...")
        params = gemini.analyze_image_for_drawing(image_path)
        
        print(f"\n   üìä ƒê·ªÅ xu·∫•t t·ª´ Gemini:")
        print(f"      K√≠ch th∆∞·ªõc: {params['max_size']}px")
        print(f"      Ng∆∞·ª°ng: {params['threshold']}")
        print(f"      ƒê·ªô ph·ª©c t·∫°p: {params['complexity']}")
        print(f"      Th·ªùi gian ∆∞·ªõc t√≠nh: {params['estimated_time_minutes']} ph√∫t")
        
        for rec in params['recommendations']:
            print(f"      üí° {rec}")
        
        apply = input("\n   ‚úÖ √Åp d·ª•ng? (y/n): ").strip().lower()
        if apply == 'y':
            # S·∫Ω d√πng params n√†y trong preprocess_image
            # (C·∫ßn s·ª≠a h√†m preprocess_image ƒë·ªÉ nh·∫≠n tham s·ªë)
            pass
    
    print("\n‚ö†Ô∏è  CHU·ªòT S·∫º DI CHUY·ªÇN T·ª∞ ƒê·ªòNG!")
    print("‚è≥ B·∫Øt ƒë·∫ßu sau 5 gi√¢y...")
    
    for i in range(5, 0, -1):
        print(f"   {i}...")
        time.sleep(1)
    
    try:
        execute_drawing(image_path)
    except Exception as e:
        print(f"\nüí• Error: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    main()